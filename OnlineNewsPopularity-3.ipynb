{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install imbalanced-learn","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting imbalanced-learn\n  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n\u001b[K     |████████████████████████████████| 167 kB 2.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: scikit-learn>=0.23 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from imbalanced-learn) (0.23.2)\nRequirement already satisfied: joblib>=0.11 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from imbalanced-learn) (0.17.0)\nRequirement already satisfied: scipy>=0.19.1 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from imbalanced-learn) (1.5.3)\nRequirement already satisfied: numpy>=1.13.3 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from imbalanced-learn) (1.19.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\nInstalling collected packages: imbalanced-learn\nSuccessfully installed imbalanced-learn-0.7.0\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"pip install tensorflow","execution_count":19,"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting tensorflow\n  Downloading tensorflow-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4 MB)\n\u001b[K     |████████████████████████████████| 320.4 MB 24 kB/s  eta 0:00:01     |██████████████████████          | 220.0 MB 4.1 MB/s eta 0:00:25MB 4.1 MB/s eta 0:00:24    |█████████████████████████████▋  | 296.4 MB 3.9 MB/s eta 0:00:07\n\u001b[?25hCollecting keras-preprocessing<1.2,>=1.1.1\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[K     |████████████████████████████████| 42 kB 1.9 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: wheel>=0.26 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from tensorflow) (0.34.2)\nCollecting wrapt>=1.11.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting gast==0.3.3\n  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\nCollecting opt-einsum>=2.3.2\n  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n\u001b[K     |████████████████████████████████| 65 kB 4.0 MB/s  eta 0:00:01\n\u001b[?25hCollecting numpy<1.19.0,>=1.16.0\n  Downloading numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n\u001b[K     |████████████████████████████████| 20.1 MB 36.2 MB/s eta 0:00:01\n\u001b[?25hCollecting protobuf>=3.9.2\n  Downloading protobuf-3.14.0-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n\u001b[K     |████████████████████████████████| 1.0 MB 36.9 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: six>=1.12.0 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from tensorflow) (1.15.0)\nCollecting h5py<2.11.0,>=2.10.0\n  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n\u001b[K     |████████████████████████████████| 2.9 MB 60.4 MB/s eta 0:00:01\n\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n\u001b[K     |████████████████████████████████| 459 kB 56.0 MB/s eta 0:00:01\n\u001b[?25hCollecting grpcio>=1.8.6\n  Downloading grpcio-1.33.2-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n\u001b[K     |████████████████████████████████| 3.8 MB 52.1 MB/s eta 0:00:01\n\u001b[?25hCollecting termcolor>=1.1.0\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\nCollecting tensorboard<3,>=2.3.0\n  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n\u001b[K     |████████████████████████████████| 10.6 MB 54.1 MB/s eta 0:00:01    |████████████████████████▉       | 8.2 MB 54.1 MB/s eta 0:00:01\n\u001b[?25hCollecting astunparse==1.6.3\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nCollecting absl-py>=0.7.0\n  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n\u001b[K     |████████████████████████████████| 127 kB 28.1 MB/s eta 0:00:01\n\u001b[?25hCollecting google-pasta>=0.1.8\n  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n\u001b[K     |████████████████████████████████| 57 kB 8.6 MB/s  eta 0:00:01\n\u001b[?25hCollecting google-auth<2,>=1.6.3\n  Downloading google_auth-1.23.0-py2.py3-none-any.whl (114 kB)\n\u001b[K     |████████████████████████████████| 114 kB 37.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\nCollecting google-auth-oauthlib<0.5,>=0.4.1\n  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\nRequirement already satisfied: setuptools>=41.0.0 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.2.0.post20200712)\nCollecting werkzeug>=0.11.15\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n\u001b[K     |████████████████████████████████| 298 kB 36.4 MB/s eta 0:00:01\n\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n\u001b[K     |████████████████████████████████| 779 kB 50.4 MB/s eta 0:00:01\n\u001b[?25hCollecting markdown>=2.6.8\n  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n\u001b[K     |████████████████████████████████| 96 kB 7.6 MB/s  eta 0:00:01\n\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n\u001b[K     |████████████████████████████████| 47 kB 5.8 MB/s  eta 0:00:01\n\u001b[?25hCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n\u001b[K     |████████████████████████████████| 155 kB 64.8 MB/s eta 0:00:01\n\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\nRequirement already satisfied: idna<3,>=2.5 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\nRequirement already satisfied: chardet<4,>=3.0.2 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.10)\nCollecting requests-oauthlib>=0.7.0\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /srv/conda/envs/notebook/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\nCollecting pyasn1>=0.1.3\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n\u001b[K     |████████████████████████████████| 77 kB 774 kB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.0.1)\nRequirement already satisfied: zipp>=0.5 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\nBuilding wheels for collected packages: wrapt, termcolor\n  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=69748 sha256=5bd62fc00b619bcfc9ac9acf6d7dab95c2a9268f2cf395943bde7967ce0e5012\n  Stored in directory: /home/jovyan/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=8a97e90d9c3cecdd79e13c0b4ec75082f2f26dfa0b7e5badcc89750f68e3e7bb\n  Stored in directory: /home/jovyan/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\nSuccessfully built wrapt termcolor\nInstalling collected packages: numpy, keras-preprocessing, wrapt, gast, opt-einsum, protobuf, h5py, tensorflow-estimator, grpcio, termcolor, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, absl-py, requests-oauthlib, google-auth-oauthlib, werkzeug, tensorboard-plugin-wit, markdown, tensorboard, astunparse, google-pasta, tensorflow\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.19.4\n    Uninstalling numpy-1.19.4:\n      Successfully uninstalled numpy-1.19.4\nSuccessfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.23.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.33.2 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.3.3 numpy-1.18.5 opt-einsum-3.3.0 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0 termcolor-1.1.0 werkzeug-1.0.1 wrapt-1.12.1\nNote: you may need to restart the kernel to use updated packages.\n"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"pip install keras","execution_count":20,"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting keras\n  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\nRequirement already satisfied: pyyaml in /srv/conda/envs/notebook/lib/python3.6/site-packages (from keras) (5.3.1)\nRequirement already satisfied: h5py in /srv/conda/envs/notebook/lib/python3.6/site-packages (from keras) (2.10.0)\nRequirement already satisfied: scipy>=0.14 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from keras) (1.5.3)\nRequirement already satisfied: numpy>=1.9.1 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from keras) (1.18.5)\nRequirement already satisfied: six in /srv/conda/envs/notebook/lib/python3.6/site-packages (from h5py->keras) (1.15.0)\nInstalling collected packages: keras\nSuccessfully installed keras-2.4.3\nNote: you may need to restart the kernel to use updated packages.\n"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nurl=\"https://bd29ee0e-54ab-4daa-9671-d153865d1620.usrfiles.com/ugd/bd29ee_7e85a80ed75c409d8da531a0f5e89a1d.csv\"\ndf=pd.read_csv(url)\ndf.head()","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"                                                 url   timedelta  \\\n0  http://mashable.com/2013/01/07/amazon-instant-...         731   \n1  http://mashable.com/2013/01/07/ap-samsung-spon...         731   \n2  http://mashable.com/2013/01/07/apple-40-billio...         731   \n3  http://mashable.com/2013/01/07/astronaut-notre...         731   \n4   http://mashable.com/2013/01/07/att-u-verse-apps/         731   \n\n    n_tokens_title   n_tokens_content   n_unique_tokens   n_non_stop_words  \\\n0               12                219          0.663594                1.0   \n1                9                255          0.604743                1.0   \n2                9                211          0.575130                1.0   \n3                9                531          0.503788                1.0   \n4               13               1072          0.415646                1.0   \n\n    n_non_stop_unique_tokens   num_hrefs   num_self_hrefs   num_imgs  ...  \\\n0                   0.815385           4                2          1  ...   \n1                   0.791946           3                1          1  ...   \n2                   0.663866           3                1          1  ...   \n3                   0.665635           9                0          1  ...   \n4                   0.540890          19               19         20  ...   \n\n    min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n0                0.100000                     0.7               -0.350000   \n1                0.033333                     0.7               -0.118750   \n2                0.100000                     1.0               -0.466667   \n3                0.136364                     0.8               -0.369697   \n4                0.033333                     1.0               -0.220192   \n\n    min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n0                  -0.600               -0.200000             0.500000   \n1                  -0.125               -0.100000             0.000000   \n2                  -0.800               -0.133333             0.000000   \n3                  -0.600               -0.166667             0.000000   \n4                  -0.500               -0.050000             0.454545   \n\n    title_sentiment_polarity   abs_title_subjectivity  \\\n0                  -0.187500                 0.000000   \n1                   0.000000                 0.500000   \n2                   0.000000                 0.500000   \n3                   0.000000                 0.500000   \n4                   0.136364                 0.045455   \n\n    abs_title_sentiment_polarity   shares  \n0                       0.187500      593  \n1                       0.000000      711  \n2                       0.000000     1500  \n3                       0.000000     1200  \n4                       0.136364      505  \n\n[5 rows x 61 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>timedelta</th>\n      <th>n_tokens_title</th>\n      <th>n_tokens_content</th>\n      <th>n_unique_tokens</th>\n      <th>n_non_stop_words</th>\n      <th>n_non_stop_unique_tokens</th>\n      <th>num_hrefs</th>\n      <th>num_self_hrefs</th>\n      <th>num_imgs</th>\n      <th>...</th>\n      <th>min_positive_polarity</th>\n      <th>max_positive_polarity</th>\n      <th>avg_negative_polarity</th>\n      <th>min_negative_polarity</th>\n      <th>max_negative_polarity</th>\n      <th>title_subjectivity</th>\n      <th>title_sentiment_polarity</th>\n      <th>abs_title_subjectivity</th>\n      <th>abs_title_sentiment_polarity</th>\n      <th>shares</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n      <td>731</td>\n      <td>12</td>\n      <td>219</td>\n      <td>0.663594</td>\n      <td>1.0</td>\n      <td>0.815385</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.100000</td>\n      <td>0.7</td>\n      <td>-0.350000</td>\n      <td>-0.600</td>\n      <td>-0.200000</td>\n      <td>0.500000</td>\n      <td>-0.187500</td>\n      <td>0.000000</td>\n      <td>0.187500</td>\n      <td>593</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n      <td>731</td>\n      <td>9</td>\n      <td>255</td>\n      <td>0.604743</td>\n      <td>1.0</td>\n      <td>0.791946</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.033333</td>\n      <td>0.7</td>\n      <td>-0.118750</td>\n      <td>-0.125</td>\n      <td>-0.100000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>711</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n      <td>731</td>\n      <td>9</td>\n      <td>211</td>\n      <td>0.575130</td>\n      <td>1.0</td>\n      <td>0.663866</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.100000</td>\n      <td>1.0</td>\n      <td>-0.466667</td>\n      <td>-0.800</td>\n      <td>-0.133333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n      <td>731</td>\n      <td>9</td>\n      <td>531</td>\n      <td>0.503788</td>\n      <td>1.0</td>\n      <td>0.665635</td>\n      <td>9</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.136364</td>\n      <td>0.8</td>\n      <td>-0.369697</td>\n      <td>-0.600</td>\n      <td>-0.166667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n      <td>731</td>\n      <td>13</td>\n      <td>1072</td>\n      <td>0.415646</td>\n      <td>1.0</td>\n      <td>0.540890</td>\n      <td>19</td>\n      <td>19</td>\n      <td>20</td>\n      <td>...</td>\n      <td>0.033333</td>\n      <td>1.0</td>\n      <td>-0.220192</td>\n      <td>-0.500</td>\n      <td>-0.050000</td>\n      <td>0.454545</td>\n      <td>0.136364</td>\n      <td>0.045455</td>\n      <td>0.136364</td>\n      <td>505</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 61 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"(39644, 61)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop([\"url\", \" timedelta\"],axis=1)\ndf.shape","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"(39644, 59)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop([\" shares\"],axis=1)\nX.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"    n_tokens_title   n_tokens_content   n_unique_tokens   n_non_stop_words  \\\n0               12                219          0.663594                1.0   \n1                9                255          0.604743                1.0   \n2                9                211          0.575130                1.0   \n3                9                531          0.503788                1.0   \n4               13               1072          0.415646                1.0   \n\n    n_non_stop_unique_tokens   num_hrefs   num_self_hrefs   num_imgs  \\\n0                   0.815385           4                2          1   \n1                   0.791946           3                1          1   \n2                   0.663866           3                1          1   \n3                   0.665635           9                0          1   \n4                   0.540890          19               19         20   \n\n    num_videos   average_token_length  ...   avg_positive_polarity  \\\n0            0               4.680365  ...                0.378636   \n1            0               4.913725  ...                0.286915   \n2            0               4.393365  ...                0.495833   \n3            0               4.404896  ...                0.385965   \n4            0               4.682836  ...                0.411127   \n\n    min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n0                0.100000                     0.7               -0.350000   \n1                0.033333                     0.7               -0.118750   \n2                0.100000                     1.0               -0.466667   \n3                0.136364                     0.8               -0.369697   \n4                0.033333                     1.0               -0.220192   \n\n    min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n0                  -0.600               -0.200000             0.500000   \n1                  -0.125               -0.100000             0.000000   \n2                  -0.800               -0.133333             0.000000   \n3                  -0.600               -0.166667             0.000000   \n4                  -0.500               -0.050000             0.454545   \n\n    title_sentiment_polarity   abs_title_subjectivity  \\\n0                  -0.187500                 0.000000   \n1                   0.000000                 0.500000   \n2                   0.000000                 0.500000   \n3                   0.000000                 0.500000   \n4                   0.136364                 0.045455   \n\n    abs_title_sentiment_polarity  \n0                       0.187500  \n1                       0.000000  \n2                       0.000000  \n3                       0.000000  \n4                       0.136364  \n\n[5 rows x 58 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_tokens_title</th>\n      <th>n_tokens_content</th>\n      <th>n_unique_tokens</th>\n      <th>n_non_stop_words</th>\n      <th>n_non_stop_unique_tokens</th>\n      <th>num_hrefs</th>\n      <th>num_self_hrefs</th>\n      <th>num_imgs</th>\n      <th>num_videos</th>\n      <th>average_token_length</th>\n      <th>...</th>\n      <th>avg_positive_polarity</th>\n      <th>min_positive_polarity</th>\n      <th>max_positive_polarity</th>\n      <th>avg_negative_polarity</th>\n      <th>min_negative_polarity</th>\n      <th>max_negative_polarity</th>\n      <th>title_subjectivity</th>\n      <th>title_sentiment_polarity</th>\n      <th>abs_title_subjectivity</th>\n      <th>abs_title_sentiment_polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12</td>\n      <td>219</td>\n      <td>0.663594</td>\n      <td>1.0</td>\n      <td>0.815385</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.680365</td>\n      <td>...</td>\n      <td>0.378636</td>\n      <td>0.100000</td>\n      <td>0.7</td>\n      <td>-0.350000</td>\n      <td>-0.600</td>\n      <td>-0.200000</td>\n      <td>0.500000</td>\n      <td>-0.187500</td>\n      <td>0.000000</td>\n      <td>0.187500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>255</td>\n      <td>0.604743</td>\n      <td>1.0</td>\n      <td>0.791946</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.913725</td>\n      <td>...</td>\n      <td>0.286915</td>\n      <td>0.033333</td>\n      <td>0.7</td>\n      <td>-0.118750</td>\n      <td>-0.125</td>\n      <td>-0.100000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9</td>\n      <td>211</td>\n      <td>0.575130</td>\n      <td>1.0</td>\n      <td>0.663866</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.393365</td>\n      <td>...</td>\n      <td>0.495833</td>\n      <td>0.100000</td>\n      <td>1.0</td>\n      <td>-0.466667</td>\n      <td>-0.800</td>\n      <td>-0.133333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>531</td>\n      <td>0.503788</td>\n      <td>1.0</td>\n      <td>0.665635</td>\n      <td>9</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.404896</td>\n      <td>...</td>\n      <td>0.385965</td>\n      <td>0.136364</td>\n      <td>0.8</td>\n      <td>-0.369697</td>\n      <td>-0.600</td>\n      <td>-0.166667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13</td>\n      <td>1072</td>\n      <td>0.415646</td>\n      <td>1.0</td>\n      <td>0.540890</td>\n      <td>19</td>\n      <td>19</td>\n      <td>20</td>\n      <td>0</td>\n      <td>4.682836</td>\n      <td>...</td>\n      <td>0.411127</td>\n      <td>0.033333</td>\n      <td>1.0</td>\n      <td>-0.220192</td>\n      <td>-0.500</td>\n      <td>-0.050000</td>\n      <td>0.454545</td>\n      <td>0.136364</td>\n      <td>0.045455</td>\n      <td>0.136364</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 58 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df[[\" shares\"]]\ny.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"    shares\n0      593\n1      711\n2     1500\n3     1200\n4      505","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>shares</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>593</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>711</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>505</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.describe()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"              shares\ncount   39644.000000\nmean     3395.380184\nstd     11626.950749\nmin         1.000000\n25%       946.000000\n50%      1400.000000\n75%      2800.000000\nmax    843300.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>shares</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>39644.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3395.380184</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>11626.950749</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>946.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1400.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2800.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>843300.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\ny[\" shares\"]=np.where((y[\" shares\"]<1400),0,y[\" shares\"])\ny[\" shares\"]=np.where((y[\" shares\"]>=1400),1,y[\" shares\"])\ny.head()","execution_count":7,"outputs":[{"output_type":"stream","text":"/srv/conda/envs/notebook/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/srv/conda/envs/notebook/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n","name":"stderr"},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"    shares\n0        0\n1        0\n2        1\n3        0\n4        0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>shares</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom numpy import set_printoptions\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n\n\ntest = SelectKBest(score_func=f_classif, k=\"all\")\nfit = test.fit(X, np.asarray(y).reshape(y.shape[0],))\nfeatures = fit.transform(X)\nset_printoptions(precision=3)\n\nscores=fit.scores_\nscores=pd.DataFrame(scores)\nscores=scores.rename(columns={0:\"scores\"})\nscores=scores.sort_values(by=[\"scores\"],ascending=False)\nscores","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"         scores\n39  1040.107422\n25  1012.157296\n16   965.484629\n36   802.383879\n12   523.415977\n14   503.990473\n34   476.103909\n15   423.667435\n41   360.082347\n23   328.877426\n5    325.384098\n35   280.851679\n38   248.153250\n43   215.597222\n10   212.879931\n47   202.264220\n24   197.991454\n42   184.475867\n37   180.111713\n7    179.792206\n28   169.779378\n44   147.653829\n27   146.436873\n40   136.574875\n55   113.679026\n26   111.291750\n17   104.425196\n31    79.932746\n0     76.940103\n46    72.646013\n50    70.562889\n1     68.169239\n57    65.474285\n6     65.194516\n30    57.177776\n11    53.758908\n19    51.526458\n21    47.511387\n54    41.693737\n9     32.710266\n48    31.844139\n32    29.499055\n49    27.783106\n45    26.587026\n18    25.522054\n29    19.344276\n22     9.954147\n33     4.144323\n8      2.142019\n20     2.137165\n3      0.671200\n13     0.566665\n56     0.397473\n2      0.318977\n4      0.173452\n51     0.063035\n52     0.008358\n53     0.003542","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39</th>\n      <td>1040.107422</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1012.157296</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>965.484629</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>802.383879</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>523.415977</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>503.990473</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>476.103909</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>423.667435</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>360.082347</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>328.877426</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>325.384098</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>280.851679</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>248.153250</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>215.597222</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>212.879931</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>202.264220</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>197.991454</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>184.475867</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>180.111713</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>179.792206</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>169.779378</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>147.653829</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>146.436873</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>136.574875</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>113.679026</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>111.291750</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>104.425196</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>79.932746</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>76.940103</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>72.646013</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>70.562889</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>68.169239</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>65.474285</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>65.194516</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>57.177776</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>53.758908</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>51.526458</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>47.511387</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>41.693737</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>32.710266</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>31.844139</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>29.499055</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>27.783106</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>26.587026</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>25.522054</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>19.344276</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>9.954147</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>4.144323</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2.142019</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2.137165</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.671200</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.566665</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>0.397473</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.318977</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.173452</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>0.063035</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>0.008358</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>0.003542</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_scores=scores[scores[\"scores\"]>70]\nlen(X_scores)","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"31"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_prime=X.iloc[:,X_scores.index]\nX_prime.head()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"     LDA_02   kw_avg_avg   data_channel_is_world   is_weekend  \\\n0  0.040005          0.0                       0            0   \n1  0.050096          0.0                       0            0   \n2  0.033351          0.0                       0            0   \n3  0.494651          0.0                       0            0   \n4  0.028575          0.0                       0            0   \n\n    data_channel_is_entertainment   data_channel_is_socmed  \\\n0                               1                        0   \n1                               0                        0   \n2                               0                        0   \n3                               1                        0   \n4                               0                        0   \n\n    weekday_is_saturday   data_channel_is_tech    LDA_04   kw_min_avg  ...  \\\n0                     0                      0  0.040123          0.0  ...   \n1                     0                      0  0.050001          0.0  ...   \n2                     0                      0  0.682188          0.0  ...   \n3                     0                      0  0.028572          0.0  ...   \n4                     0                      1  0.885427          0.0  ...   \n\n    global_rate_positive_words   self_reference_max_shares    LDA_03  \\\n0                     0.045662                       496.0  0.041263   \n1                     0.043137                         0.0  0.050101   \n2                     0.056872                       918.0  0.033334   \n3                     0.041431                         0.0  0.028905   \n4                     0.074627                     16000.0  0.028572   \n\n    title_sentiment_polarity   self_reference_min_shares   kw_min_min  \\\n0                  -0.187500                       496.0            0   \n1                   0.000000                         0.0            0   \n2                   0.000000                       918.0            0   \n3                   0.000000                         0.0            0   \n4                   0.136364                       545.0            0   \n\n    weekday_is_wednesday   n_tokens_title   rate_positive_words  \\\n0                      0               12              0.769231   \n1                      0                9              0.733333   \n2                      0                9              0.857143   \n3                      0                9              0.666667   \n4                      0               13              0.860215   \n\n    max_positive_polarity  \n0                     0.7  \n1                     0.7  \n2                     1.0  \n3                     0.8  \n4                     1.0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LDA_02</th>\n      <th>kw_avg_avg</th>\n      <th>data_channel_is_world</th>\n      <th>is_weekend</th>\n      <th>data_channel_is_entertainment</th>\n      <th>data_channel_is_socmed</th>\n      <th>weekday_is_saturday</th>\n      <th>data_channel_is_tech</th>\n      <th>LDA_04</th>\n      <th>kw_min_avg</th>\n      <th>...</th>\n      <th>global_rate_positive_words</th>\n      <th>self_reference_max_shares</th>\n      <th>LDA_03</th>\n      <th>title_sentiment_polarity</th>\n      <th>self_reference_min_shares</th>\n      <th>kw_min_min</th>\n      <th>weekday_is_wednesday</th>\n      <th>n_tokens_title</th>\n      <th>rate_positive_words</th>\n      <th>max_positive_polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.040005</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.040123</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.045662</td>\n      <td>496.0</td>\n      <td>0.041263</td>\n      <td>-0.187500</td>\n      <td>496.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0.769231</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.050096</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.050001</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.043137</td>\n      <td>0.0</td>\n      <td>0.050101</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0.733333</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.033351</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.682188</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.056872</td>\n      <td>918.0</td>\n      <td>0.033334</td>\n      <td>0.000000</td>\n      <td>918.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0.857143</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.494651</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.028572</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.041431</td>\n      <td>0.0</td>\n      <td>0.028905</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0.666667</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.028575</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.885427</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.074627</td>\n      <td>16000.0</td>\n      <td>0.028572</td>\n      <td>0.136364</td>\n      <td>545.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>0.860215</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.groupby(\" shares\")[\" shares\"].count()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":" shares\n0    18490\n1    21154\nName:  shares, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(y[y[\" shares\"]==0])/len(y))\nprint(len(y[y[\" shares\"]==1])/len(y))","execution_count":12,"outputs":[{"output_type":"stream","text":"0.46640096862072444\n0.5335990313792756\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X_prime,y,test_size=0.1,random_state=42)\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":13,"outputs":[{"output_type":"stream","text":"(35679, 31)\n(3965, 31)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.ensemble import BalancedBaggingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nBBagging=BalancedBaggingClassifier(base_estimator=RandomForestClassifier(n_estimators=200),\n                                   random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nBBagging","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"BalancedBaggingClassifier(base_estimator=RandomForestClassifier(n_estimators=200),\n                          random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ntrain_pred=BBagging.predict(X_train)\ntest_pred=BBagging.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":15,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.9850051851229015\nAccuracy on test data:  0.6691046658259773\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nprint(\"ROC_AUC on train data: \",roc_auc_score(y_train,train_pred))\nprint(\"ROC_AUC on test data: \",roc_auc_score(y_test,test_pred))","execution_count":16,"outputs":[{"output_type":"stream","text":"ROC_AUC on train data:  0.9853405612442232\nROC_AUC on test data:  0.6681465210097236\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score\nprint(\"Precision score on train data: \",precision_score(y_train,train_pred,average=\"binary\"))\nprint(\"Precision score on test data: \",precision_score(y_test,test_pred,average=\"binary\"))","execution_count":17,"outputs":[{"output_type":"stream","text":"Precision score on train data:  0.9913601187321107\nPrecision score on test data:  0.6832298136645962\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import recall_score\nprint(\"Recall score on train data: \",recall_score(y_train,train_pred,average=\"binary\"))\nprint(\"Recall score on test data: \",recall_score(y_test,test_pred,average=\"binary\"))","execution_count":18,"outputs":[{"output_type":"stream","text":"Recall score on train data:  0.9804980340760158\nRecall score on test data:  0.6878306878306878\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nprint(\"F1 score on train data: \",f1_score(y_train,train_pred,average=\"binary\"))\nprint(\"F1 score on test data: \",f1_score(y_test,test_pred,average=\"binary\"))","execution_count":19,"outputs":[{"output_type":"stream","text":"F1 score on train data:  0.9858991592208957\nF1 score on test data:  0.6855225311601151\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nprint(\"Confusion matrix for train data: \\n\",confusion_matrix(y_train,train_pred))\nprint(\"Confusion matrix for test data: \\n\",confusion_matrix(y_test,test_pred))","execution_count":20,"outputs":[{"output_type":"stream","text":"Confusion matrix for train data: \n [[16441   163]\n [  372 18703]]\nConfusion matrix for test data: \n [[1223  663]\n [ 649 1430]]\n","name":"stdout"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** **************************** **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.ensemble import BalancedRandomForestClassifier\nBForest=BalancedRandomForestClassifier(random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nBForest","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"BalancedRandomForestClassifier(random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ntrain_pred=BForest.predict(X_train)\ntest_pred=BForest.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":16,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.9998878892345637\nAccuracy on test data:  0.6668348045397225\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nprint(\"ROC_AUC on train data: \",roc_auc_score(y_train,train_pred))\nprint(\"ROC_AUC on test data: \",roc_auc_score(y_test,test_pred))","execution_count":17,"outputs":[{"output_type":"stream","text":"ROC_AUC on train data:  0.9998951507208388\nROC_AUC on test data:  0.6674094630086146\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nprint(\"F1 score on train data: \",f1_score(y_train,train_pred,average=\"binary\"))\nprint(\"F1 score on test data: \",f1_score(y_test,test_pred,average=\"binary\"))","execution_count":18,"outputs":[{"output_type":"stream","text":"F1 score on train data:  0.9998951397263147\nF1 score on test data:  0.6735853718804052\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score\nprint(\"Precision score on train data: \",precision_score(y_train,train_pred,average=\"binary\"))\nprint(\"Precision score on test data: \",precision_score(y_test,test_pred,average=\"binary\"))","execution_count":19,"outputs":[{"output_type":"stream","text":"Precision score on train data:  1.0\nPrecision score on test data:  0.6925813008130082\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import recall_score\nprint(\"Recall score on train data: \",recall_score(y_train,train_pred,average=\"binary\"))\nprint(\"Recall score on test data: \",recall_score(y_test,test_pred,average=\"binary\"))","execution_count":20,"outputs":[{"output_type":"stream","text":"Recall score on train data:  0.9997903014416776\nRecall score on test data:  0.6556036556036556\n","name":"stdout"}]},{"metadata":{"trusted":false},"cell_type":"markdown","source":"** ***************************** **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nForest=RandomForestClassifier(n_estimators=200,random_state=42).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nForest","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"RandomForestClassifier(n_estimators=200, random_state=42)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=Forest.predict(X_train)\ntest_pred=Forest.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":28,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  1.0\nAccuracy on test data:  0.6711223203026482\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"ROC_AUC on train data: \",roc_auc_score(y_train,train_pred))\nprint(\"ROC_AUC on test data: \",roc_auc_score(y_test,test_pred))","execution_count":29,"outputs":[{"output_type":"stream","text":"ROC_AUC on train data:  1.0\nROC_AUC on test data:  0.6682493010700858\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nprint(\"F1 score on train data: \",f1_score(y_train,train_pred,average=\"binary\"))\nprint(\"F1 score on test data: \",f1_score(y_test,test_pred,average=\"binary\"))","execution_count":30,"outputs":[{"output_type":"stream","text":"F1 score on train data:  1.0\nF1 score on test data:  0.6987060998151571\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score\nprint(\"Precision score on train data: \",precision_score(y_train,train_pred,average=\"binary\"))\nprint(\"Precision score on test data: \",precision_score(y_test,test_pred,average=\"binary\"))","execution_count":31,"outputs":[{"output_type":"stream","text":"Precision score on train data:  1.0\nPrecision score on test data:  0.6722987994664296\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import recall_score\nprint(\"Recall score on train data: \",recall_score(y_train,train_pred,average=\"binary\"))\nprint(\"Recall score on test data: \",recall_score(y_test,test_pred,average=\"binary\"))","execution_count":32,"outputs":[{"output_type":"stream","text":"Recall score on train data:  1.0\nRecall score on test data:  0.7272727272727273\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}