{"cells":[{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"pip install tensorflow","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting tensorflow\n  Downloading tensorflow-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4 MB)\n\u001b[K     |████████████████████████████████| 320.4 MB 26 kB/s s eta 0:00:01|████▋                           | 45.9 MB 53.7 MB/s eta 0:00:065     |████████▊                       | 87.8 MB 59.9 MB/s eta 0:00:04     |██████████                      | 99.0 MB 59.9 MB/s eta 0:00:04MB/s eta 0:00:11██                    | 120.1 MB 20.9 MB/s eta 0:00:10     |████████████▍                   | 124.5 MB 20.9 MB/s eta 0:00:10��▊               | 167.9 MB 41.5 MB/s eta 0:00:04     |███████████████████▎            | 193.3 MB 21.9 MB/s eta 0:00:06     |████████████████████▋           | 206.9 MB 19.8 MB/s eta 0:00:06██████████████▊           | 208.0 MB 19.8 MB/s eta 0:00:06     |█████████████████████▎          | 213.3 MB 19.8 MB/s eta 0:00:06��███████████████████████▉      | 258.8 MB 37.1 MB/s eta 0:00:02279.3 MB 60.8 MB/s eta 0:00:01██████████████████▋   | 286.6 MB 60.8 MB/s eta 0:00:01��█████████████████▌  | 295.4 MB 60.8 MB/s eta 0:00:01ta 0:00:01     |██████████████████████████████  | 299.6 MB 60.8 MB/s eta 0:00:01�█▉ | 308.9 MB 60.8 MB/s eta 0:00:01\n\u001b[?25hCollecting google-pasta>=0.1.8\n  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n\u001b[K     |████████████████████████████████| 57 kB 4.0 MB/s  eta 0:00:01\n\u001b[?25hCollecting astunparse==1.6.3\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: six>=1.12.0 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from tensorflow) (1.15.0)\nCollecting grpcio>=1.8.6\n  Downloading grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n\u001b[K     |████████████████████████████████| 3.8 MB 44.8 MB/s eta 0:00:01\n\u001b[?25hCollecting gast==0.3.3\n  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\nCollecting opt-einsum>=2.3.2\n  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n\u001b[K     |████████████████████████████████| 65 kB 4.8 MB/s  eta 0:00:01\n\u001b[?25hCollecting wrapt>=1.11.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting absl-py>=0.7.0\n  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n\u001b[K     |████████████████████████████████| 127 kB 8.0 MB/s eta 0:00:01\n\u001b[?25hCollecting numpy<1.19.0,>=1.16.0\n  Downloading numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n\u001b[K     |████████████████████████████████| 20.1 MB 48.1 MB/s eta 0:00:01    |█████████                       | 5.7 MB 48.1 MB/s eta 0:00:01\n\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n\u001b[K     |████████████████████████████████| 459 kB 42.9 MB/s eta 0:00:01\n\u001b[?25hCollecting termcolor>=1.1.0\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\nCollecting tensorboard<3,>=2.3.0\n  Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n\u001b[K     |████████████████████████████████| 6.8 MB 43.0 MB/s eta 0:00:01\n\u001b[?25hCollecting protobuf>=3.9.2\n  Downloading protobuf-3.13.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n\u001b[K     |████████████████████████████████| 1.3 MB 40.6 MB/s eta 0:00:01\n\u001b[?25hCollecting h5py<2.11.0,>=2.10.0\n  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n\u001b[K     |████████████████████████████████| 2.9 MB 38.7 MB/s eta 0:00:01     |█████████▊                      | 870 kB 38.7 MB/s eta 0:00:01\n\u001b[?25hCollecting keras-preprocessing<1.2,>=1.1.1\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[K     |████████████████████████████████| 42 kB 248 kB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: wheel>=0.26 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from tensorflow) (0.34.2)\nRequirement already satisfied: setuptools>=41.0.0 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.2.0.post20200712)\nCollecting google-auth<2,>=1.6.3\n  Downloading google_auth-1.22.1-py2.py3-none-any.whl (114 kB)\n\u001b[K     |████████████████████████████████| 114 kB 31.0 MB/s eta 0:00:01\n\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\nCollecting markdown>=2.6.8\n  Downloading Markdown-3.3.1-py3-none-any.whl (95 kB)\n\u001b[K     |████████████████████████████████| 95 kB 753 kB/s  eta 0:00:01\n\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n\u001b[K     |████████████████████████████████| 779 kB 13.7 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\nCollecting werkzeug>=0.11.15\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n\u001b[K     |████████████████████████████████| 298 kB 44.3 MB/s eta 0:00:01\n\u001b[?25hCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n\u001b[K     |████████████████████████████████| 155 kB 42.6 MB/s eta 0:00:01\n\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\nCollecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n\u001b[K     |████████████████████████████████| 47 kB 5.0 MB/s  eta 0:00:01\n\u001b[?25hCollecting requests-oauthlib>=0.7.0\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /srv/conda/envs/notebook/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\nRequirement already satisfied: chardet<4,>=3.0.2 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.10)\nRequirement already satisfied: idna<3,>=2.5 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\nCollecting pyasn1<0.5.0,>=0.4.6\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n\u001b[K     |████████████████████████████████| 77 kB 7.1 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.0.1)\nRequirement already satisfied: zipp>=0.5 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\nBuilding wheels for collected packages: wrapt, termcolor\n  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=69742 sha256=ea92747cb6475fb3496dfd87321d8bcafcbd5f69119fe2b0f29b96d11617b22a\n  Stored in directory: /home/jovyan/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=e0fe5d63330c30dced401d4c9d6b30650236c1c0add8c9a8de4d3d20b1957ae2\n  Stored in directory: /home/jovyan/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\nSuccessfully built wrapt termcolor\nInstalling collected packages: google-pasta, astunparse, grpcio, gast, numpy, opt-einsum, wrapt, absl-py, tensorflow-estimator, termcolor, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, requests-oauthlib, google-auth-oauthlib, markdown, protobuf, tensorboard-plugin-wit, werkzeug, tensorboard, h5py, keras-preprocessing, tensorflow\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.19.2\n    Uninstalling numpy-1.19.2:\n      Successfully uninstalled numpy-1.19.2\nSuccessfully installed absl-py-0.10.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.22.1 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.3.1 numpy-1.18.5 opt-einsum-3.3.0 protobuf-3.13.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0 termcolor-1.1.0 werkzeug-1.0.1 wrapt-1.12.1\n","name":"stdout"},{"output_type":"stream","text":"Note: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"pip install keras","execution_count":2,"outputs":[{"output_type":"stream","text":"Collecting keras\n  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\nRequirement already satisfied: pyyaml in /srv/conda/envs/notebook/lib/python3.6/site-packages (from keras) (5.3.1)\nRequirement already satisfied: scipy>=0.14 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from keras) (1.5.2)\nRequirement already satisfied: numpy>=1.9.1 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from keras) (1.18.5)\nRequirement already satisfied: h5py in /srv/conda/envs/notebook/lib/python3.6/site-packages (from keras) (2.10.0)\nRequirement already satisfied: six in /srv/conda/envs/notebook/lib/python3.6/site-packages (from h5py->keras) (1.15.0)\nInstalling collected packages: keras\nSuccessfully installed keras-2.4.3\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Load the data in pandas data frame."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\nurl1=\"https://bd29ee0e-54ab-4daa-9671-d153865d1620.usrfiles.com/ugd/bd29ee_554093d294594a7e9051e3da088590a3.csv\"\ndf1=pd.read_csv(url1,header=None)\ndf1.head()","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"   0      1      2      3     4       5      6      7       8      9    ...  \\\n0    0   87.0  975.0 -287.0  11.0  1001.0  163.0   95.0   975.0  152.0  ...   \n1   33  124.0  978.0 -389.0  -7.0  1014.0  199.0  124.0   968.0  123.0  ...   \n2   67  102.0  996.0 -440.0 -49.0  1024.0  193.0  127.0  1001.0  113.0  ...   \n3  100   59.0  861.0 -384.0  -9.0  1023.0  202.0  110.0  1007.0  106.0  ...   \n4  133  119.0  946.0 -426.0 -22.0  1026.0  188.0   98.0  1001.0   92.0  ...   \n\n      240     241     242  243  244  245  246  247  248  249  \n0  5789.0  2907.0  1447.0    0    0    0    0    0    0    0  \n1  5789.0  2908.0  1443.0    0    0    0    0    0    0    0  \n2  5789.0  2910.0  1440.0    0    0    0    0    0    0    0  \n3  5789.0  2912.0  1440.0    0    0    0    0    0    0    0  \n4  5791.0  2915.0  1442.0    0    0    0    0    0    0    0  \n\n[5 rows x 250 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>240</th>\n      <th>241</th>\n      <th>242</th>\n      <th>243</th>\n      <th>244</th>\n      <th>245</th>\n      <th>246</th>\n      <th>247</th>\n      <th>248</th>\n      <th>249</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>87.0</td>\n      <td>975.0</td>\n      <td>-287.0</td>\n      <td>11.0</td>\n      <td>1001.0</td>\n      <td>163.0</td>\n      <td>95.0</td>\n      <td>975.0</td>\n      <td>152.0</td>\n      <td>...</td>\n      <td>5789.0</td>\n      <td>2907.0</td>\n      <td>1447.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>33</td>\n      <td>124.0</td>\n      <td>978.0</td>\n      <td>-389.0</td>\n      <td>-7.0</td>\n      <td>1014.0</td>\n      <td>199.0</td>\n      <td>124.0</td>\n      <td>968.0</td>\n      <td>123.0</td>\n      <td>...</td>\n      <td>5789.0</td>\n      <td>2908.0</td>\n      <td>1443.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>102.0</td>\n      <td>996.0</td>\n      <td>-440.0</td>\n      <td>-49.0</td>\n      <td>1024.0</td>\n      <td>193.0</td>\n      <td>127.0</td>\n      <td>1001.0</td>\n      <td>113.0</td>\n      <td>...</td>\n      <td>5789.0</td>\n      <td>2910.0</td>\n      <td>1440.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>59.0</td>\n      <td>861.0</td>\n      <td>-384.0</td>\n      <td>-9.0</td>\n      <td>1023.0</td>\n      <td>202.0</td>\n      <td>110.0</td>\n      <td>1007.0</td>\n      <td>106.0</td>\n      <td>...</td>\n      <td>5789.0</td>\n      <td>2912.0</td>\n      <td>1440.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>133</td>\n      <td>119.0</td>\n      <td>946.0</td>\n      <td>-426.0</td>\n      <td>-22.0</td>\n      <td>1026.0</td>\n      <td>188.0</td>\n      <td>98.0</td>\n      <td>1001.0</td>\n      <td>92.0</td>\n      <td>...</td>\n      <td>5791.0</td>\n      <td>2915.0</td>\n      <td>1442.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 250 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.shape","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"(51116, 250)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Separate the predictor variables (X) and target variables (y)."},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df1.iloc[:,0:243]\nX.head()","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"   0      1      2      3     4       5      6      7       8      9    ...  \\\n0    0   87.0  975.0 -287.0  11.0  1001.0  163.0   95.0   975.0  152.0  ...   \n1   33  124.0  978.0 -389.0  -7.0  1014.0  199.0  124.0   968.0  123.0  ...   \n2   67  102.0  996.0 -440.0 -49.0  1024.0  193.0  127.0  1001.0  113.0  ...   \n3  100   59.0  861.0 -384.0  -9.0  1023.0  202.0  110.0  1007.0  106.0  ...   \n4  133  119.0  946.0 -426.0 -22.0  1026.0  188.0   98.0  1001.0   92.0  ...   \n\n      233     234     235     236     237     238     239     240     241  \\\n0  1265.0  5858.0  2707.0  1134.0  6294.0  2663.0  1533.0  5789.0  2907.0   \n1  1267.0  5905.0  2708.0  1155.0  6294.0  2664.0  1532.0  5789.0  2908.0   \n2  1268.0  5948.0  2710.0  1175.0  6295.0  2664.0  1531.0  5789.0  2910.0   \n3  1266.0  5986.0  2711.0  1192.0  6296.0  2664.0  1530.0  5789.0  2912.0   \n4  1263.0  6018.0  2712.0  1205.0  6299.0  2664.0  1529.0  5791.0  2915.0   \n\n      242  \n0  1447.0  \n1  1443.0  \n2  1440.0  \n3  1440.0  \n4  1442.0  \n\n[5 rows x 243 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>233</th>\n      <th>234</th>\n      <th>235</th>\n      <th>236</th>\n      <th>237</th>\n      <th>238</th>\n      <th>239</th>\n      <th>240</th>\n      <th>241</th>\n      <th>242</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>87.0</td>\n      <td>975.0</td>\n      <td>-287.0</td>\n      <td>11.0</td>\n      <td>1001.0</td>\n      <td>163.0</td>\n      <td>95.0</td>\n      <td>975.0</td>\n      <td>152.0</td>\n      <td>...</td>\n      <td>1265.0</td>\n      <td>5858.0</td>\n      <td>2707.0</td>\n      <td>1134.0</td>\n      <td>6294.0</td>\n      <td>2663.0</td>\n      <td>1533.0</td>\n      <td>5789.0</td>\n      <td>2907.0</td>\n      <td>1447.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>33</td>\n      <td>124.0</td>\n      <td>978.0</td>\n      <td>-389.0</td>\n      <td>-7.0</td>\n      <td>1014.0</td>\n      <td>199.0</td>\n      <td>124.0</td>\n      <td>968.0</td>\n      <td>123.0</td>\n      <td>...</td>\n      <td>1267.0</td>\n      <td>5905.0</td>\n      <td>2708.0</td>\n      <td>1155.0</td>\n      <td>6294.0</td>\n      <td>2664.0</td>\n      <td>1532.0</td>\n      <td>5789.0</td>\n      <td>2908.0</td>\n      <td>1443.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>102.0</td>\n      <td>996.0</td>\n      <td>-440.0</td>\n      <td>-49.0</td>\n      <td>1024.0</td>\n      <td>193.0</td>\n      <td>127.0</td>\n      <td>1001.0</td>\n      <td>113.0</td>\n      <td>...</td>\n      <td>1268.0</td>\n      <td>5948.0</td>\n      <td>2710.0</td>\n      <td>1175.0</td>\n      <td>6295.0</td>\n      <td>2664.0</td>\n      <td>1531.0</td>\n      <td>5789.0</td>\n      <td>2910.0</td>\n      <td>1440.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>59.0</td>\n      <td>861.0</td>\n      <td>-384.0</td>\n      <td>-9.0</td>\n      <td>1023.0</td>\n      <td>202.0</td>\n      <td>110.0</td>\n      <td>1007.0</td>\n      <td>106.0</td>\n      <td>...</td>\n      <td>1266.0</td>\n      <td>5986.0</td>\n      <td>2711.0</td>\n      <td>1192.0</td>\n      <td>6296.0</td>\n      <td>2664.0</td>\n      <td>1530.0</td>\n      <td>5789.0</td>\n      <td>2912.0</td>\n      <td>1440.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>133</td>\n      <td>119.0</td>\n      <td>946.0</td>\n      <td>-426.0</td>\n      <td>-22.0</td>\n      <td>1026.0</td>\n      <td>188.0</td>\n      <td>98.0</td>\n      <td>1001.0</td>\n      <td>92.0</td>\n      <td>...</td>\n      <td>1263.0</td>\n      <td>6018.0</td>\n      <td>2712.0</td>\n      <td>1205.0</td>\n      <td>6299.0</td>\n      <td>2664.0</td>\n      <td>1529.0</td>\n      <td>5791.0</td>\n      <td>2915.0</td>\n      <td>1442.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 243 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df1.iloc[:,243:250]\ny.head()","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"   243  244  245  246  247  248  249\n0    0    0    0    0    0    0    0\n1    0    0    0    0    0    0    0\n2    0    0    0    0    0    0    0\n3    0    0    0    0    0    0    0\n4    0    0    0    0    0    0    0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>243</th>\n      <th>244</th>\n      <th>245</th>\n      <th>246</th>\n      <th>247</th>\n      <th>248</th>\n      <th>249</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Check if the dataset has empty cells."},{"metadata":{"trusted":true},"cell_type":"code","source":"X.isna().sum()","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"0        0\n1      911\n2      911\n3      911\n4      466\n      ... \n238    409\n239    409\n240    409\n241    409\n242    409\nLength: 243, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"It looks like there are a lot of empty cells in the predictor variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"y.isna().sum()","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"243    0\n244    0\n245    0\n246    0\n247    0\n248    0\n249    0\ndtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"There is no empty cells in the target variables."},{"metadata":{},"cell_type":"markdown","source":"Calculate the percentage of empty cells in each column in the predictor variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"p_m =pd.DataFrame(X.isnull().sum() * 100 / len(X)).rename(columns={0:\"Percentage\"})\np_m=p_m.sort_values(by=\"Percentage\",ascending=False)\np_m","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"     Percentage\n36    99.998044\n35    99.998044\n34    99.998044\n219   99.998044\n220   99.998044\n..          ...\n203    0.000000\n202    0.000000\n201    0.000000\n200    0.000000\n0      0.000000\n\n[243 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36</th>\n      <td>99.998044</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>99.998044</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>99.998044</td>\n    </tr>\n    <tr>\n      <th>219</th>\n      <td>99.998044</td>\n    </tr>\n    <tr>\n      <th>220</th>\n      <td>99.998044</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>203</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>200</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>243 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"It appears that some columns have as much as 99.99% of empty cells. These columns will be discarded. We will discard columns with more than 20% of missing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"p_m=p_m[p_m[\"Percentage\"]<=20]\np_m","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"     Percentage\n20     4.067220\n21     4.067220\n19     4.067220\n15     2.369121\n13     2.369121\n..          ...\n203    0.000000\n202    0.000000\n201    0.000000\n200    0.000000\n0      0.000000\n\n[237 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>4.067220</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>4.067220</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>4.067220</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2.369121</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2.369121</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>203</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>200</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>237 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"After discarding columns with more than 20% of missing values, we have 237 columns in the predictor variables X."},{"metadata":{},"cell_type":"markdown","source":"Select those columns with at most 20% missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"X=X.iloc[:,p_m.index.tolist()]\nX.head()","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"     20    21     19     15     13      14     143   139    140    141  ...  \\\n0  973.0 -41.0  209.0   99.0  249.0  1008.0  411.0 -72.0  682.0 -778.0  ...   \n1  956.0 -93.0  245.0   97.0  272.0   963.0  409.0 -72.0  684.0 -770.0  ...   \n2  929.0 -69.0  277.0  116.0  213.0  1017.0  410.0 -72.0  684.0 -770.0  ...   \n3  958.0 -76.0  245.0  120.0  234.0  1028.0  411.0 -69.0  673.0 -773.0  ...   \n4  968.0 -20.0  231.0  189.0  191.0   991.0  411.0 -62.0  684.0 -787.0  ...   \n\n   196  197  206  205  204  203  202  201  200  0    \n0    0    0    0    0    0    0    0    0    0    0  \n1    0    0    0    0    0    0    0    0    0   33  \n2    0    0    0    0    0    0    0    0    0   67  \n3    0    0    0    0    0    0    0    0    0  100  \n4    0    0    0    0    0    0    0    0    0  133  \n\n[5 rows x 237 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>20</th>\n      <th>21</th>\n      <th>19</th>\n      <th>15</th>\n      <th>13</th>\n      <th>14</th>\n      <th>143</th>\n      <th>139</th>\n      <th>140</th>\n      <th>141</th>\n      <th>...</th>\n      <th>196</th>\n      <th>197</th>\n      <th>206</th>\n      <th>205</th>\n      <th>204</th>\n      <th>203</th>\n      <th>202</th>\n      <th>201</th>\n      <th>200</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>973.0</td>\n      <td>-41.0</td>\n      <td>209.0</td>\n      <td>99.0</td>\n      <td>249.0</td>\n      <td>1008.0</td>\n      <td>411.0</td>\n      <td>-72.0</td>\n      <td>682.0</td>\n      <td>-778.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>956.0</td>\n      <td>-93.0</td>\n      <td>245.0</td>\n      <td>97.0</td>\n      <td>272.0</td>\n      <td>963.0</td>\n      <td>409.0</td>\n      <td>-72.0</td>\n      <td>684.0</td>\n      <td>-770.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>929.0</td>\n      <td>-69.0</td>\n      <td>277.0</td>\n      <td>116.0</td>\n      <td>213.0</td>\n      <td>1017.0</td>\n      <td>410.0</td>\n      <td>-72.0</td>\n      <td>684.0</td>\n      <td>-770.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>958.0</td>\n      <td>-76.0</td>\n      <td>245.0</td>\n      <td>120.0</td>\n      <td>234.0</td>\n      <td>1028.0</td>\n      <td>411.0</td>\n      <td>-69.0</td>\n      <td>673.0</td>\n      <td>-773.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>968.0</td>\n      <td>-20.0</td>\n      <td>231.0</td>\n      <td>189.0</td>\n      <td>191.0</td>\n      <td>991.0</td>\n      <td>411.0</td>\n      <td>-62.0</td>\n      <td>684.0</td>\n      <td>-787.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>133</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 237 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Fill those empty cells with the median of the respective column."},{"metadata":{"trusted":true},"cell_type":"code","source":"X=X.fillna(X.median())","execution_count":30,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verified that there is no more missing values in the predictor variables X."},{"metadata":{"trusted":true},"cell_type":"code","source":"null=pd.DataFrame(X.isna().any()).rename(columns={0:\"Null\"})\nnull[null[\"Null\"]==True]","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"Empty DataFrame\nColumns: [Null]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Null</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"All empty cells have been filled."},{"metadata":{},"cell_type":"markdown","source":"For this task, we will build a model to predict the locomotion: Stand, Walk, Sit or Lie. That is the first column in the target variables y."},{"metadata":{"trusted":true},"cell_type":"code","source":"y1=pd.DataFrame(y.iloc[:,0]).rename(columns={243:\"locomotion\"})\ny1","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"       locomotion\n0               0\n1               0\n2               0\n3               0\n4               0\n...           ...\n51111           0\n51112           0\n51113           0\n51114           0\n51115           0\n\n[51116 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>locomotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>51111</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>51112</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>51113</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>51114</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>51115</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>51116 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nnp.unique(y1)","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"array([0, 1, 2, 4, 5])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Feature extraction."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nscaler=preprocessing.StandardScaler()\nX=scaler.fit_transform(X)\nX=pd.DataFrame(X)\nX.head()","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"        0         1         2         3         4         5         6    \\\n0  0.290387  0.493052 -0.115890  0.205712 -0.433329  0.590983 -0.045576   \n1  0.224739  0.265039  0.001353  0.200330 -0.356390  0.508880 -0.645468   \n2  0.120474  0.370276  0.105569  0.251459 -0.553755  0.607403 -0.345522   \n3  0.232462  0.339582  0.001353  0.262223 -0.483506  0.627473 -0.045576   \n4  0.271079  0.585134 -0.044241  0.447903 -0.627348  0.559966 -0.045576   \n\n        7         8         9    ...       227       228       229       230  \\\n0 -0.189098  0.018619 -0.408523  ... -0.056035 -0.024634 -0.020273 -0.019283   \n1 -0.189098  0.026657 -0.384108  ... -0.056035 -0.024634 -0.020273 -0.019283   \n2 -0.189098  0.026657 -0.384108  ... -0.056035 -0.024634 -0.020273 -0.019283   \n3 -0.156555 -0.017552 -0.393263  ... -0.056035 -0.024634 -0.020273 -0.019283   \n4 -0.080623  0.026657 -0.435990  ... -0.056035 -0.024634 -0.020273 -0.019283   \n\n        231       232       233  234  235       236  \n0 -0.158326 -0.021674 -0.023826  0.0  0.0 -1.732017  \n1 -0.158326 -0.021674 -0.023826  0.0  0.0 -1.731950  \n2 -0.158326 -0.021674 -0.023826  0.0  0.0 -1.731881  \n3 -0.158326 -0.021674 -0.023826  0.0  0.0 -1.731814  \n4 -0.158326 -0.021674 -0.023826  0.0  0.0 -1.731747  \n\n[5 rows x 237 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>227</th>\n      <th>228</th>\n      <th>229</th>\n      <th>230</th>\n      <th>231</th>\n      <th>232</th>\n      <th>233</th>\n      <th>234</th>\n      <th>235</th>\n      <th>236</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.290387</td>\n      <td>0.493052</td>\n      <td>-0.115890</td>\n      <td>0.205712</td>\n      <td>-0.433329</td>\n      <td>0.590983</td>\n      <td>-0.045576</td>\n      <td>-0.189098</td>\n      <td>0.018619</td>\n      <td>-0.408523</td>\n      <td>...</td>\n      <td>-0.056035</td>\n      <td>-0.024634</td>\n      <td>-0.020273</td>\n      <td>-0.019283</td>\n      <td>-0.158326</td>\n      <td>-0.021674</td>\n      <td>-0.023826</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.732017</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.224739</td>\n      <td>0.265039</td>\n      <td>0.001353</td>\n      <td>0.200330</td>\n      <td>-0.356390</td>\n      <td>0.508880</td>\n      <td>-0.645468</td>\n      <td>-0.189098</td>\n      <td>0.026657</td>\n      <td>-0.384108</td>\n      <td>...</td>\n      <td>-0.056035</td>\n      <td>-0.024634</td>\n      <td>-0.020273</td>\n      <td>-0.019283</td>\n      <td>-0.158326</td>\n      <td>-0.021674</td>\n      <td>-0.023826</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.731950</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.120474</td>\n      <td>0.370276</td>\n      <td>0.105569</td>\n      <td>0.251459</td>\n      <td>-0.553755</td>\n      <td>0.607403</td>\n      <td>-0.345522</td>\n      <td>-0.189098</td>\n      <td>0.026657</td>\n      <td>-0.384108</td>\n      <td>...</td>\n      <td>-0.056035</td>\n      <td>-0.024634</td>\n      <td>-0.020273</td>\n      <td>-0.019283</td>\n      <td>-0.158326</td>\n      <td>-0.021674</td>\n      <td>-0.023826</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.731881</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.232462</td>\n      <td>0.339582</td>\n      <td>0.001353</td>\n      <td>0.262223</td>\n      <td>-0.483506</td>\n      <td>0.627473</td>\n      <td>-0.045576</td>\n      <td>-0.156555</td>\n      <td>-0.017552</td>\n      <td>-0.393263</td>\n      <td>...</td>\n      <td>-0.056035</td>\n      <td>-0.024634</td>\n      <td>-0.020273</td>\n      <td>-0.019283</td>\n      <td>-0.158326</td>\n      <td>-0.021674</td>\n      <td>-0.023826</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.731814</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.271079</td>\n      <td>0.585134</td>\n      <td>-0.044241</td>\n      <td>0.447903</td>\n      <td>-0.627348</td>\n      <td>0.559966</td>\n      <td>-0.045576</td>\n      <td>-0.080623</td>\n      <td>0.026657</td>\n      <td>-0.435990</td>\n      <td>...</td>\n      <td>-0.056035</td>\n      <td>-0.024634</td>\n      <td>-0.020273</td>\n      <td>-0.019283</td>\n      <td>-0.158326</td>\n      <td>-0.021674</td>\n      <td>-0.023826</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.731747</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 237 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA, IncrementalPCA\n\nipca = IncrementalPCA(n_components=30,whiten=True)\nX=ipca.fit_transform(X)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=pd.DataFrame(X)\nX","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"             0         1         2         3         4         5         6   \\\n0     -0.779637 -0.478474  0.635114  1.090687 -0.255061 -1.231526  0.308716   \n1     -0.776115 -0.493976  0.653046  1.127359 -0.228167 -1.325151 -0.062817   \n2     -0.766890 -0.416995  0.584813  1.148440 -0.254395 -1.278737 -0.426898   \n3     -0.776255 -0.442681  0.643475  1.159379 -0.272868 -1.333967 -0.416260   \n4     -0.770985 -0.442353  0.673203  1.066249 -0.271848 -1.307775 -0.385441   \n...         ...       ...       ...       ...       ...       ...       ...   \n51111 -0.282918 -0.334041  0.058231  0.151783  0.058806 -0.165540  0.031032   \n51112 -0.282916 -0.334039  0.058229  0.151782  0.058805 -0.165539  0.031031   \n51113 -0.282915 -0.334036  0.058227  0.151781  0.058804 -0.165538  0.031030   \n51114 -0.282914 -0.334034  0.058225  0.151781  0.058803 -0.165537  0.031030   \n51115 -0.282912 -0.334031  0.058223  0.151780  0.058803 -0.165537  0.031029   \n\n             7         8         9   ...        20        21        22  \\\n0     -1.359427 -0.128528  0.105931  ...  1.007063  0.521752  0.060881   \n1     -1.399275  0.053751 -0.021489  ...  1.067392  0.577343 -0.017322   \n2     -1.380744  0.067258  0.047619  ...  0.983196  0.226752  0.091084   \n3     -1.423296 -0.232984  0.035836  ...  1.063633 -0.078714  0.009909   \n4     -1.337149  0.262240  0.053162  ...  0.877758 -0.170506  0.103188   \n...         ...       ...       ...  ...       ...       ...       ...   \n51111  0.230290  0.095166 -0.006590  ...  0.207980  0.004780  0.047068   \n51112  0.230293  0.095166 -0.006590  ...  0.207979  0.004781  0.047070   \n51113  0.230296  0.095165 -0.006590  ...  0.207978  0.004782  0.047073   \n51114  0.230299  0.095165 -0.006590  ...  0.207977  0.004783  0.047075   \n51115  0.230302  0.095165 -0.006590  ...  0.207976  0.004783  0.047077   \n\n             23        24        25        26        27        28        29  \n0      1.090612 -0.072613 -0.004863 -0.050337  0.936883  0.045683  0.010402  \n1      1.366246 -0.411713 -0.069551  0.047967  0.556898 -0.134072  0.365830  \n2      1.507945 -0.030696 -0.237545 -0.129532  0.374661 -0.247567  0.284645  \n3      1.220695  0.086734  0.026009 -0.413850  0.109655  0.417410 -0.030357  \n4      1.103431 -0.060818 -0.110982 -0.224408  0.126037  0.152301 -0.220722  \n...         ...       ...       ...       ...       ...       ...       ...  \n51111 -0.037535  0.238295 -0.214540  0.018184 -0.027917  0.061008 -0.411142  \n51112 -0.037535  0.238296 -0.214541  0.018184 -0.027918  0.061006 -0.411144  \n51113 -0.037535  0.238298 -0.214542  0.018184 -0.027918  0.061005 -0.411145  \n51114 -0.037535  0.238299 -0.214543  0.018184 -0.027919  0.061004 -0.411146  \n51115 -0.037535  0.238301 -0.214545  0.018184 -0.027919  0.061003 -0.411148  \n\n[51116 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.779637</td>\n      <td>-0.478474</td>\n      <td>0.635114</td>\n      <td>1.090687</td>\n      <td>-0.255061</td>\n      <td>-1.231526</td>\n      <td>0.308716</td>\n      <td>-1.359427</td>\n      <td>-0.128528</td>\n      <td>0.105931</td>\n      <td>...</td>\n      <td>1.007063</td>\n      <td>0.521752</td>\n      <td>0.060881</td>\n      <td>1.090612</td>\n      <td>-0.072613</td>\n      <td>-0.004863</td>\n      <td>-0.050337</td>\n      <td>0.936883</td>\n      <td>0.045683</td>\n      <td>0.010402</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.776115</td>\n      <td>-0.493976</td>\n      <td>0.653046</td>\n      <td>1.127359</td>\n      <td>-0.228167</td>\n      <td>-1.325151</td>\n      <td>-0.062817</td>\n      <td>-1.399275</td>\n      <td>0.053751</td>\n      <td>-0.021489</td>\n      <td>...</td>\n      <td>1.067392</td>\n      <td>0.577343</td>\n      <td>-0.017322</td>\n      <td>1.366246</td>\n      <td>-0.411713</td>\n      <td>-0.069551</td>\n      <td>0.047967</td>\n      <td>0.556898</td>\n      <td>-0.134072</td>\n      <td>0.365830</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.766890</td>\n      <td>-0.416995</td>\n      <td>0.584813</td>\n      <td>1.148440</td>\n      <td>-0.254395</td>\n      <td>-1.278737</td>\n      <td>-0.426898</td>\n      <td>-1.380744</td>\n      <td>0.067258</td>\n      <td>0.047619</td>\n      <td>...</td>\n      <td>0.983196</td>\n      <td>0.226752</td>\n      <td>0.091084</td>\n      <td>1.507945</td>\n      <td>-0.030696</td>\n      <td>-0.237545</td>\n      <td>-0.129532</td>\n      <td>0.374661</td>\n      <td>-0.247567</td>\n      <td>0.284645</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.776255</td>\n      <td>-0.442681</td>\n      <td>0.643475</td>\n      <td>1.159379</td>\n      <td>-0.272868</td>\n      <td>-1.333967</td>\n      <td>-0.416260</td>\n      <td>-1.423296</td>\n      <td>-0.232984</td>\n      <td>0.035836</td>\n      <td>...</td>\n      <td>1.063633</td>\n      <td>-0.078714</td>\n      <td>0.009909</td>\n      <td>1.220695</td>\n      <td>0.086734</td>\n      <td>0.026009</td>\n      <td>-0.413850</td>\n      <td>0.109655</td>\n      <td>0.417410</td>\n      <td>-0.030357</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.770985</td>\n      <td>-0.442353</td>\n      <td>0.673203</td>\n      <td>1.066249</td>\n      <td>-0.271848</td>\n      <td>-1.307775</td>\n      <td>-0.385441</td>\n      <td>-1.337149</td>\n      <td>0.262240</td>\n      <td>0.053162</td>\n      <td>...</td>\n      <td>0.877758</td>\n      <td>-0.170506</td>\n      <td>0.103188</td>\n      <td>1.103431</td>\n      <td>-0.060818</td>\n      <td>-0.110982</td>\n      <td>-0.224408</td>\n      <td>0.126037</td>\n      <td>0.152301</td>\n      <td>-0.220722</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>51111</th>\n      <td>-0.282918</td>\n      <td>-0.334041</td>\n      <td>0.058231</td>\n      <td>0.151783</td>\n      <td>0.058806</td>\n      <td>-0.165540</td>\n      <td>0.031032</td>\n      <td>0.230290</td>\n      <td>0.095166</td>\n      <td>-0.006590</td>\n      <td>...</td>\n      <td>0.207980</td>\n      <td>0.004780</td>\n      <td>0.047068</td>\n      <td>-0.037535</td>\n      <td>0.238295</td>\n      <td>-0.214540</td>\n      <td>0.018184</td>\n      <td>-0.027917</td>\n      <td>0.061008</td>\n      <td>-0.411142</td>\n    </tr>\n    <tr>\n      <th>51112</th>\n      <td>-0.282916</td>\n      <td>-0.334039</td>\n      <td>0.058229</td>\n      <td>0.151782</td>\n      <td>0.058805</td>\n      <td>-0.165539</td>\n      <td>0.031031</td>\n      <td>0.230293</td>\n      <td>0.095166</td>\n      <td>-0.006590</td>\n      <td>...</td>\n      <td>0.207979</td>\n      <td>0.004781</td>\n      <td>0.047070</td>\n      <td>-0.037535</td>\n      <td>0.238296</td>\n      <td>-0.214541</td>\n      <td>0.018184</td>\n      <td>-0.027918</td>\n      <td>0.061006</td>\n      <td>-0.411144</td>\n    </tr>\n    <tr>\n      <th>51113</th>\n      <td>-0.282915</td>\n      <td>-0.334036</td>\n      <td>0.058227</td>\n      <td>0.151781</td>\n      <td>0.058804</td>\n      <td>-0.165538</td>\n      <td>0.031030</td>\n      <td>0.230296</td>\n      <td>0.095165</td>\n      <td>-0.006590</td>\n      <td>...</td>\n      <td>0.207978</td>\n      <td>0.004782</td>\n      <td>0.047073</td>\n      <td>-0.037535</td>\n      <td>0.238298</td>\n      <td>-0.214542</td>\n      <td>0.018184</td>\n      <td>-0.027918</td>\n      <td>0.061005</td>\n      <td>-0.411145</td>\n    </tr>\n    <tr>\n      <th>51114</th>\n      <td>-0.282914</td>\n      <td>-0.334034</td>\n      <td>0.058225</td>\n      <td>0.151781</td>\n      <td>0.058803</td>\n      <td>-0.165537</td>\n      <td>0.031030</td>\n      <td>0.230299</td>\n      <td>0.095165</td>\n      <td>-0.006590</td>\n      <td>...</td>\n      <td>0.207977</td>\n      <td>0.004783</td>\n      <td>0.047075</td>\n      <td>-0.037535</td>\n      <td>0.238299</td>\n      <td>-0.214543</td>\n      <td>0.018184</td>\n      <td>-0.027919</td>\n      <td>0.061004</td>\n      <td>-0.411146</td>\n    </tr>\n    <tr>\n      <th>51115</th>\n      <td>-0.282912</td>\n      <td>-0.334031</td>\n      <td>0.058223</td>\n      <td>0.151780</td>\n      <td>0.058803</td>\n      <td>-0.165537</td>\n      <td>0.031029</td>\n      <td>0.230302</td>\n      <td>0.095165</td>\n      <td>-0.006590</td>\n      <td>...</td>\n      <td>0.207976</td>\n      <td>0.004783</td>\n      <td>0.047077</td>\n      <td>-0.037535</td>\n      <td>0.238301</td>\n      <td>-0.214545</td>\n      <td>0.018184</td>\n      <td>-0.027919</td>\n      <td>0.061003</td>\n      <td>-0.411148</td>\n    </tr>\n  </tbody>\n</table>\n<p>51116 rows × 30 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Check for class imbalance."},{"metadata":{"trusted":true},"cell_type":"code","source":"locomotion=pd.concat([X,y1],axis=1)\n(locomotion.groupby(\"locomotion\").count().T)/len(locomotion)","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"locomotion         0         1         2         4         5\n0           0.266238  0.437828  0.128003  0.145864  0.022067\n1           0.266238  0.437828  0.128003  0.145864  0.022067\n2           0.266238  0.437828  0.128003  0.145864  0.022067\n3           0.266238  0.437828  0.128003  0.145864  0.022067\n4           0.266238  0.437828  0.128003  0.145864  0.022067\n5           0.266238  0.437828  0.128003  0.145864  0.022067\n6           0.266238  0.437828  0.128003  0.145864  0.022067\n7           0.266238  0.437828  0.128003  0.145864  0.022067\n8           0.266238  0.437828  0.128003  0.145864  0.022067\n9           0.266238  0.437828  0.128003  0.145864  0.022067\n10          0.266238  0.437828  0.128003  0.145864  0.022067\n11          0.266238  0.437828  0.128003  0.145864  0.022067\n12          0.266238  0.437828  0.128003  0.145864  0.022067\n13          0.266238  0.437828  0.128003  0.145864  0.022067\n14          0.266238  0.437828  0.128003  0.145864  0.022067\n15          0.266238  0.437828  0.128003  0.145864  0.022067\n16          0.266238  0.437828  0.128003  0.145864  0.022067\n17          0.266238  0.437828  0.128003  0.145864  0.022067\n18          0.266238  0.437828  0.128003  0.145864  0.022067\n19          0.266238  0.437828  0.128003  0.145864  0.022067\n20          0.266238  0.437828  0.128003  0.145864  0.022067\n21          0.266238  0.437828  0.128003  0.145864  0.022067\n22          0.266238  0.437828  0.128003  0.145864  0.022067\n23          0.266238  0.437828  0.128003  0.145864  0.022067\n24          0.266238  0.437828  0.128003  0.145864  0.022067\n25          0.266238  0.437828  0.128003  0.145864  0.022067\n26          0.266238  0.437828  0.128003  0.145864  0.022067\n27          0.266238  0.437828  0.128003  0.145864  0.022067\n28          0.266238  0.437828  0.128003  0.145864  0.022067\n29          0.266238  0.437828  0.128003  0.145864  0.022067","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>locomotion</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.266238</td>\n      <td>0.437828</td>\n      <td>0.128003</td>\n      <td>0.145864</td>\n      <td>0.022067</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The classes that represent the motions are not evenly distributed. Almost 44% of the data belongs to Class 1, while only slightly more than 2% belongs to Class 5. We are going to oversample the minority classes (Classes 2,4,5): duplicate Classes 2 and 4 by 2 times and Class 5 by 10 times.\n\nTo ensure that test data consists of strictly data that the model has not seen during the training process, we will split the data between oversampling. In other words, we will only oversample the minority classes in the train data."},{"metadata":{"trusted":true},"cell_type":"code","source":"locomotion_train=locomotion.sample(frac=0.9)\nlocomotion_train.shape","execution_count":56,"outputs":[{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"(46004, 31)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(51116*0.9)\nprint(51116*0.1)","execution_count":57,"outputs":[{"output_type":"stream","text":"46004.4\n5111.6\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"L_0=locomotion_train[locomotion_train[\"locomotion\"]==0]\nL_1=locomotion_train[locomotion_train[\"locomotion\"]==1]\nL_2=locomotion_train[locomotion_train[\"locomotion\"]==2]\nL_4=locomotion_train[locomotion_train[\"locomotion\"]==4]\n\n\nL_5=locomotion_train[locomotion_train[\"locomotion\"]==5]\nL_5=pd.concat([L_5]*5,axis=0)","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"locomotion_train=pd.concat([L_0,L_1,L_2,L_4,L_5],axis=0)\nlocomotion_train.shape","execution_count":59,"outputs":[{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"(50056, 31)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"(locomotion_train.groupby(\"locomotion\").count().T)/len(locomotion_train)","execution_count":60,"outputs":[{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"locomotion         0        1         2        4         5\n0           0.245325  0.40149  0.118268  0.13373  0.101187\n1           0.245325  0.40149  0.118268  0.13373  0.101187\n2           0.245325  0.40149  0.118268  0.13373  0.101187\n3           0.245325  0.40149  0.118268  0.13373  0.101187\n4           0.245325  0.40149  0.118268  0.13373  0.101187\n5           0.245325  0.40149  0.118268  0.13373  0.101187\n6           0.245325  0.40149  0.118268  0.13373  0.101187\n7           0.245325  0.40149  0.118268  0.13373  0.101187\n8           0.245325  0.40149  0.118268  0.13373  0.101187\n9           0.245325  0.40149  0.118268  0.13373  0.101187\n10          0.245325  0.40149  0.118268  0.13373  0.101187\n11          0.245325  0.40149  0.118268  0.13373  0.101187\n12          0.245325  0.40149  0.118268  0.13373  0.101187\n13          0.245325  0.40149  0.118268  0.13373  0.101187\n14          0.245325  0.40149  0.118268  0.13373  0.101187\n15          0.245325  0.40149  0.118268  0.13373  0.101187\n16          0.245325  0.40149  0.118268  0.13373  0.101187\n17          0.245325  0.40149  0.118268  0.13373  0.101187\n18          0.245325  0.40149  0.118268  0.13373  0.101187\n19          0.245325  0.40149  0.118268  0.13373  0.101187\n20          0.245325  0.40149  0.118268  0.13373  0.101187\n21          0.245325  0.40149  0.118268  0.13373  0.101187\n22          0.245325  0.40149  0.118268  0.13373  0.101187\n23          0.245325  0.40149  0.118268  0.13373  0.101187\n24          0.245325  0.40149  0.118268  0.13373  0.101187\n25          0.245325  0.40149  0.118268  0.13373  0.101187\n26          0.245325  0.40149  0.118268  0.13373  0.101187\n27          0.245325  0.40149  0.118268  0.13373  0.101187\n28          0.245325  0.40149  0.118268  0.13373  0.101187\n29          0.245325  0.40149  0.118268  0.13373  0.101187","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>locomotion</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.245325</td>\n      <td>0.40149</td>\n      <td>0.118268</td>\n      <td>0.13373</td>\n      <td>0.101187</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"locomotion_test=locomotion.drop(locomotion.index[locomotion_train.index.tolist()])\nlocomotion_test.shape","execution_count":61,"outputs":[{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"(5112, 31)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"(locomotion_test.groupby(\"locomotion\").count().T)/len(locomotion_test)","execution_count":62,"outputs":[{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"locomotion         0         1        2         4         5\n0           0.259977  0.446596  0.12187  0.149061  0.022496\n1           0.259977  0.446596  0.12187  0.149061  0.022496\n2           0.259977  0.446596  0.12187  0.149061  0.022496\n3           0.259977  0.446596  0.12187  0.149061  0.022496\n4           0.259977  0.446596  0.12187  0.149061  0.022496\n5           0.259977  0.446596  0.12187  0.149061  0.022496\n6           0.259977  0.446596  0.12187  0.149061  0.022496\n7           0.259977  0.446596  0.12187  0.149061  0.022496\n8           0.259977  0.446596  0.12187  0.149061  0.022496\n9           0.259977  0.446596  0.12187  0.149061  0.022496\n10          0.259977  0.446596  0.12187  0.149061  0.022496\n11          0.259977  0.446596  0.12187  0.149061  0.022496\n12          0.259977  0.446596  0.12187  0.149061  0.022496\n13          0.259977  0.446596  0.12187  0.149061  0.022496\n14          0.259977  0.446596  0.12187  0.149061  0.022496\n15          0.259977  0.446596  0.12187  0.149061  0.022496\n16          0.259977  0.446596  0.12187  0.149061  0.022496\n17          0.259977  0.446596  0.12187  0.149061  0.022496\n18          0.259977  0.446596  0.12187  0.149061  0.022496\n19          0.259977  0.446596  0.12187  0.149061  0.022496\n20          0.259977  0.446596  0.12187  0.149061  0.022496\n21          0.259977  0.446596  0.12187  0.149061  0.022496\n22          0.259977  0.446596  0.12187  0.149061  0.022496\n23          0.259977  0.446596  0.12187  0.149061  0.022496\n24          0.259977  0.446596  0.12187  0.149061  0.022496\n25          0.259977  0.446596  0.12187  0.149061  0.022496\n26          0.259977  0.446596  0.12187  0.149061  0.022496\n27          0.259977  0.446596  0.12187  0.149061  0.022496\n28          0.259977  0.446596  0.12187  0.149061  0.022496\n29          0.259977  0.446596  0.12187  0.149061  0.022496","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>locomotion</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.259977</td>\n      <td>0.446596</td>\n      <td>0.12187</td>\n      <td>0.149061</td>\n      <td>0.022496</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Because the dataset was split first and then only the train data was oversampled, although the proportions of the classes change in the train data, the proportions of classes in the test data remain the same."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=locomotion_train.drop([\"locomotion\"],axis=1)\ny_train=locomotion_train[[\"locomotion\"]]","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=locomotion_test.drop([\"locomotion\"],axis=1)\ny_test=locomotion_test[[\"locomotion\"]]","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nenc=OneHotEncoder(handle_unknown=\"ignore\")\ny_train=pd.DataFrame(enc.fit_transform(y_train).toarray())\ny_train","execution_count":65,"outputs":[{"output_type":"execute_result","execution_count":65,"data":{"text/plain":"         0    1    2    3    4\n0      1.0  0.0  0.0  0.0  0.0\n1      1.0  0.0  0.0  0.0  0.0\n2      1.0  0.0  0.0  0.0  0.0\n3      1.0  0.0  0.0  0.0  0.0\n4      1.0  0.0  0.0  0.0  0.0\n...    ...  ...  ...  ...  ...\n50051  0.0  0.0  0.0  0.0  1.0\n50052  0.0  0.0  0.0  0.0  1.0\n50053  0.0  0.0  0.0  0.0  1.0\n50054  0.0  0.0  0.0  0.0  1.0\n50055  0.0  0.0  0.0  0.0  1.0\n\n[50056 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>50051</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>50052</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>50053</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>50054</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>50055</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>50056 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=pd.DataFrame(enc.fit_transform(y_test).toarray())\ny_test","execution_count":66,"outputs":[{"output_type":"execute_result","execution_count":66,"data":{"text/plain":"        0    1    2    3    4\n0     1.0  0.0  0.0  0.0  0.0\n1     1.0  0.0  0.0  0.0  0.0\n2     1.0  0.0  0.0  0.0  0.0\n3     1.0  0.0  0.0  0.0  0.0\n4     1.0  0.0  0.0  0.0  0.0\n...   ...  ...  ...  ...  ...\n5107  1.0  0.0  0.0  0.0  0.0\n5108  1.0  0.0  0.0  0.0  0.0\n5109  1.0  0.0  0.0  0.0  0.0\n5110  1.0  0.0  0.0  0.0  0.0\n5111  1.0  0.0  0.0  0.0  0.0\n\n[5112 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5107</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5108</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5109</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5110</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5111</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5112 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the libraries\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam","execution_count":67,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"length=X_train.shape[1]\nnum_classes=y_test.shape[1]\n\ndef classification_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(length, activation='relu', input_shape=(length,)))\n    model.add(Dense(60, activation='relu'))\n    model.add(Dense(60, activation='relu'))\n    model.add(Dense(60, activation='relu'))\n    model.add(Dense(60, activation= 'relu'))\n    model.add(Dense(60, activation = 'relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    opt=Adam(lr=0.001)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=classification_model()\nmodel.fit(X_train,y_train,validation_data=(X_test, y_test),epochs=50, verbose=2)\nmodel.evaluate(X_test,y_test,verbose=0)","execution_count":70,"outputs":[{"output_type":"stream","text":"Epoch 1/50\n1565/1565 - 7s - loss: 0.3142 - accuracy: 0.8805 - val_loss: 0.2272 - val_accuracy: 0.9216\nEpoch 2/50\n1565/1565 - 6s - loss: 0.1667 - accuracy: 0.9384 - val_loss: 0.1613 - val_accuracy: 0.9419\nEpoch 3/50\n1565/1565 - 6s - loss: 0.1294 - accuracy: 0.9519 - val_loss: 0.1376 - val_accuracy: 0.9509\nEpoch 4/50\n1565/1565 - 6s - loss: 0.1083 - accuracy: 0.9607 - val_loss: 0.1413 - val_accuracy: 0.9499\nEpoch 5/50\n1565/1565 - 6s - loss: 0.0936 - accuracy: 0.9669 - val_loss: 0.1137 - val_accuracy: 0.9605\nEpoch 6/50\n1565/1565 - 6s - loss: 0.0814 - accuracy: 0.9711 - val_loss: 0.1244 - val_accuracy: 0.9587\nEpoch 7/50\n1565/1565 - 6s - loss: 0.0745 - accuracy: 0.9741 - val_loss: 0.1020 - val_accuracy: 0.9640\nEpoch 8/50\n1565/1565 - 6s - loss: 0.0670 - accuracy: 0.9766 - val_loss: 0.1052 - val_accuracy: 0.9630\nEpoch 9/50\n1565/1565 - 7s - loss: 0.0589 - accuracy: 0.9786 - val_loss: 0.1020 - val_accuracy: 0.9646\nEpoch 10/50\n1565/1565 - 8s - loss: 0.0560 - accuracy: 0.9799 - val_loss: 0.0872 - val_accuracy: 0.9709\nEpoch 11/50\n1565/1565 - 6s - loss: 0.0537 - accuracy: 0.9808 - val_loss: 0.0799 - val_accuracy: 0.9734\nEpoch 12/50\n1565/1565 - 6s - loss: 0.0484 - accuracy: 0.9830 - val_loss: 0.0775 - val_accuracy: 0.9736\nEpoch 13/50\n1565/1565 - 6s - loss: 0.0469 - accuracy: 0.9841 - val_loss: 0.0850 - val_accuracy: 0.9726\nEpoch 14/50\n1565/1565 - 7s - loss: 0.0451 - accuracy: 0.9839 - val_loss: 0.0800 - val_accuracy: 0.9722\nEpoch 15/50\n1565/1565 - 8s - loss: 0.0419 - accuracy: 0.9859 - val_loss: 0.0860 - val_accuracy: 0.9734\nEpoch 16/50\n1565/1565 - 9s - loss: 0.0402 - accuracy: 0.9856 - val_loss: 0.0880 - val_accuracy: 0.9720\nEpoch 17/50\n1565/1565 - 10s - loss: 0.0394 - accuracy: 0.9864 - val_loss: 0.0714 - val_accuracy: 0.9787\nEpoch 18/50\n1565/1565 - 10s - loss: 0.0362 - accuracy: 0.9876 - val_loss: 0.0743 - val_accuracy: 0.9777\nEpoch 19/50\n1565/1565 - 8s - loss: 0.0380 - accuracy: 0.9871 - val_loss: 0.0884 - val_accuracy: 0.9750\nEpoch 20/50\n1565/1565 - 10s - loss: 0.0339 - accuracy: 0.9881 - val_loss: 0.0729 - val_accuracy: 0.9783\nEpoch 21/50\n1565/1565 - 11s - loss: 0.0325 - accuracy: 0.9886 - val_loss: 0.0835 - val_accuracy: 0.9765\nEpoch 22/50\n1565/1565 - 12s - loss: 0.0332 - accuracy: 0.9883 - val_loss: 0.0735 - val_accuracy: 0.9779\nEpoch 23/50\n1565/1565 - 12s - loss: 0.0295 - accuracy: 0.9897 - val_loss: 0.0829 - val_accuracy: 0.9763\nEpoch 24/50\n1565/1565 - 10s - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.0750 - val_accuracy: 0.9781\nEpoch 25/50\n1565/1565 - 12s - loss: 0.0296 - accuracy: 0.9897 - val_loss: 0.0785 - val_accuracy: 0.9752\nEpoch 26/50\n1565/1565 - 9s - loss: 0.0297 - accuracy: 0.9897 - val_loss: 0.0725 - val_accuracy: 0.9777\nEpoch 27/50\n1565/1565 - 10s - loss: 0.0293 - accuracy: 0.9898 - val_loss: 0.0694 - val_accuracy: 0.9787\nEpoch 28/50\n1565/1565 - 10s - loss: 0.0273 - accuracy: 0.9907 - val_loss: 0.0695 - val_accuracy: 0.9791\nEpoch 29/50\n1565/1565 - 10s - loss: 0.0260 - accuracy: 0.9910 - val_loss: 0.0818 - val_accuracy: 0.9773\nEpoch 30/50\n1565/1565 - 9s - loss: 0.0263 - accuracy: 0.9906 - val_loss: 0.0613 - val_accuracy: 0.9820\nEpoch 31/50\n1565/1565 - 8s - loss: 0.0248 - accuracy: 0.9919 - val_loss: 0.0767 - val_accuracy: 0.9785\nEpoch 32/50\n1565/1565 - 8s - loss: 0.0258 - accuracy: 0.9911 - val_loss: 0.0715 - val_accuracy: 0.9795\nEpoch 33/50\n1565/1565 - 8s - loss: 0.0251 - accuracy: 0.9913 - val_loss: 0.0710 - val_accuracy: 0.9799\nEpoch 34/50\n1565/1565 - 8s - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.0891 - val_accuracy: 0.9759\nEpoch 35/50\n1565/1565 - 8s - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.0801 - val_accuracy: 0.9797\nEpoch 36/50\n1565/1565 - 8s - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.0799 - val_accuracy: 0.9816\nEpoch 37/50\n1565/1565 - 8s - loss: 0.0221 - accuracy: 0.9923 - val_loss: 0.0809 - val_accuracy: 0.9777\nEpoch 38/50\n1565/1565 - 8s - loss: 0.0204 - accuracy: 0.9927 - val_loss: 0.0773 - val_accuracy: 0.9814\nEpoch 39/50\n1565/1565 - 8s - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.0848 - val_accuracy: 0.9744\nEpoch 40/50\n1565/1565 - 8s - loss: 0.0202 - accuracy: 0.9927 - val_loss: 0.0726 - val_accuracy: 0.9814\nEpoch 41/50\n1565/1565 - 8s - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.0901 - val_accuracy: 0.9771\nEpoch 42/50\n1565/1565 - 8s - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.0923 - val_accuracy: 0.9793\nEpoch 43/50\n1565/1565 - 8s - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.0785 - val_accuracy: 0.9816\nEpoch 44/50\n1565/1565 - 8s - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.0786 - val_accuracy: 0.9777\nEpoch 45/50\n1565/1565 - 7s - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.0828 - val_accuracy: 0.9802\nEpoch 46/50\n1565/1565 - 7s - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.0885 - val_accuracy: 0.9799\nEpoch 47/50\n1565/1565 - 7s - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0909 - val_accuracy: 0.9767\nEpoch 48/50\n1565/1565 - 7s - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.0930 - val_accuracy: 0.9789\nEpoch 49/50\n1565/1565 - 7s - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0832 - val_accuracy: 0.9795\nEpoch 50/50\n1565/1565 - 7s - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.0775 - val_accuracy: 0.9826\n","name":"stdout"},{"output_type":"execute_result","execution_count":70,"data":{"text/plain":"[0.07750649005174637, 0.9825899600982666]"},"metadata":{}}]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}