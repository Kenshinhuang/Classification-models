{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1  2  3  4  5    6  7     8  9\n",
       "0  -0.33  0.69  0  1  1  0  0.8  0  0.88  N\n",
       "1  -0.33  0.94  1  0  1  0  0.8  1  0.31  O\n",
       "2  -0.33  0.50  1  0  0  0  1.0 -1  0.50  N\n",
       "3  -0.33  0.75  0  1  1  0  1.0 -1  0.38  N\n",
       "4  -0.33  0.67  1  1  0  0  0.8 -1  0.50  O\n",
       "..   ...   ... .. .. .. ..  ... ..   ... ..\n",
       "95 -1.00  0.67  1  0  0  0  1.0 -1  0.50  N\n",
       "96 -1.00  0.61  1  0  0  0  0.8  0  0.50  N\n",
       "97 -1.00  0.67  1  1  1  0  1.0 -1  0.31  N\n",
       "98 -1.00  0.64  1  0  1  0  1.0  0  0.19  N\n",
       "99 -1.00  0.69  0  1  1  0  0.6 -1  0.19  N\n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"fertility_diagnosis.csv\",header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1  2  3  4  5    6  7     8\n",
       "0 -0.33  0.69  0  1  1  0  0.8  0  0.88\n",
       "1 -0.33  0.94  1  0  1  0  0.8  1  0.31\n",
       "2 -0.33  0.50  1  0  0  0  1.0 -1  0.50\n",
       "3 -0.33  0.75  0  1  1  0  1.0 -1  0.38\n",
       "4 -0.33  0.67  1  1  0  0  0.8 -1  0.50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,0:9]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   9\n",
       "0  N\n",
       "1  O\n",
       "2  N\n",
       "3  N\n",
       "4  O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=pd.DataFrame(df.iloc[:,9])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.316753</td>\n",
       "      <td>0.173970</td>\n",
       "      <td>-2.586949</td>\n",
       "      <td>1.128152</td>\n",
       "      <td>0.980196</td>\n",
       "      <td>-0.32881</td>\n",
       "      <td>-0.192006</td>\n",
       "      <td>0.434959</td>\n",
       "      <td>2.551481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.316753</td>\n",
       "      <td>2.245043</td>\n",
       "      <td>0.386556</td>\n",
       "      <td>-0.886405</td>\n",
       "      <td>0.980196</td>\n",
       "      <td>-0.32881</td>\n",
       "      <td>-0.192006</td>\n",
       "      <td>1.677698</td>\n",
       "      <td>-0.521943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.316753</td>\n",
       "      <td>-1.400045</td>\n",
       "      <td>0.386556</td>\n",
       "      <td>-0.886405</td>\n",
       "      <td>-1.020204</td>\n",
       "      <td>-0.32881</td>\n",
       "      <td>1.008032</td>\n",
       "      <td>-0.807781</td>\n",
       "      <td>0.502532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.316753</td>\n",
       "      <td>0.671028</td>\n",
       "      <td>-2.586949</td>\n",
       "      <td>1.128152</td>\n",
       "      <td>0.980196</td>\n",
       "      <td>-0.32881</td>\n",
       "      <td>1.008032</td>\n",
       "      <td>-0.807781</td>\n",
       "      <td>-0.144505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.316753</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.386556</td>\n",
       "      <td>1.128152</td>\n",
       "      <td>-1.020204</td>\n",
       "      <td>-0.32881</td>\n",
       "      <td>-0.192006</td>\n",
       "      <td>-0.807781</td>\n",
       "      <td>0.502532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.161931</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.386556</td>\n",
       "      <td>-0.886405</td>\n",
       "      <td>-1.020204</td>\n",
       "      <td>-0.32881</td>\n",
       "      <td>1.008032</td>\n",
       "      <td>-0.807781</td>\n",
       "      <td>0.502532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-1.161931</td>\n",
       "      <td>-0.488773</td>\n",
       "      <td>0.386556</td>\n",
       "      <td>-0.886405</td>\n",
       "      <td>-1.020204</td>\n",
       "      <td>-0.32881</td>\n",
       "      <td>-0.192006</td>\n",
       "      <td>0.434959</td>\n",
       "      <td>0.502532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1.161931</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.386556</td>\n",
       "      <td>1.128152</td>\n",
       "      <td>0.980196</td>\n",
       "      <td>-0.32881</td>\n",
       "      <td>1.008032</td>\n",
       "      <td>-0.807781</td>\n",
       "      <td>-0.521943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.161931</td>\n",
       "      <td>-0.240244</td>\n",
       "      <td>0.386556</td>\n",
       "      <td>-0.886405</td>\n",
       "      <td>0.980196</td>\n",
       "      <td>-0.32881</td>\n",
       "      <td>1.008032</td>\n",
       "      <td>0.434959</td>\n",
       "      <td>-1.168979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.161931</td>\n",
       "      <td>0.173970</td>\n",
       "      <td>-2.586949</td>\n",
       "      <td>1.128152</td>\n",
       "      <td>0.980196</td>\n",
       "      <td>-0.32881</td>\n",
       "      <td>-1.392045</td>\n",
       "      <td>-0.807781</td>\n",
       "      <td>-1.168979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4        5         6  \\\n",
       "0  -0.316753  0.173970 -2.586949  1.128152  0.980196 -0.32881 -0.192006   \n",
       "1  -0.316753  2.245043  0.386556 -0.886405  0.980196 -0.32881 -0.192006   \n",
       "2  -0.316753 -1.400045  0.386556 -0.886405 -1.020204 -0.32881  1.008032   \n",
       "3  -0.316753  0.671028 -2.586949  1.128152  0.980196 -0.32881  1.008032   \n",
       "4  -0.316753  0.008284  0.386556  1.128152 -1.020204 -0.32881 -0.192006   \n",
       "..       ...       ...       ...       ...       ...      ...       ...   \n",
       "95 -1.161931  0.008284  0.386556 -0.886405 -1.020204 -0.32881  1.008032   \n",
       "96 -1.161931 -0.488773  0.386556 -0.886405 -1.020204 -0.32881 -0.192006   \n",
       "97 -1.161931  0.008284  0.386556  1.128152  0.980196 -0.32881  1.008032   \n",
       "98 -1.161931 -0.240244  0.386556 -0.886405  0.980196 -0.32881  1.008032   \n",
       "99 -1.161931  0.173970 -2.586949  1.128152  0.980196 -0.32881 -1.392045   \n",
       "\n",
       "           7         8  \n",
       "0   0.434959  2.551481  \n",
       "1   1.677698 -0.521943  \n",
       "2  -0.807781  0.502532  \n",
       "3  -0.807781 -0.144505  \n",
       "4  -0.807781  0.502532  \n",
       "..       ...       ...  \n",
       "95 -0.807781  0.502532  \n",
       "96  0.434959  0.502532  \n",
       "97 -0.807781 -0.521943  \n",
       "98  0.434959 -1.168979  \n",
       "99 -0.807781 -1.168979  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler=preprocessing.StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X=pd.DataFrame(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     scores\n",
       "3  0.064153\n",
       "2  0.024888\n",
       "1  0.011783\n",
       "0  0.000000\n",
       "4  0.000000\n",
       "5  0.000000\n",
       "6  0.000000\n",
       "7  0.000000\n",
       "8  0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# feature extraction. We are going to output the selection scores for all features and select the features with the highest scores.\n",
    "test = SelectKBest(score_func=mutual_info_classif, k=\"all\")\n",
    "fit = test.fit(X, y)\n",
    "features = fit.transform(X)\n",
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "scores=fit.scores_\n",
    "scores=pd.DataFrame(scores)\n",
    "scores=scores.rename(columns={0:\"scores\"})\n",
    "scores=scores.sort_values(by=[\"scores\"],ascending=False)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     scores\n",
       "3  0.064153\n",
       "2  0.024888\n",
       "1  0.011783"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=scores[scores[\"scores\"]>0]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.128152</td>\n",
       "      <td>-2.586949</td>\n",
       "      <td>0.173970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.886405</td>\n",
       "      <td>0.386556</td>\n",
       "      <td>2.245043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.886405</td>\n",
       "      <td>0.386556</td>\n",
       "      <td>-1.400045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.128152</td>\n",
       "      <td>-2.586949</td>\n",
       "      <td>0.671028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.128152</td>\n",
       "      <td>0.386556</td>\n",
       "      <td>0.008284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          3         2         1\n",
       "0  1.128152 -2.586949  0.173970\n",
       "1 -0.886405  0.386556  2.245043\n",
       "2 -0.886405  0.386556 -1.400045\n",
       "3  1.128152 -2.586949  0.671028\n",
       "4  1.128152  0.386556  0.008284"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=X.iloc[:,features.index]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  1.0  0.0\n",
       "1  0.0  1.0\n",
       "2  1.0  0.0\n",
       "3  1.0  0.0\n",
       "4  0.0  1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y=pd.DataFrame(enc.fit_transform(y).toarray())\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=X_train.shape[1]\n",
    "num_classes=y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the batch size and the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.870279 using {'batch_size': 20, 'epochs': 100}\n",
      "0.770525 (0.029404) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.870279 (0.018578) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.870279 (0.018578) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.530788 (0.101219) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.818145 (0.029898) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.870279 (0.018578) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.629310 (0.160499) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.823686 (0.011922) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.870279 (0.018578) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.646757 (0.068073) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.722291 (0.077601) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.870279 (0.018578) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.507389 (0.100575) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.789409 (0.072028) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.818555 (0.054571) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.590107 (0.112717) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.604064 (0.252924) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.810755 (0.067312) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=length, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "model = KerasClassifier(build_fn=create_model,verbose=0)\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal batch size is 20 and the optimal number of epochs is 100. Implement the results and optimize other hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for the best optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.870588 using {'optimizer': 'RMSprop'}\n",
      "0.847059 (0.018076) with: {'optimizer': 'SGD'}\n",
      "0.870588 (0.018684) with: {'optimizer': 'RMSprop'}\n",
      "0.870588 (0.018684) with: {'optimizer': 'Adagrad'}\n",
      "0.870588 (0.031925) with: {'optimizer': 'Adadelta'}\n",
      "0.870588 (0.018684) with: {'optimizer': 'Adam'}\n",
      "0.858824 (0.030777) with: {'optimizer': 'Adamax'}\n",
      "0.870588 (0.018684) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=length, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=20, verbose=0)\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm chose \"RMSprop\" as the optimal optimizer. Indeed, a closer look at the output shows that \"SGD\", \"Adagrad\",\"RMSProp\",\"Adam\" or \"Nadam\" would make no difference. The only two optimizers that would make a difference is \"Adadelta\" and \"Adamax\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the best optimizer and search for the optimal learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.870588 using {'learn_rate': 0.001}\n",
      "0.870588 (0.018684) with: {'learn_rate': 0.001}\n",
      "0.864706 (0.030835) with: {'learn_rate': 0.005}\n",
      "0.858824 (0.026269) with: {'learn_rate': 0.01}\n",
      "0.870588 (0.034488) with: {'learn_rate': 0.05}\n",
      "0.870588 (0.015738) with: {'learn_rate': 0.1}\n",
      "0.811765 (0.018431) with: {'learn_rate': 0.2}\n",
      "0.847059 (0.014013) with: {'learn_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=length, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    optimizer = RMSprop(lr=learn_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=20, verbose=0)\n",
    "learn_rate = [0.001, 0.005,0.01, 0.05,0.1, 0.2, 0.3]\n",
    "param_grid = dict(learn_rate=learn_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal learning rate is 0.001."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the optimial learning rate and search for the optimal initialization for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.870588 using {'init_mode': 'uniform'}\n",
      "0.870588 (0.018684) with: {'init_mode': 'uniform'}\n",
      "0.870588 (0.018684) with: {'init_mode': 'lecun_uniform'}\n",
      "0.870588 (0.018684) with: {'init_mode': 'normal'}\n",
      "0.870588 (0.018684) with: {'init_mode': 'zero'}\n",
      "0.870588 (0.018684) with: {'init_mode': 'glorot_normal'}\n",
      "0.870588 (0.018684) with: {'init_mode': 'glorot_uniform'}\n",
      "0.870588 (0.018684) with: {'init_mode': 'he_normal'}\n",
      "0.852941 (0.038178) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(init_mode='uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=length, kernel_initializer=init_mode, activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    opt= RMSprop(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=20, verbose=0)\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal initialization is \"uniform\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the optimal initialization and search for the optimal neuron activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.870588 using {'activation': 'softmax'}\n",
      "0.870588 (0.018684) with: {'activation': 'softmax'}\n",
      "0.870588 (0.018684) with: {'activation': 'softplus'}\n",
      "0.858824 (0.030777) with: {'activation': 'softsign'}\n",
      "0.870588 (0.018684) with: {'activation': 'relu'}\n",
      "0.858824 (0.030777) with: {'activation': 'tanh'}\n",
      "0.870588 (0.018684) with: {'activation': 'sigmoid'}\n",
      "0.870588 (0.018684) with: {'activation': 'hard_sigmoid'}\n",
      "0.858824 (0.030777) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=length, kernel_initializer='uniform', activation=activation))\n",
    "    model.add(Dense(num_classes, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    opt= RMSprop(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=20, verbose=0)\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal activation function is \"softmax\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement \"softmax\" and search for the optimal dropout rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.870588 using {'dropout_rate': 0.0, 'weight_constraint': 1}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.0, 'weight_constraint': 1}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.0, 'weight_constraint': 2}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.0, 'weight_constraint': 3}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.0, 'weight_constraint': 4}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.0, 'weight_constraint': 5}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.1, 'weight_constraint': 1}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.1, 'weight_constraint': 2}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.1, 'weight_constraint': 3}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.1, 'weight_constraint': 4}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.1, 'weight_constraint': 5}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.2, 'weight_constraint': 1}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.2, 'weight_constraint': 2}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.2, 'weight_constraint': 3}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.2, 'weight_constraint': 4}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.2, 'weight_constraint': 5}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.3, 'weight_constraint': 1}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.3, 'weight_constraint': 2}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.3, 'weight_constraint': 3}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.3, 'weight_constraint': 4}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.3, 'weight_constraint': 5}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.4, 'weight_constraint': 1}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.4, 'weight_constraint': 2}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.4, 'weight_constraint': 3}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.4, 'weight_constraint': 4}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.4, 'weight_constraint': 5}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.5, 'weight_constraint': 1}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.5, 'weight_constraint': 2}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.5, 'weight_constraint': 3}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.5, 'weight_constraint': 4}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.5, 'weight_constraint': 5}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.6, 'weight_constraint': 1}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.6, 'weight_constraint': 2}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.6, 'weight_constraint': 3}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.6, 'weight_constraint': 4}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.6, 'weight_constraint': 5}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.7, 'weight_constraint': 1}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.7, 'weight_constraint': 2}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.7, 'weight_constraint': 3}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.7, 'weight_constraint': 4}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.7, 'weight_constraint': 5}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.8, 'weight_constraint': 1}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.8, 'weight_constraint': 2}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.8, 'weight_constraint': 3}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.8, 'weight_constraint': 4}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.8, 'weight_constraint': 5}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.9, 'weight_constraint': 1}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.9, 'weight_constraint': 2}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.9, 'weight_constraint': 3}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.9, 'weight_constraint': 4}\n",
      "0.870588 (0.018684) with: {'dropout_rate': 0.9, 'weight_constraint': 5}\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Dropout\n",
    "dim=X_train.shape[1]\n",
    "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=length, kernel_initializer='uniform', activation='softmax', kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(num_classes, kernel_initializer='uniform', activation='softmax'))\n",
    "    opt= RMSprop(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=20, verbose=0)\n",
    "weight_constraint = [1, 2, 3, 4, 5]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal dropout rate is 0 and optimal weight_constraint is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the optimal dropout rate, weight-constraint and search for the optimal number of neurons for the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.870588 using {'neurons': 10}\n",
      "0.870588 (0.018684) with: {'neurons': 10}\n",
      "0.870588 (0.018684) with: {'neurons': 15}\n",
      "0.870588 (0.018684) with: {'neurons': 20}\n",
      "0.870588 (0.018684) with: {'neurons': 25}\n",
      "0.870588 (0.018684) with: {'neurons': 30}\n",
      "0.870588 (0.018684) with: {'neurons': 35}\n",
      "0.870588 (0.018684) with: {'neurons': 40}\n",
      "0.870588 (0.018684) with: {'neurons': 45}\n",
      "0.870588 (0.018684) with: {'neurons': 50}\n",
      "0.870588 (0.018684) with: {'neurons': 55}\n",
      "0.870588 (0.018684) with: {'neurons': 60}\n",
      "0.870588 (0.018684) with: {'neurons': 65}\n",
      "0.870588 (0.018684) with: {'neurons': 70}\n",
      "0.870588 (0.018684) with: {'neurons': 75}\n",
      "0.870588 (0.018684) with: {'neurons': 80}\n",
      "0.870588 (0.018684) with: {'neurons': 85}\n",
      "0.870588 (0.018684) with: {'neurons': 90}\n",
      "0.870588 (0.018684) with: {'neurons': 95}\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "def create_model(neurons=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=length, kernel_initializer='uniform', activation='softmax', kernel_constraint=maxnorm(1)))\n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(num_classes, kernel_initializer='uniform', activation='softmax'))\n",
    "    opt= RMSprop(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=20, verbose=0)\n",
    "neurons = np.arange(10,100,5)\n",
    "param_grid = dict(neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal number of neurons for hidden layers is 10. Indeed, the results show that it makes no difference whether we put 10 of 95 neurons on the hidden layers. For efficiency, we will go with 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a summary of the optimization results: </br>\n",
    "- Optimal batch size: 20\n",
    "- Optimal number of epochs: 100\n",
    "- Optimal optimization algorithm: SGD\", \"Adagrad\",\"RMSProp\",\"Adam\" or \"Nadam\".\n",
    "- OPtimal learning rate: 0.001\n",
    "- Optimal initializer: uniform\n",
    "- Optimal activation function: softmax\n",
    "- Optimal dropout rate: 0\n",
    "- Optimal weight constraint: 1\n",
    "- Optimal number of neurons for hidden layers: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras neural network model based on the optimization results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import Adam\n",
    "#from keras.optimizers import Adam\n",
    "\n",
    "def classification_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=length, kernel_initializer='uniform', activation='softmax', kernel_constraint=maxnorm(1)))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='uniform', activation='softmax'))\n",
    "    opt= Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#model = KerasClassifier(build_fn=classification_model, epochs=100, batch_size=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 85 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 0.8730 - acc: 0.3706 - val_loss: 0.8203 - val_acc: 0.4667\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.8552 - acc: 0.3765 - val_loss: 0.8057 - val_acc: 0.4667\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.8388 - acc: 0.3824 - val_loss: 0.7918 - val_acc: 0.4667\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.8212 - acc: 0.4000 - val_loss: 0.7782 - val_acc: 0.4667\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.8051 - acc: 0.4118 - val_loss: 0.7649 - val_acc: 0.4667\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.7897 - acc: 0.4176 - val_loss: 0.7521 - val_acc: 0.5667\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.7748 - acc: 0.4706 - val_loss: 0.7397 - val_acc: 0.6000\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.7602 - acc: 0.5059 - val_loss: 0.7278 - val_acc: 0.6333\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.7464 - acc: 0.5176 - val_loss: 0.7164 - val_acc: 0.5667\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.7329 - acc: 0.5235 - val_loss: 0.7056 - val_acc: 0.5667\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.7213 - acc: 0.5412 - val_loss: 0.6949 - val_acc: 0.6000\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.7090 - acc: 0.5765 - val_loss: 0.6848 - val_acc: 0.6333\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.6977 - acc: 0.5824 - val_loss: 0.6753 - val_acc: 0.6667\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.6874 - acc: 0.5941 - val_loss: 0.6659 - val_acc: 0.6667\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.6767 - acc: 0.6176 - val_loss: 0.6570 - val_acc: 0.7000\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.6673 - acc: 0.6353 - val_loss: 0.6483 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.6575 - acc: 0.6706 - val_loss: 0.6398 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.6481 - acc: 0.7000 - val_loss: 0.6314 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.6397 - acc: 0.7059 - val_loss: 0.6233 - val_acc: 0.7000\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.6308 - acc: 0.7118 - val_loss: 0.6159 - val_acc: 0.7333\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.6230 - acc: 0.7412 - val_loss: 0.6086 - val_acc: 0.7333\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.6151 - acc: 0.7471 - val_loss: 0.6014 - val_acc: 0.7333\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.6076 - acc: 0.7471 - val_loss: 0.5945 - val_acc: 0.7667\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.6006 - acc: 0.7647 - val_loss: 0.5877 - val_acc: 0.7667\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.5936 - acc: 0.7706 - val_loss: 0.5812 - val_acc: 0.7667\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.5869 - acc: 0.7765 - val_loss: 0.5749 - val_acc: 0.7667\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.5805 - acc: 0.7765 - val_loss: 0.5687 - val_acc: 0.7667\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.5742 - acc: 0.7824 - val_loss: 0.5627 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.5680 - acc: 0.7882 - val_loss: 0.5569 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.5615 - acc: 0.7824 - val_loss: 0.5512 - val_acc: 0.8333\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.5556 - acc: 0.7882 - val_loss: 0.5456 - val_acc: 0.8333\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.5500 - acc: 0.7882 - val_loss: 0.5401 - val_acc: 0.8333\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.5445 - acc: 0.7882 - val_loss: 0.5348 - val_acc: 0.8333\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.5388 - acc: 0.7941 - val_loss: 0.5297 - val_acc: 0.8333\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.5338 - acc: 0.7941 - val_loss: 0.5249 - val_acc: 0.8333\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.5288 - acc: 0.7941 - val_loss: 0.5205 - val_acc: 0.8333\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.5243 - acc: 0.7941 - val_loss: 0.5159 - val_acc: 0.8333\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.5194 - acc: 0.8000 - val_loss: 0.5116 - val_acc: 0.8667\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.5151 - acc: 0.8000 - val_loss: 0.5074 - val_acc: 0.8667\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.5109 - acc: 0.8000 - val_loss: 0.5034 - val_acc: 0.8667\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.5066 - acc: 0.8000 - val_loss: 0.4994 - val_acc: 0.8667\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.5028 - acc: 0.8118 - val_loss: 0.4952 - val_acc: 0.8667\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.4986 - acc: 0.8176 - val_loss: 0.4914 - val_acc: 0.9000\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.4950 - acc: 0.8235 - val_loss: 0.4874 - val_acc: 0.9000\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.4913 - acc: 0.8235 - val_loss: 0.4837 - val_acc: 0.9000\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.4876 - acc: 0.8412 - val_loss: 0.4804 - val_acc: 0.9000\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.4842 - acc: 0.8412 - val_loss: 0.4769 - val_acc: 0.9000\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.4807 - acc: 0.8412 - val_loss: 0.4734 - val_acc: 0.9000\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4772 - acc: 0.8412 - val_loss: 0.4698 - val_acc: 0.9000\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.4739 - acc: 0.8412 - val_loss: 0.4661 - val_acc: 0.9000\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.4708 - acc: 0.8412 - val_loss: 0.4626 - val_acc: 0.9333\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.4675 - acc: 0.8471 - val_loss: 0.4595 - val_acc: 0.9333\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.4646 - acc: 0.8471 - val_loss: 0.4566 - val_acc: 0.9333\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.4619 - acc: 0.8471 - val_loss: 0.4536 - val_acc: 0.9333\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.4592 - acc: 0.8471 - val_loss: 0.4505 - val_acc: 0.9333\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.4565 - acc: 0.8471 - val_loss: 0.4475 - val_acc: 0.9333\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.4539 - acc: 0.8471 - val_loss: 0.4446 - val_acc: 0.9333\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.4509 - acc: 0.8471 - val_loss: 0.4416 - val_acc: 0.9333\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.4483 - acc: 0.8471 - val_loss: 0.4389 - val_acc: 0.9333\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.4458 - acc: 0.8529 - val_loss: 0.4362 - val_acc: 0.9333\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.4433 - acc: 0.8529 - val_loss: 0.4336 - val_acc: 0.9333\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.4409 - acc: 0.8529 - val_loss: 0.4309 - val_acc: 0.9333\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.4388 - acc: 0.8588 - val_loss: 0.4283 - val_acc: 0.9333\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.4363 - acc: 0.8588 - val_loss: 0.4259 - val_acc: 0.9333\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.4342 - acc: 0.8588 - val_loss: 0.4236 - val_acc: 0.9333\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.4319 - acc: 0.8588 - val_loss: 0.4215 - val_acc: 0.9333\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.4299 - acc: 0.8588 - val_loss: 0.4190 - val_acc: 0.9333\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.4279 - acc: 0.8588 - val_loss: 0.4166 - val_acc: 0.9333\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4260 - acc: 0.8588 - val_loss: 0.4142 - val_acc: 0.9333\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.4239 - acc: 0.8588 - val_loss: 0.4120 - val_acc: 0.9333\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4220 - acc: 0.8647 - val_loss: 0.4099 - val_acc: 0.9333\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.4202 - acc: 0.8706 - val_loss: 0.4078 - val_acc: 0.9333\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.4183 - acc: 0.8706 - val_loss: 0.4056 - val_acc: 0.9333\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.4166 - acc: 0.8706 - val_loss: 0.4034 - val_acc: 0.9333\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4147 - acc: 0.8706 - val_loss: 0.4015 - val_acc: 0.9333\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.4132 - acc: 0.8647 - val_loss: 0.3995 - val_acc: 0.9333\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.4112 - acc: 0.8647 - val_loss: 0.3977 - val_acc: 0.9333\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4096 - acc: 0.8647 - val_loss: 0.3958 - val_acc: 0.9333\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4080 - acc: 0.8647 - val_loss: 0.3938 - val_acc: 0.9333\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.4063 - acc: 0.8647 - val_loss: 0.3922 - val_acc: 0.9333\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4048 - acc: 0.8647 - val_loss: 0.3907 - val_acc: 0.9333\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4035 - acc: 0.8647 - val_loss: 0.3895 - val_acc: 0.9333\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4025 - acc: 0.8647 - val_loss: 0.3880 - val_acc: 0.9333\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4010 - acc: 0.8647 - val_loss: 0.3867 - val_acc: 0.9333\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.3997 - acc: 0.8647 - val_loss: 0.3854 - val_acc: 0.9333\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.3983 - acc: 0.8647 - val_loss: 0.3841 - val_acc: 0.9333\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.3972 - acc: 0.8588 - val_loss: 0.3827 - val_acc: 0.9333\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.3956 - acc: 0.8588 - val_loss: 0.3814 - val_acc: 0.9333\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.3945 - acc: 0.8588 - val_loss: 0.3800 - val_acc: 0.9333\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.3932 - acc: 0.8647 - val_loss: 0.3786 - val_acc: 0.9333\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.3919 - acc: 0.8647 - val_loss: 0.3773 - val_acc: 0.9333\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.3908 - acc: 0.8647 - val_loss: 0.3760 - val_acc: 0.9333\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.3898 - acc: 0.8647 - val_loss: 0.3746 - val_acc: 0.9333\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.3885 - acc: 0.8647 - val_loss: 0.3734 - val_acc: 0.9333\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.3873 - acc: 0.8647 - val_loss: 0.3723 - val_acc: 0.9333\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.3863 - acc: 0.8647 - val_loss: 0.3711 - val_acc: 0.9333\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.3851 - acc: 0.8647 - val_loss: 0.3700 - val_acc: 0.9333\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.3838 - acc: 0.8647 - val_loss: 0.3689 - val_acc: 0.9333\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.3827 - acc: 0.8647 - val_loss: 0.3677 - val_acc: 0.9333\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.3816 - acc: 0.8647 - val_loss: 0.3666 - val_acc: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36658674478530884, 0.9333333373069763]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=classification_model()\n",
    "model.fit(X_train,y_train,validation_data=(X_test, y_test),epochs=100, batch_size=20,verbose=2)\n",
    "model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.722, 0.284],\n",
       "       [0.844, 0.121],\n",
       "       [0.888, 0.079],\n",
       "       [0.876, 0.06 ],\n",
       "       [0.873, 0.093],\n",
       "       [0.72 , 0.167],\n",
       "       [0.795, 0.187],\n",
       "       [0.699, 0.32 ],\n",
       "       [0.795, 0.187],\n",
       "       [0.663, 0.36 ],\n",
       "       [0.765, 0.227],\n",
       "       [0.81 , 0.099],\n",
       "       [0.894, 0.05 ],\n",
       "       [0.844, 0.121],\n",
       "       [0.74 , 0.255]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicted all semens in the test data to be \"Normal (N)\". However, there is 1 instance of \"Altered (O)\" semen in the test data, row index 70, as shown below. This is the 3rd instance in the test data. However, the model predicted that there was only 6% (0.06) chance that the semen would be \"Altered (O)\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "83  1.0  0.0\n",
       "53  1.0  0.0\n",
       "70  0.0  1.0\n",
       "45  1.0  0.0\n",
       "44  1.0  0.0\n",
       "39  1.0  0.0\n",
       "22  1.0  0.0\n",
       "80  1.0  0.0\n",
       "10  1.0  0.0\n",
       "0   1.0  0.0\n",
       "18  1.0  0.0\n",
       "30  1.0  0.0\n",
       "73  1.0  0.0\n",
       "33  1.0  0.0\n",
       "90  1.0  0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with all the hyper-parameters fined-tune, even with a 93.33% accuracy on test data, if this model is to be used for screening for semens that are \"altered\", labeled as \"O\" in the dataset, it is practically useless. [It is my own work, but that does not mean I won't criticize it. :) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of this experiment. It illustrates (1) the limitation of fine-tuning hyper-parameters; (2) the problem with an imbalanced dataset.\n",
    "\n",
    "For dataset with uneven class distribution, it seems to me that the most effective and the only way to deal with with it is to recalibrate the class distribution with synthetic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
