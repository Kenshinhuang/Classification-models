{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Recording</th>\n",
       "      <th>Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Jitter_rel</th>\n",
       "      <th>Jitter_abs</th>\n",
       "      <th>Jitter_RAP</th>\n",
       "      <th>Jitter_PPQ</th>\n",
       "      <th>Shim_loc</th>\n",
       "      <th>Shim_dB</th>\n",
       "      <th>...</th>\n",
       "      <th>Delta3</th>\n",
       "      <th>Delta4</th>\n",
       "      <th>Delta5</th>\n",
       "      <th>Delta6</th>\n",
       "      <th>Delta7</th>\n",
       "      <th>Delta8</th>\n",
       "      <th>Delta9</th>\n",
       "      <th>Delta10</th>\n",
       "      <th>Delta11</th>\n",
       "      <th>Delta12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONT-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25546</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.030256</td>\n",
       "      <td>0.26313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.407701</td>\n",
       "      <td>1.417218</td>\n",
       "      <td>1.380352</td>\n",
       "      <td>1.420670</td>\n",
       "      <td>1.451240</td>\n",
       "      <td>1.440295</td>\n",
       "      <td>1.403678</td>\n",
       "      <td>1.405495</td>\n",
       "      <td>1.416705</td>\n",
       "      <td>1.354610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CONT-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36964</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.023146</td>\n",
       "      <td>0.20217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.331232</td>\n",
       "      <td>1.227338</td>\n",
       "      <td>1.213377</td>\n",
       "      <td>1.352739</td>\n",
       "      <td>1.354242</td>\n",
       "      <td>1.365692</td>\n",
       "      <td>1.322870</td>\n",
       "      <td>1.314549</td>\n",
       "      <td>1.318999</td>\n",
       "      <td>1.323508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CONT-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23514</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.019338</td>\n",
       "      <td>0.16710</td>\n",
       "      <td>...</td>\n",
       "      <td>1.412304</td>\n",
       "      <td>1.324674</td>\n",
       "      <td>1.276088</td>\n",
       "      <td>1.429634</td>\n",
       "      <td>1.455996</td>\n",
       "      <td>1.368882</td>\n",
       "      <td>1.438053</td>\n",
       "      <td>1.388910</td>\n",
       "      <td>1.305469</td>\n",
       "      <td>1.305402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONT-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.29320</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.024716</td>\n",
       "      <td>0.20892</td>\n",
       "      <td>...</td>\n",
       "      <td>1.501200</td>\n",
       "      <td>1.534170</td>\n",
       "      <td>1.323993</td>\n",
       "      <td>1.496442</td>\n",
       "      <td>1.472926</td>\n",
       "      <td>1.643177</td>\n",
       "      <td>1.551286</td>\n",
       "      <td>1.638346</td>\n",
       "      <td>1.604008</td>\n",
       "      <td>1.621456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONT-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23075</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.11607</td>\n",
       "      <td>...</td>\n",
       "      <td>1.508468</td>\n",
       "      <td>1.334511</td>\n",
       "      <td>1.610694</td>\n",
       "      <td>1.685021</td>\n",
       "      <td>1.417614</td>\n",
       "      <td>1.574895</td>\n",
       "      <td>1.640088</td>\n",
       "      <td>1.533666</td>\n",
       "      <td>1.297536</td>\n",
       "      <td>1.382023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Recording  Status  Gender  Jitter_rel  Jitter_abs  Jitter_RAP  \\\n",
       "0  CONT-01          1       0       1     0.25546    0.000015    0.001467   \n",
       "1  CONT-01          2       0       1     0.36964    0.000022    0.001932   \n",
       "2  CONT-01          3       0       1     0.23514    0.000013    0.001353   \n",
       "3  CONT-02          1       0       0     0.29320    0.000017    0.001105   \n",
       "4  CONT-02          2       0       0     0.23075    0.000015    0.001073   \n",
       "\n",
       "   Jitter_PPQ  Shim_loc  Shim_dB  ...    Delta3    Delta4    Delta5    Delta6  \\\n",
       "0    0.001673  0.030256  0.26313  ...  1.407701  1.417218  1.380352  1.420670   \n",
       "1    0.002245  0.023146  0.20217  ...  1.331232  1.227338  1.213377  1.352739   \n",
       "2    0.001546  0.019338  0.16710  ...  1.412304  1.324674  1.276088  1.429634   \n",
       "3    0.001444  0.024716  0.20892  ...  1.501200  1.534170  1.323993  1.496442   \n",
       "4    0.001404  0.013119  0.11607  ...  1.508468  1.334511  1.610694  1.685021   \n",
       "\n",
       "     Delta7    Delta8    Delta9   Delta10   Delta11   Delta12  \n",
       "0  1.451240  1.440295  1.403678  1.405495  1.416705  1.354610  \n",
       "1  1.354242  1.365692  1.322870  1.314549  1.318999  1.323508  \n",
       "2  1.455996  1.368882  1.438053  1.388910  1.305469  1.305402  \n",
       "3  1.472926  1.643177  1.551286  1.638346  1.604008  1.621456  \n",
       "4  1.417614  1.574895  1.640088  1.533666  1.297536  1.382023  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url=\"https://bd29ee0e-54ab-4daa-9671-d153865d1620.usrfiles.com/ugd/bd29ee_4d48cf73646441e0b238705225f8b4c3.csv\"\n",
    "df=pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 47)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop([\"ID\"],axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recording     False\n",
       "Status        False\n",
       "Gender        False\n",
       "Jitter_rel    False\n",
       "Jitter_abs    False\n",
       "Jitter_RAP    False\n",
       "Jitter_PPQ    False\n",
       "Shim_loc      False\n",
       "Shim_dB       False\n",
       "Shim_APQ3     False\n",
       "Shim_APQ5     False\n",
       "Shi_APQ11     False\n",
       "HNR05         False\n",
       "HNR15         False\n",
       "HNR25         False\n",
       "HNR35         False\n",
       "HNR38         False\n",
       "RPDE          False\n",
       "DFA           False\n",
       "PPE           False\n",
       "GNE           False\n",
       "MFCC0         False\n",
       "MFCC1         False\n",
       "MFCC2         False\n",
       "MFCC3         False\n",
       "MFCC4         False\n",
       "MFCC5         False\n",
       "MFCC6         False\n",
       "MFCC7         False\n",
       "MFCC8         False\n",
       "MFCC9         False\n",
       "MFCC10        False\n",
       "MFCC11        False\n",
       "MFCC12        False\n",
       "Delta0        False\n",
       "Delta1        False\n",
       "Delta2        False\n",
       "Delta3        False\n",
       "Delta4        False\n",
       "Delta5        False\n",
       "Delta6        False\n",
       "Delta7        False\n",
       "Delta8        False\n",
       "Delta9        False\n",
       "Delta10       False\n",
       "Delta11       False\n",
       "Delta12       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Status</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recording</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jitter_rel</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jitter_abs</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jitter_RAP</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Status        0    1\n",
       "Recording   120  120\n",
       "Gender      120  120\n",
       "Jitter_rel  120  120\n",
       "Jitter_abs  120  120\n",
       "Jitter_RAP  120  120"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Status\").count().T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recording</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Jitter_rel</th>\n",
       "      <th>Jitter_abs</th>\n",
       "      <th>Jitter_RAP</th>\n",
       "      <th>Jitter_PPQ</th>\n",
       "      <th>Shim_loc</th>\n",
       "      <th>Shim_dB</th>\n",
       "      <th>Shim_APQ3</th>\n",
       "      <th>Shim_APQ5</th>\n",
       "      <th>...</th>\n",
       "      <th>Delta3</th>\n",
       "      <th>Delta4</th>\n",
       "      <th>Delta5</th>\n",
       "      <th>Delta6</th>\n",
       "      <th>Delta7</th>\n",
       "      <th>Delta8</th>\n",
       "      <th>Delta9</th>\n",
       "      <th>Delta10</th>\n",
       "      <th>Delta11</th>\n",
       "      <th>Delta12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25546</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.030256</td>\n",
       "      <td>0.26313</td>\n",
       "      <td>0.017463</td>\n",
       "      <td>0.019660</td>\n",
       "      <td>...</td>\n",
       "      <td>1.407701</td>\n",
       "      <td>1.417218</td>\n",
       "      <td>1.380352</td>\n",
       "      <td>1.420670</td>\n",
       "      <td>1.451240</td>\n",
       "      <td>1.440295</td>\n",
       "      <td>1.403678</td>\n",
       "      <td>1.405495</td>\n",
       "      <td>1.416705</td>\n",
       "      <td>1.354610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36964</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.023146</td>\n",
       "      <td>0.20217</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>0.014097</td>\n",
       "      <td>...</td>\n",
       "      <td>1.331232</td>\n",
       "      <td>1.227338</td>\n",
       "      <td>1.213377</td>\n",
       "      <td>1.352739</td>\n",
       "      <td>1.354242</td>\n",
       "      <td>1.365692</td>\n",
       "      <td>1.322870</td>\n",
       "      <td>1.314549</td>\n",
       "      <td>1.318999</td>\n",
       "      <td>1.323508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23514</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.019338</td>\n",
       "      <td>0.16710</td>\n",
       "      <td>0.011049</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>...</td>\n",
       "      <td>1.412304</td>\n",
       "      <td>1.324674</td>\n",
       "      <td>1.276088</td>\n",
       "      <td>1.429634</td>\n",
       "      <td>1.455996</td>\n",
       "      <td>1.368882</td>\n",
       "      <td>1.438053</td>\n",
       "      <td>1.388910</td>\n",
       "      <td>1.305469</td>\n",
       "      <td>1.305402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.29320</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.024716</td>\n",
       "      <td>0.20892</td>\n",
       "      <td>0.014525</td>\n",
       "      <td>0.015696</td>\n",
       "      <td>...</td>\n",
       "      <td>1.501200</td>\n",
       "      <td>1.534170</td>\n",
       "      <td>1.323993</td>\n",
       "      <td>1.496442</td>\n",
       "      <td>1.472926</td>\n",
       "      <td>1.643177</td>\n",
       "      <td>1.551286</td>\n",
       "      <td>1.638346</td>\n",
       "      <td>1.604008</td>\n",
       "      <td>1.621456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23075</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.11607</td>\n",
       "      <td>0.006461</td>\n",
       "      <td>0.008385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.508468</td>\n",
       "      <td>1.334511</td>\n",
       "      <td>1.610694</td>\n",
       "      <td>1.685021</td>\n",
       "      <td>1.417614</td>\n",
       "      <td>1.574895</td>\n",
       "      <td>1.640088</td>\n",
       "      <td>1.533666</td>\n",
       "      <td>1.297536</td>\n",
       "      <td>1.382023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recording  Gender  Jitter_rel  Jitter_abs  Jitter_RAP  Jitter_PPQ  \\\n",
       "0          1       1     0.25546    0.000015    0.001467    0.001673   \n",
       "1          2       1     0.36964    0.000022    0.001932    0.002245   \n",
       "2          3       1     0.23514    0.000013    0.001353    0.001546   \n",
       "3          1       0     0.29320    0.000017    0.001105    0.001444   \n",
       "4          2       0     0.23075    0.000015    0.001073    0.001404   \n",
       "\n",
       "   Shim_loc  Shim_dB  Shim_APQ3  Shim_APQ5  ...    Delta3    Delta4    Delta5  \\\n",
       "0  0.030256  0.26313   0.017463   0.019660  ...  1.407701  1.417218  1.380352   \n",
       "1  0.023146  0.20217   0.013010   0.014097  ...  1.331232  1.227338  1.213377   \n",
       "2  0.019338  0.16710   0.011049   0.012683  ...  1.412304  1.324674  1.276088   \n",
       "3  0.024716  0.20892   0.014525   0.015696  ...  1.501200  1.534170  1.323993   \n",
       "4  0.013119  0.11607   0.006461   0.008385  ...  1.508468  1.334511  1.610694   \n",
       "\n",
       "     Delta6    Delta7    Delta8    Delta9   Delta10   Delta11   Delta12  \n",
       "0  1.420670  1.451240  1.440295  1.403678  1.405495  1.416705  1.354610  \n",
       "1  1.352739  1.354242  1.365692  1.322870  1.314549  1.318999  1.323508  \n",
       "2  1.429634  1.455996  1.368882  1.438053  1.388910  1.305469  1.305402  \n",
       "3  1.496442  1.472926  1.643177  1.551286  1.638346  1.604008  1.621456  \n",
       "4  1.685021  1.417614  1.574895  1.640088  1.533666  1.297536  1.382023  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop([\"Status\"],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Status\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df[[\"Status\"]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recording</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Jitter_rel</th>\n",
       "      <th>Jitter_abs</th>\n",
       "      <th>Jitter_RAP</th>\n",
       "      <th>Jitter_PPQ</th>\n",
       "      <th>Shim_loc</th>\n",
       "      <th>Shim_dB</th>\n",
       "      <th>Shim_APQ3</th>\n",
       "      <th>Shim_APQ5</th>\n",
       "      <th>...</th>\n",
       "      <th>Delta3</th>\n",
       "      <th>Delta4</th>\n",
       "      <th>Delta5</th>\n",
       "      <th>Delta6</th>\n",
       "      <th>Delta7</th>\n",
       "      <th>Delta8</th>\n",
       "      <th>Delta9</th>\n",
       "      <th>Delta10</th>\n",
       "      <th>Delta11</th>\n",
       "      <th>Delta12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.614469</td>\n",
       "      <td>-0.662971</td>\n",
       "      <td>-0.506666</td>\n",
       "      <td>-0.418506</td>\n",
       "      <td>-0.352789</td>\n",
       "      <td>-0.358691</td>\n",
       "      <td>-0.293390</td>\n",
       "      <td>-0.264977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325967</td>\n",
       "      <td>0.322848</td>\n",
       "      <td>0.208432</td>\n",
       "      <td>0.377491</td>\n",
       "      <td>0.517459</td>\n",
       "      <td>0.456646</td>\n",
       "      <td>0.305441</td>\n",
       "      <td>0.351243</td>\n",
       "      <td>0.318174</td>\n",
       "      <td>0.040627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.400910</td>\n",
       "      <td>-0.506000</td>\n",
       "      <td>-0.368597</td>\n",
       "      <td>-0.289864</td>\n",
       "      <td>-0.659723</td>\n",
       "      <td>-0.655370</td>\n",
       "      <td>-0.617055</td>\n",
       "      <td>-0.652047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060705</td>\n",
       "      <td>-0.574647</td>\n",
       "      <td>-0.607871</td>\n",
       "      <td>0.052417</td>\n",
       "      <td>0.062588</td>\n",
       "      <td>0.102947</td>\n",
       "      <td>-0.091342</td>\n",
       "      <td>-0.080073</td>\n",
       "      <td>-0.123891</td>\n",
       "      <td>-0.108627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.652475</td>\n",
       "      <td>-0.695602</td>\n",
       "      <td>-0.540626</td>\n",
       "      <td>-0.447086</td>\n",
       "      <td>-0.824112</td>\n",
       "      <td>-0.826047</td>\n",
       "      <td>-0.759589</td>\n",
       "      <td>-0.750432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349243</td>\n",
       "      <td>-0.114575</td>\n",
       "      <td>-0.301290</td>\n",
       "      <td>0.420389</td>\n",
       "      <td>0.539764</td>\n",
       "      <td>0.118074</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>0.272589</td>\n",
       "      <td>-0.185105</td>\n",
       "      <td>-0.195514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.543881</td>\n",
       "      <td>-0.602009</td>\n",
       "      <td>-0.614281</td>\n",
       "      <td>-0.470103</td>\n",
       "      <td>-0.591947</td>\n",
       "      <td>-0.622519</td>\n",
       "      <td>-0.506938</td>\n",
       "      <td>-0.540790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798755</td>\n",
       "      <td>0.875640</td>\n",
       "      <td>-0.067094</td>\n",
       "      <td>0.740090</td>\n",
       "      <td>0.619154</td>\n",
       "      <td>1.418525</td>\n",
       "      <td>1.030224</td>\n",
       "      <td>1.455556</td>\n",
       "      <td>1.165614</td>\n",
       "      <td>1.321177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.660686</td>\n",
       "      <td>-0.663414</td>\n",
       "      <td>-0.623759</td>\n",
       "      <td>-0.479112</td>\n",
       "      <td>-1.092582</td>\n",
       "      <td>-1.074398</td>\n",
       "      <td>-1.093096</td>\n",
       "      <td>-1.049512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835506</td>\n",
       "      <td>-0.068078</td>\n",
       "      <td>1.334520</td>\n",
       "      <td>1.642508</td>\n",
       "      <td>0.359772</td>\n",
       "      <td>1.094794</td>\n",
       "      <td>1.466256</td>\n",
       "      <td>0.959102</td>\n",
       "      <td>-0.220999</td>\n",
       "      <td>0.172176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recording    Gender  Jitter_rel  Jitter_abs  Jitter_RAP  Jitter_PPQ  \\\n",
       "0  -1.224745  1.224745   -0.614469   -0.662971   -0.506666   -0.418506   \n",
       "1   0.000000  1.224745   -0.400910   -0.506000   -0.368597   -0.289864   \n",
       "2   1.224745  1.224745   -0.652475   -0.695602   -0.540626   -0.447086   \n",
       "3  -1.224745 -0.816497   -0.543881   -0.602009   -0.614281   -0.470103   \n",
       "4   0.000000 -0.816497   -0.660686   -0.663414   -0.623759   -0.479112   \n",
       "\n",
       "   Shim_loc   Shim_dB  Shim_APQ3  Shim_APQ5  ...    Delta3    Delta4  \\\n",
       "0 -0.352789 -0.358691  -0.293390  -0.264977  ...  0.325967  0.322848   \n",
       "1 -0.659723 -0.655370  -0.617055  -0.652047  ... -0.060705 -0.574647   \n",
       "2 -0.824112 -0.826047  -0.759589  -0.750432  ...  0.349243 -0.114575   \n",
       "3 -0.591947 -0.622519  -0.506938  -0.540790  ...  0.798755  0.875640   \n",
       "4 -1.092582 -1.074398  -1.093096  -1.049512  ...  0.835506 -0.068078   \n",
       "\n",
       "     Delta5    Delta6    Delta7    Delta8    Delta9   Delta10   Delta11  \\\n",
       "0  0.208432  0.377491  0.517459  0.456646  0.305441  0.351243  0.318174   \n",
       "1 -0.607871  0.052417  0.062588  0.102947 -0.091342 -0.080073 -0.123891   \n",
       "2 -0.301290  0.420389  0.539764  0.118074  0.474227  0.272589 -0.185105   \n",
       "3 -0.067094  0.740090  0.619154  1.418525  1.030224  1.455556  1.165614   \n",
       "4  1.334520  1.642508  0.359772  1.094794  1.466256  0.959102 -0.220999   \n",
       "\n",
       "    Delta12  \n",
       "0  0.040627  \n",
       "1 -0.108627  \n",
       "2 -0.195514  \n",
       "3  1.321177  \n",
       "4  0.172176  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X=pd.DataFrame(scaler.fit_transform(X),columns=X.columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.231574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.228834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.213959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.212406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.210662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.210092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.200591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.198324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.194830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.193466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.191792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.191604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.189706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.188060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.185768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.185727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.184346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.182093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.178999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.177869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.176387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.175857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.175372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.166366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.164078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.159502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.151493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.122303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.118957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.103071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.094541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.079365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.077980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.073682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.070614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.051395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.039979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.032505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.007504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scores\n",
       "14  0.231574\n",
       "15  0.228834\n",
       "12  0.213959\n",
       "30  0.212406\n",
       "38  0.210662\n",
       "33  0.210092\n",
       "36  0.200591\n",
       "25  0.198324\n",
       "27  0.194830\n",
       "40  0.193466\n",
       "37  0.191792\n",
       "32  0.191604\n",
       "11  0.189706\n",
       "44  0.188060\n",
       "13  0.185768\n",
       "34  0.185727\n",
       "45  0.184346\n",
       "23  0.182093\n",
       "24  0.178999\n",
       "29  0.177869\n",
       "20  0.176387\n",
       "28  0.175857\n",
       "42  0.175372\n",
       "31  0.166366\n",
       "43  0.164078\n",
       "35  0.159502\n",
       "26  0.151493\n",
       "41  0.122303\n",
       "39  0.118957\n",
       "22  0.103071\n",
       "21  0.094541\n",
       "18  0.079365\n",
       "19  0.077980\n",
       "17  0.073682\n",
       "10  0.070614\n",
       "5   0.051395\n",
       "9   0.039979\n",
       "7   0.032505\n",
       "4   0.028722\n",
       "2   0.017045\n",
       "3   0.008447\n",
       "6   0.007504\n",
       "1   0.004691\n",
       "8   0.000000\n",
       "16  0.000000\n",
       "0   0.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# feature extraction. We are going to output the selection scores for all features and select the features with the highest scores.\n",
    "test = SelectKBest(score_func=mutual_info_classif, k=\"all\")\n",
    "fit = test.fit(X, np.asarray(y).reshape(y.shape[0],))\n",
    "features = fit.transform(X)\n",
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "scores=fit.scores_\n",
    "scores=pd.DataFrame(scores)\n",
    "scores=scores.rename(columns={0:\"scores\"})\n",
    "scores=scores.sort_values(by=[\"scores\"],ascending=False)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(8, 16, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HNR35</th>\n",
       "      <th>HNR38</th>\n",
       "      <th>HNR15</th>\n",
       "      <th>MFCC10</th>\n",
       "      <th>Delta5</th>\n",
       "      <th>Delta0</th>\n",
       "      <th>Delta3</th>\n",
       "      <th>MFCC5</th>\n",
       "      <th>MFCC7</th>\n",
       "      <th>Delta7</th>\n",
       "      <th>...</th>\n",
       "      <th>DFA</th>\n",
       "      <th>Shi_APQ11</th>\n",
       "      <th>Jitter_PPQ</th>\n",
       "      <th>Shim_APQ5</th>\n",
       "      <th>Shim_dB</th>\n",
       "      <th>Jitter_RAP</th>\n",
       "      <th>Jitter_rel</th>\n",
       "      <th>Jitter_abs</th>\n",
       "      <th>Shim_loc</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.149284</td>\n",
       "      <td>-0.228541</td>\n",
       "      <td>-0.188492</td>\n",
       "      <td>0.101960</td>\n",
       "      <td>0.208432</td>\n",
       "      <td>0.265783</td>\n",
       "      <td>0.325967</td>\n",
       "      <td>-0.598428</td>\n",
       "      <td>-0.291353</td>\n",
       "      <td>0.517459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174762</td>\n",
       "      <td>-0.409597</td>\n",
       "      <td>-0.418506</td>\n",
       "      <td>-0.264977</td>\n",
       "      <td>-0.358691</td>\n",
       "      <td>-0.506666</td>\n",
       "      <td>-0.614469</td>\n",
       "      <td>-0.662971</td>\n",
       "      <td>-0.352789</td>\n",
       "      <td>1.224745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.011545</td>\n",
       "      <td>-0.071178</td>\n",
       "      <td>-0.065367</td>\n",
       "      <td>0.116714</td>\n",
       "      <td>-0.607871</td>\n",
       "      <td>-0.164784</td>\n",
       "      <td>-0.060705</td>\n",
       "      <td>-0.426257</td>\n",
       "      <td>-0.173321</td>\n",
       "      <td>0.062588</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.408005</td>\n",
       "      <td>-0.714508</td>\n",
       "      <td>-0.289864</td>\n",
       "      <td>-0.652047</td>\n",
       "      <td>-0.655370</td>\n",
       "      <td>-0.368597</td>\n",
       "      <td>-0.400910</td>\n",
       "      <td>-0.506000</td>\n",
       "      <td>-0.659723</td>\n",
       "      <td>1.224745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.073271</td>\n",
       "      <td>-0.142394</td>\n",
       "      <td>-0.116511</td>\n",
       "      <td>0.078448</td>\n",
       "      <td>-0.301290</td>\n",
       "      <td>-0.117478</td>\n",
       "      <td>0.349243</td>\n",
       "      <td>-0.018092</td>\n",
       "      <td>0.044825</td>\n",
       "      <td>0.539764</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156557</td>\n",
       "      <td>-0.943162</td>\n",
       "      <td>-0.447086</td>\n",
       "      <td>-0.750432</td>\n",
       "      <td>-0.826047</td>\n",
       "      <td>-0.540626</td>\n",
       "      <td>-0.652475</td>\n",
       "      <td>-0.695602</td>\n",
       "      <td>-0.824112</td>\n",
       "      <td>1.224745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.243730</td>\n",
       "      <td>0.158243</td>\n",
       "      <td>0.320979</td>\n",
       "      <td>0.701720</td>\n",
       "      <td>-0.067094</td>\n",
       "      <td>0.183503</td>\n",
       "      <td>0.798755</td>\n",
       "      <td>1.168629</td>\n",
       "      <td>1.415977</td>\n",
       "      <td>0.619154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158541</td>\n",
       "      <td>-0.623892</td>\n",
       "      <td>-0.470103</td>\n",
       "      <td>-0.540790</td>\n",
       "      <td>-0.622519</td>\n",
       "      <td>-0.614281</td>\n",
       "      <td>-0.543881</td>\n",
       "      <td>-0.602009</td>\n",
       "      <td>-0.591947</td>\n",
       "      <td>-0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.632391</td>\n",
       "      <td>0.555302</td>\n",
       "      <td>0.725034</td>\n",
       "      <td>1.005771</td>\n",
       "      <td>1.334520</td>\n",
       "      <td>-0.390955</td>\n",
       "      <td>0.835506</td>\n",
       "      <td>-0.369798</td>\n",
       "      <td>0.521166</td>\n",
       "      <td>0.359772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134223</td>\n",
       "      <td>-1.063883</td>\n",
       "      <td>-0.479112</td>\n",
       "      <td>-1.049512</td>\n",
       "      <td>-1.074398</td>\n",
       "      <td>-0.623759</td>\n",
       "      <td>-0.660686</td>\n",
       "      <td>-0.663414</td>\n",
       "      <td>-1.092582</td>\n",
       "      <td>-0.816497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HNR35     HNR38     HNR15    MFCC10    Delta5    Delta0    Delta3  \\\n",
       "0 -0.149284 -0.228541 -0.188492  0.101960  0.208432  0.265783  0.325967   \n",
       "1 -0.011545 -0.071178 -0.065367  0.116714 -0.607871 -0.164784 -0.060705   \n",
       "2 -0.073271 -0.142394 -0.116511  0.078448 -0.301290 -0.117478  0.349243   \n",
       "3  0.243730  0.158243  0.320979  0.701720 -0.067094  0.183503  0.798755   \n",
       "4  0.632391  0.555302  0.725034  1.005771  1.334520 -0.390955  0.835506   \n",
       "\n",
       "      MFCC5     MFCC7    Delta7  ...       DFA  Shi_APQ11  Jitter_PPQ  \\\n",
       "0 -0.598428 -0.291353  0.517459  ... -0.174762  -0.409597   -0.418506   \n",
       "1 -0.426257 -0.173321  0.062588  ... -0.408005  -0.714508   -0.289864   \n",
       "2 -0.018092  0.044825  0.539764  ... -0.156557  -0.943162   -0.447086   \n",
       "3  1.168629  1.415977  0.619154  ...  0.158541  -0.623892   -0.470103   \n",
       "4 -0.369798  0.521166  0.359772  ... -0.134223  -1.063883   -0.479112   \n",
       "\n",
       "   Shim_APQ5   Shim_dB  Jitter_RAP  Jitter_rel  Jitter_abs  Shim_loc    Gender  \n",
       "0  -0.264977 -0.358691   -0.506666   -0.614469   -0.662971 -0.352789  1.224745  \n",
       "1  -0.652047 -0.655370   -0.368597   -0.400910   -0.506000 -0.659723  1.224745  \n",
       "2  -0.750432 -0.826047   -0.540626   -0.652475   -0.695602 -0.824112  1.224745  \n",
       "3  -0.540790 -0.622519   -0.614281   -0.543881   -0.602009 -0.591947 -0.816497  \n",
       "4  -1.049512 -1.074398   -0.623759   -0.660686   -0.663414 -1.092582 -0.816497  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores=scores[scores[\"scores\"]>0]\n",
    "X=X.iloc[:,scores.index]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest=RandomForestClassifier(n_estimators=270,criterion=\"entropy\",max_depth=4,min_samples_split=2,min_samples_leaf=3,max_features=\"log2\",bootstrap=False,n_jobs=-1,warm_start=True,class_weight=\"balanced\",random_state=0)\n",
    "scores=cross_val_score(forest,X,np.asarray(y).reshape(240,),cv=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7935267857142858\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(forest, X, np.asarray(y).reshape(240,), cv=16)\n",
    "AUC = roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for the Random Forest model:  0.7875000000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC for the Random Forest model: \",AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[97 23]\n",
      " [28 92]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion matrix: \\n\",confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.7666666666666667\n",
      "Specificity:  0.8083333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",92/120)\n",
    "print(\"Specificity: \",97/120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7885044642857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradient=GradientBoostingClassifier(loss=\"exponential\",learning_rate=0.03,n_estimators=200,subsample=0.5,criterion=\"mae\",min_samples_split=4,min_samples_leaf=2,max_depth=5,max_features=\"sqrt\",random_state=0)\n",
    "scores=cross_val_score(gradient,X,np.asarray(y).reshape(240,),cv=16)\n",
    "print(\"Accuracy: \",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for the Gradient Boosting model:  0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(gradient, X, np.asarray(y).reshape(240,), cv=16)\n",
    "AUC = roc_auc_score(y, y_pred)\n",
    "print(\"AUC for the Gradient Boosting model: \",AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[97 23]\n",
      " [29 91]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n\",confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.7583333333333333\n",
      "Specificity:  0.8083333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",91/120)\n",
    "print(\"Specificity: \",97/120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8303571428571428\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "svm=svm.SVC(C=0.01,kernel=\"linear\",degree=3,gamma=\"auto\",cache_size=150,\n",
    "            decision_function_shape=\"ovo\",probability=True,random_state=0)\n",
    "scores=cross_val_score(svm,X,np.asarray(y).reshape(240,),cv=16)\n",
    "print(\"Accuracy: \",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for the SVM model:  0.8250000000000002\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(svm, X, np.asarray(y).reshape(240,), cv=16)\n",
    "AUC = roc_auc_score(y, y_pred)\n",
    "print(\"AUC for the SVM model: \",AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[ 97  23]\n",
      " [ 19 101]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n\",confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.8416666666666667\n",
      "Specificity:  0.8083333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",101/120)\n",
    "print(\"Specificity: \",97/120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.576083</td>\n",
       "      <td>0.423917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.469816</td>\n",
       "      <td>0.530184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.556887</td>\n",
       "      <td>0.443113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.183325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.804300</td>\n",
       "      <td>0.195700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_0    pred_1\n",
       "0  0.576083  0.423917\n",
       "1  0.469816  0.530184\n",
       "2  0.556887  0.443113\n",
       "3  0.816675  0.183325\n",
       "4  0.804300  0.195700"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =pd.DataFrame((cross_val_predict(svm, X, y, cv=16,method=\"predict_proba\"))).rename(columns={0:\"pred_0\",1:\"pred_1\"})\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs1=y_pred[[\"pred_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "thresholds=np.arange(0,1,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs,threshold):\n",
    "    return (pos_probs >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "scores=[f1_score(y, to_labels(y_probs1,t)) for t in thresholds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.47700000000000004, 0.83739837398374)\n"
     ]
    }
   ],
   "source": [
    "ix=np.argmax(scores)\n",
    "print((thresholds[ix],scores[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 >=0.477),1,y_pred.pred_0)\n",
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 < 0.477),0,y_pred.pred_0)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 >=0.477),1,y_pred.pred_1)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 <0.477),0,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 == y_pred.pred_1),0,y_pred.pred_0)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_0 == y_pred.pred_1),1,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_0  pred_1\n",
       "0     1.0     0.0\n",
       "1     0.0     1.0\n",
       "2     1.0     0.0\n",
       "3     1.0     0.0\n",
       "4     1.0     0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted negative cases:  114\n"
     ]
    }
   ],
   "source": [
    "len00=len(y_pred[y_pred[\"pred_0\"]==1])\n",
    "print(\"The number of predicted negative cases: \",len00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted positive cases:  126\n"
     ]
    }
   ],
   "source": [
    "len11=len(y_pred[y_pred[\"pred_1\"]==1])\n",
    "print(\"The number of predicted positive cases: \",len11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_0</th>\n",
       "      <th>y_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_0  y_1\n",
       "0  1.0  0.0\n",
       "1  1.0  0.0\n",
       "2  1.0  0.0\n",
       "3  1.0  0.0\n",
       "4  1.0  0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc=OneHotEncoder(handle_unknown=\"ignore\")\n",
    "y_true=np.asarray(y).reshape(-1,1)\n",
    "y_true=pd.DataFrame(enc.fit_transform(y_true).toarray()).rename(columns={0:\"y_0\",1:\"y_1\"})\n",
    "y_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 200)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare=pd.concat([y_true,y_pred],axis=1)\n",
    "pd.DataFrame(np.where(compare[\"pred_0\"]==compare[\"y_0\"])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",200/240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adjusting the threshold, the SVM model predicted:\n",
    "- (1) 117 negative cases.\n",
    "- (2) 123 positive cases\n",
    "- (3) Total number correct prediction is 195.\n",
    "\n",
    "The new confusion matrix is therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New confusion matrix :\n",
      " [[ 97  23]\n",
      " [ 17 103]]\n"
     ]
    }
   ],
   "source": [
    "print(\"New confusion matrix :\\n\", np.array([[97,23],[17,103]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True positive increased by 1, at the cost of increasing false positive by 1 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.8583333333333333\n",
      "Specificity:  0.8083333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",103/120)\n",
    "print(\"Specificity: \",97/120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8291666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB=GaussianNB()\n",
    "scores=cross_val_score(NB,X,np.asarray(y).reshape(240,),cv=12)\n",
    "print(\"Accuracy: \",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for the Naive Bayes model:  0.8291666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(NB, X, np.asarray(y).reshape(240,), cv=12)\n",
    "AUC = roc_auc_score(y, y_pred)\n",
    "print(\"AUC for the Naive Bayes model: \",AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[101  19]\n",
      " [ 22  98]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n\",confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.8166666666666667\n",
      "Specificity:  0.8416666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",98/120)\n",
    "print(\"Specificity: \", 101/120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999982</td>\n",
       "      <td>1.772145e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.558069</td>\n",
       "      <td>4.419309e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999274</td>\n",
       "      <td>7.263820e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.221785e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.617304e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_0        pred_1\n",
       "0  0.999982  1.772145e-05\n",
       "1  0.558069  4.419309e-01\n",
       "2  0.999274  7.263820e-04\n",
       "3  1.000000  1.221785e-20\n",
       "4  1.000000  2.617304e-17"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =pd.DataFrame((cross_val_predict(NB, X, y, cv=12,method=\"predict_proba\"))).rename(columns={0:\"pred_0\",1:\"pred_1\"})\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs1=y_pred[[\"pred_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "thresholds=np.arange(0,1,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs,threshold):\n",
    "    return (pos_probs >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score\n",
    "scores=[f1_score(y, to_labels(y_probs1,t)) for t in thresholds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.442, 0.8270042194092827)\n"
     ]
    }
   ],
   "source": [
    "ix=np.argmax(scores)\n",
    "print((thresholds[ix],scores[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 >=0.442),1,y_pred.pred_0)\n",
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 < 0.442),0,y_pred.pred_0)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 >=0.442),1,y_pred.pred_1)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 <0.442),0,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 == y_pred.pred_1),0,y_pred.pred_0)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_0 == y_pred.pred_1),1,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_0  pred_1\n",
       "0     1.0     0.0\n",
       "1     1.0     0.0\n",
       "2     1.0     0.0\n",
       "3     1.0     0.0\n",
       "4     1.0     0.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted negative cases:  123\n"
     ]
    }
   ],
   "source": [
    "len00=len(y_pred[y_pred[\"pred_0\"]==1])\n",
    "print(\"The number of predicted negative cases: \",len00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted positive cases:  117\n"
     ]
    }
   ],
   "source": [
    "len11=len(y_pred[y_pred[\"pred_1\"]==1])\n",
    "print(\"The number of predicted positive cases: \",len11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 199)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare=pd.concat([y_true,y_pred],axis=1)\n",
    "pd.DataFrame(np.where(compare[\"pred_0\"]==compare[\"y_0\"])).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of correct predictions is 199."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after adjusting the threshold:  0.8291666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy after adjusting the threshold: \",199/240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New confusion matrix: \n",
      " [[101  19]\n",
      " [ 22  98]]\n"
     ]
    }
   ],
   "source": [
    "print(\"New confusion matrix: \\n\",np.array([[101,19],[22,98]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.8166666666666667\n",
      "Specificity:  0.8416666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",98/120)\n",
    "print(\"Specificity: \",101/120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN=KNeighborsClassifier(n_neighbors=6,weights=\"uniform\",algorithm=\"brute\",leaf_size=35,p=1,n_jobs=-1)\n",
    "scores=cross_val_score(KNN,X,np.asarray(y).reshape(240,),cv=10)\n",
    "print(\"Accuracy: \",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8291666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR=LogisticRegression(penalty=\"l2\",C=0.05,class_weight=\"liblinear\",solver=\"lbfgs\",max_iter=100,multi_class=\"auto\",n_jobs=-1,warm_start=False,random_state=0)\n",
    "scores=cross_val_score(LR,X,np.asarray(y).reshape(240,),cv=12)\n",
    "print(\"Accuracy: \",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for the Naive Bayes model:  0.8291666666666666\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(LR, X, np.asarray(y).reshape(240,), cv=12)\n",
    "AUC = roc_auc_score(y, y_pred)\n",
    "print(\"AUC for the Naive Bayes model: \",AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[ 99  21]\n",
      " [ 20 100]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n\",confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.8333333333333334\n",
      "Specificity:  0.825\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",100/120)\n",
    "print(\"Specificity: \",99/120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.613858</td>\n",
       "      <td>0.386142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.463046</td>\n",
       "      <td>0.536954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.552706</td>\n",
       "      <td>0.447294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.864809</td>\n",
       "      <td>0.135191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.861123</td>\n",
       "      <td>0.138877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_0    pred_1\n",
       "0  0.613858  0.386142\n",
       "1  0.463046  0.536954\n",
       "2  0.552706  0.447294\n",
       "3  0.864809  0.135191\n",
       "4  0.861123  0.138877"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =pd.DataFrame((cross_val_predict(LR, X, y, cv=12,method=\"predict_proba\"))).rename(columns={0:\"pred_0\",1:\"pred_1\"})\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs1=y_pred[[\"pred_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "thresholds=np.arange(0,1,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs,threshold):\n",
    "    return (pos_probs >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "scores=[f1_score(y, to_labels(y_probs1,t)) for t in thresholds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.498, 0.8298755186721992)\n"
     ]
    }
   ],
   "source": [
    "ix=np.argmax(scores)\n",
    "print((thresholds[ix],scores[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 >=0.498),1,y_pred.pred_0)\n",
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 < 0.498),0,y_pred.pred_0)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 >=0.498),1,y_pred.pred_1)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 <0.498),0,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 == y_pred.pred_1),0,y_pred.pred_0)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_0 == y_pred.pred_1),1,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted negative cases:  119\n"
     ]
    }
   ],
   "source": [
    "len00=len(y_pred[y_pred[\"pred_0\"]==1])\n",
    "print(\"The number of predicted negative cases: \",len00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted positive cases:  121\n"
     ]
    }
   ],
   "source": [
    "len11=len(y_pred[y_pred[\"pred_1\"]==1])\n",
    "print(\"The number of predicted positive cases: \",len11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 199)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare=pd.concat([y_true,y_pred],axis=1)\n",
    "pd.DataFrame(np.where(compare[\"pred_0\"]==compare[\"y_0\"])).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maxed out the Logistic Regression model already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 43)\n",
      "(48, 43)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  0.0  1.0\n",
       "1  1.0  0.0\n",
       "2  0.0  1.0\n",
       "3  0.0  1.0\n",
       "4  0.0  1.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ienc=OneHotEncoder(handle_unknown=\"ignore\")\n",
    "y_train=ienc.fit_transform(y_train)\n",
    "y_train=pd.DataFrame(y_train.toarray())\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  1.0  0.0\n",
       "1  1.0  0.0\n",
       "2  1.0  0.0\n",
       "3  1.0  0.0\n",
       "4  1.0  0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test=ienc.fit_transform(y_test)\n",
    "y_test=pd.DataFrame(y_test.toarray())\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "length=X_train.shape[1]\n",
    "num_classes=y_test.shape[1]\n",
    "print(length)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(length, activation='relu', input_shape=(length,)))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(50,activation=\"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(50,activation=\"relu\"))\n",
    "    model.add(Dropout(0.45))\n",
    "    model.add(Dense(50,activation=\"relu\"))\n",
    "    model.add(Dropout(0.45))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    opt=Adam(lr=0.003)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 192 samples, validate on 48 samples\n",
      "Epoch 1/16\n",
      " - 4s - loss: 0.7336 - acc: 0.5000 - val_loss: 0.6169 - val_acc: 0.8125\n",
      "Epoch 2/16\n",
      " - 0s - loss: 0.6389 - acc: 0.5729 - val_loss: 0.5369 - val_acc: 0.7917\n",
      "Epoch 3/16\n",
      " - 0s - loss: 0.5940 - acc: 0.6719 - val_loss: 0.4752 - val_acc: 0.7917\n",
      "Epoch 4/16\n",
      " - 0s - loss: 0.5699 - acc: 0.7448 - val_loss: 0.4673 - val_acc: 0.7708\n",
      "Epoch 5/16\n",
      " - 0s - loss: 0.4925 - acc: 0.8073 - val_loss: 0.4580 - val_acc: 0.7708\n",
      "Epoch 6/16\n",
      " - 0s - loss: 0.4692 - acc: 0.8021 - val_loss: 0.4480 - val_acc: 0.7917\n",
      "Epoch 7/16\n",
      " - 0s - loss: 0.4857 - acc: 0.8333 - val_loss: 0.4319 - val_acc: 0.7917\n",
      "Epoch 8/16\n",
      " - 0s - loss: 0.4539 - acc: 0.8177 - val_loss: 0.4439 - val_acc: 0.7917\n",
      "Epoch 9/16\n",
      " - 0s - loss: 0.4383 - acc: 0.8385 - val_loss: 0.4494 - val_acc: 0.8125\n",
      "Epoch 10/16\n",
      " - 0s - loss: 0.3912 - acc: 0.8750 - val_loss: 0.4214 - val_acc: 0.8125\n",
      "Epoch 11/16\n",
      " - 0s - loss: 0.4178 - acc: 0.8438 - val_loss: 0.4274 - val_acc: 0.8333\n",
      "Epoch 12/16\n",
      " - 0s - loss: 0.3354 - acc: 0.8906 - val_loss: 0.4391 - val_acc: 0.8333\n",
      "Epoch 13/16\n",
      " - 0s - loss: 0.3540 - acc: 0.8646 - val_loss: 0.4161 - val_acc: 0.8542\n",
      "Epoch 14/16\n",
      " - 0s - loss: 0.3150 - acc: 0.8958 - val_loss: 0.4342 - val_acc: 0.8542\n",
      "Epoch 15/16\n",
      " - 0s - loss: 0.2807 - acc: 0.8906 - val_loss: 0.4464 - val_acc: 0.8542\n",
      "Epoch 16/16\n",
      " - 0s - loss: 0.3066 - acc: 0.9062 - val_loss: 0.4325 - val_acc: 0.8542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4325363834698995, 0.8541666666666666]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=classification_model()\n",
    "model.fit(X_train,y_train,validation_data=(X_test, y_test),epochs=16, verbose=2)\n",
    "model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.380194</td>\n",
       "      <td>0.619806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995119</td>\n",
       "      <td>0.004881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998148</td>\n",
       "      <td>0.001852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941024</td>\n",
       "      <td>0.058976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.920963</td>\n",
       "      <td>0.079037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_0    pred_1\n",
       "0  0.380194  0.619806\n",
       "1  0.995119  0.004881\n",
       "2  0.998148  0.001852\n",
       "3  0.941024  0.058976\n",
       "4  0.920963  0.079037"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=pd.DataFrame(model.predict(X_test)).rename(columns={0:\"pred_0\",1:\"pred_1\"})\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs1=y_pred[[\"pred_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "thresholds=np.arange(0,1,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs,threshold):\n",
    "    return (pos_probs >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_status=pd.DataFrame(ienc.inverse_transform(y_test)).rename(columns={0:\"status\"})\n",
    "y_status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "scores=[f1_score(y_status, to_labels(y_probs1,t)) for t in thresholds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.539, 0.8799999999999999)\n"
     ]
    }
   ],
   "source": [
    "ix=np.argmax(scores)\n",
    "print((thresholds[ix],scores[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 >=0.57),1,y_pred.pred_0)\n",
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 < 0.57),0,y_pred.pred_0)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 >=0.57),1,y_pred.pred_1)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 <0.57),0,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred[\"pred_0\"]=np.where((y_pred.pred_0 == y_pred.pred_1),0,y_pred.pred_0)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_0 == y_pred.pred_1),1,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted negative cases:  21\n"
     ]
    }
   ],
   "source": [
    "len00=len(y_pred[y_pred[\"pred_0\"]==1])\n",
    "print(\"The number of predicted negative cases: \",len00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted positive cases:  27\n"
     ]
    }
   ],
   "source": [
    "len11=len(y_pred[y_pred[\"pred_1\"]==1])\n",
    "print(\"The number of predicted positive cases: \",len11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=y_test.rename(columns={0:\"y_0\",1:\"y_1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 41)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare=pd.concat([y_true,y_pred],axis=1)\n",
    "pd.DataFrame(np.where(compare[\"pred_0\"]==compare[\"y_0\"])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true[y_true[\"y_1\"]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after adjusting threshold:  0.8541666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy after adjusting threshold: \",41/48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[19  5]\n",
      " [ 2 22]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n\",np.asarray([[19,5],[2,22]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.9166666666666666\n",
      "Specificity:  0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",22/24)\n",
    "print(\"Specificity: \",19/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated AUC:  0.8541666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated AUC: \",(22/24+19/24)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
