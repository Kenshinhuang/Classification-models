{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8MB 23.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from scikit-learn) (1.19.2)\n",
      "Collecting joblib>=0.11 (from scikit-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl (301kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 30.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from scikit-learn) (1.5.3)\n",
      "Installing collected packages: joblib, threadpoolctl, scikit-learn\n",
      "  Found existing installation: scikit-learn 0.20.1\n",
      "    Uninstalling scikit-learn-0.20.1:\n",
      "      Successfully uninstalled scikit-learn-0.20.1\n",
      "Successfully installed joblib-0.17.0 scikit-learn-0.23.2 threadpoolctl-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Recording</th>\n",
       "      <th>Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Jitter_rel</th>\n",
       "      <th>Jitter_abs</th>\n",
       "      <th>Jitter_RAP</th>\n",
       "      <th>Jitter_PPQ</th>\n",
       "      <th>Shim_loc</th>\n",
       "      <th>Shim_dB</th>\n",
       "      <th>...</th>\n",
       "      <th>Delta3</th>\n",
       "      <th>Delta4</th>\n",
       "      <th>Delta5</th>\n",
       "      <th>Delta6</th>\n",
       "      <th>Delta7</th>\n",
       "      <th>Delta8</th>\n",
       "      <th>Delta9</th>\n",
       "      <th>Delta10</th>\n",
       "      <th>Delta11</th>\n",
       "      <th>Delta12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONT-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25546</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.030256</td>\n",
       "      <td>0.26313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.407701</td>\n",
       "      <td>1.417218</td>\n",
       "      <td>1.380352</td>\n",
       "      <td>1.420670</td>\n",
       "      <td>1.451240</td>\n",
       "      <td>1.440295</td>\n",
       "      <td>1.403678</td>\n",
       "      <td>1.405495</td>\n",
       "      <td>1.416705</td>\n",
       "      <td>1.354610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CONT-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36964</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.023146</td>\n",
       "      <td>0.20217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.331232</td>\n",
       "      <td>1.227338</td>\n",
       "      <td>1.213377</td>\n",
       "      <td>1.352739</td>\n",
       "      <td>1.354242</td>\n",
       "      <td>1.365692</td>\n",
       "      <td>1.322870</td>\n",
       "      <td>1.314549</td>\n",
       "      <td>1.318999</td>\n",
       "      <td>1.323508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CONT-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23514</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.019338</td>\n",
       "      <td>0.16710</td>\n",
       "      <td>...</td>\n",
       "      <td>1.412304</td>\n",
       "      <td>1.324674</td>\n",
       "      <td>1.276088</td>\n",
       "      <td>1.429634</td>\n",
       "      <td>1.455996</td>\n",
       "      <td>1.368882</td>\n",
       "      <td>1.438053</td>\n",
       "      <td>1.388910</td>\n",
       "      <td>1.305469</td>\n",
       "      <td>1.305402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONT-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.29320</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.024716</td>\n",
       "      <td>0.20892</td>\n",
       "      <td>...</td>\n",
       "      <td>1.501200</td>\n",
       "      <td>1.534170</td>\n",
       "      <td>1.323993</td>\n",
       "      <td>1.496442</td>\n",
       "      <td>1.472926</td>\n",
       "      <td>1.643177</td>\n",
       "      <td>1.551286</td>\n",
       "      <td>1.638346</td>\n",
       "      <td>1.604008</td>\n",
       "      <td>1.621456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONT-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23075</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.11607</td>\n",
       "      <td>...</td>\n",
       "      <td>1.508468</td>\n",
       "      <td>1.334511</td>\n",
       "      <td>1.610694</td>\n",
       "      <td>1.685021</td>\n",
       "      <td>1.417614</td>\n",
       "      <td>1.574895</td>\n",
       "      <td>1.640088</td>\n",
       "      <td>1.533666</td>\n",
       "      <td>1.297536</td>\n",
       "      <td>1.382023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Recording  Status  Gender  Jitter_rel  Jitter_abs  Jitter_RAP  \\\n",
       "0  CONT-01          1       0       1     0.25546    0.000015    0.001467   \n",
       "1  CONT-01          2       0       1     0.36964    0.000022    0.001932   \n",
       "2  CONT-01          3       0       1     0.23514    0.000013    0.001353   \n",
       "3  CONT-02          1       0       0     0.29320    0.000017    0.001105   \n",
       "4  CONT-02          2       0       0     0.23075    0.000015    0.001073   \n",
       "\n",
       "   Jitter_PPQ  Shim_loc  Shim_dB  ...    Delta3    Delta4    Delta5    Delta6  \\\n",
       "0    0.001673  0.030256  0.26313  ...  1.407701  1.417218  1.380352  1.420670   \n",
       "1    0.002245  0.023146  0.20217  ...  1.331232  1.227338  1.213377  1.352739   \n",
       "2    0.001546  0.019338  0.16710  ...  1.412304  1.324674  1.276088  1.429634   \n",
       "3    0.001444  0.024716  0.20892  ...  1.501200  1.534170  1.323993  1.496442   \n",
       "4    0.001404  0.013119  0.11607  ...  1.508468  1.334511  1.610694  1.685021   \n",
       "\n",
       "     Delta7    Delta8    Delta9   Delta10   Delta11   Delta12  \n",
       "0  1.451240  1.440295  1.403678  1.405495  1.416705  1.354610  \n",
       "1  1.354242  1.365692  1.322870  1.314549  1.318999  1.323508  \n",
       "2  1.455996  1.368882  1.438053  1.388910  1.305469  1.305402  \n",
       "3  1.472926  1.643177  1.551286  1.638346  1.604008  1.621456  \n",
       "4  1.417614  1.574895  1.640088  1.533666  1.297536  1.382023  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url=\"https://bd29ee0e-54ab-4daa-9671-d153865d1620.usrfiles.com/ugd/bd29ee_4d48cf73646441e0b238705225f8b4c3.csv\"\n",
    "df=pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 47)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop([\"ID\"],axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recording     False\n",
       "Status        False\n",
       "Gender        False\n",
       "Jitter_rel    False\n",
       "Jitter_abs    False\n",
       "Jitter_RAP    False\n",
       "Jitter_PPQ    False\n",
       "Shim_loc      False\n",
       "Shim_dB       False\n",
       "Shim_APQ3     False\n",
       "Shim_APQ5     False\n",
       "Shi_APQ11     False\n",
       "HNR05         False\n",
       "HNR15         False\n",
       "HNR25         False\n",
       "HNR35         False\n",
       "HNR38         False\n",
       "RPDE          False\n",
       "DFA           False\n",
       "PPE           False\n",
       "GNE           False\n",
       "MFCC0         False\n",
       "MFCC1         False\n",
       "MFCC2         False\n",
       "MFCC3         False\n",
       "MFCC4         False\n",
       "MFCC5         False\n",
       "MFCC6         False\n",
       "MFCC7         False\n",
       "MFCC8         False\n",
       "MFCC9         False\n",
       "MFCC10        False\n",
       "MFCC11        False\n",
       "MFCC12        False\n",
       "Delta0        False\n",
       "Delta1        False\n",
       "Delta2        False\n",
       "Delta3        False\n",
       "Delta4        False\n",
       "Delta5        False\n",
       "Delta6        False\n",
       "Delta7        False\n",
       "Delta8        False\n",
       "Delta9        False\n",
       "Delta10       False\n",
       "Delta11       False\n",
       "Delta12       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Status</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recording</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jitter_rel</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jitter_abs</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jitter_RAP</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Status        0    1\n",
       "Recording   120  120\n",
       "Gender      120  120\n",
       "Jitter_rel  120  120\n",
       "Jitter_abs  120  120\n",
       "Jitter_RAP  120  120"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Status\").count().T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recording</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Jitter_rel</th>\n",
       "      <th>Jitter_abs</th>\n",
       "      <th>Jitter_RAP</th>\n",
       "      <th>Jitter_PPQ</th>\n",
       "      <th>Shim_loc</th>\n",
       "      <th>Shim_dB</th>\n",
       "      <th>Shim_APQ3</th>\n",
       "      <th>Shim_APQ5</th>\n",
       "      <th>...</th>\n",
       "      <th>Delta3</th>\n",
       "      <th>Delta4</th>\n",
       "      <th>Delta5</th>\n",
       "      <th>Delta6</th>\n",
       "      <th>Delta7</th>\n",
       "      <th>Delta8</th>\n",
       "      <th>Delta9</th>\n",
       "      <th>Delta10</th>\n",
       "      <th>Delta11</th>\n",
       "      <th>Delta12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25546</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.030256</td>\n",
       "      <td>0.26313</td>\n",
       "      <td>0.017463</td>\n",
       "      <td>0.019660</td>\n",
       "      <td>...</td>\n",
       "      <td>1.407701</td>\n",
       "      <td>1.417218</td>\n",
       "      <td>1.380352</td>\n",
       "      <td>1.420670</td>\n",
       "      <td>1.451240</td>\n",
       "      <td>1.440295</td>\n",
       "      <td>1.403678</td>\n",
       "      <td>1.405495</td>\n",
       "      <td>1.416705</td>\n",
       "      <td>1.354610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36964</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.023146</td>\n",
       "      <td>0.20217</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>0.014097</td>\n",
       "      <td>...</td>\n",
       "      <td>1.331232</td>\n",
       "      <td>1.227338</td>\n",
       "      <td>1.213377</td>\n",
       "      <td>1.352739</td>\n",
       "      <td>1.354242</td>\n",
       "      <td>1.365692</td>\n",
       "      <td>1.322870</td>\n",
       "      <td>1.314549</td>\n",
       "      <td>1.318999</td>\n",
       "      <td>1.323508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23514</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.019338</td>\n",
       "      <td>0.16710</td>\n",
       "      <td>0.011049</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>...</td>\n",
       "      <td>1.412304</td>\n",
       "      <td>1.324674</td>\n",
       "      <td>1.276088</td>\n",
       "      <td>1.429634</td>\n",
       "      <td>1.455996</td>\n",
       "      <td>1.368882</td>\n",
       "      <td>1.438053</td>\n",
       "      <td>1.388910</td>\n",
       "      <td>1.305469</td>\n",
       "      <td>1.305402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.29320</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.024716</td>\n",
       "      <td>0.20892</td>\n",
       "      <td>0.014525</td>\n",
       "      <td>0.015696</td>\n",
       "      <td>...</td>\n",
       "      <td>1.501200</td>\n",
       "      <td>1.534170</td>\n",
       "      <td>1.323993</td>\n",
       "      <td>1.496442</td>\n",
       "      <td>1.472926</td>\n",
       "      <td>1.643177</td>\n",
       "      <td>1.551286</td>\n",
       "      <td>1.638346</td>\n",
       "      <td>1.604008</td>\n",
       "      <td>1.621456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23075</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.11607</td>\n",
       "      <td>0.006461</td>\n",
       "      <td>0.008385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.508468</td>\n",
       "      <td>1.334511</td>\n",
       "      <td>1.610694</td>\n",
       "      <td>1.685021</td>\n",
       "      <td>1.417614</td>\n",
       "      <td>1.574895</td>\n",
       "      <td>1.640088</td>\n",
       "      <td>1.533666</td>\n",
       "      <td>1.297536</td>\n",
       "      <td>1.382023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recording  Gender  Jitter_rel  Jitter_abs  Jitter_RAP  Jitter_PPQ  \\\n",
       "0          1       1     0.25546    0.000015    0.001467    0.001673   \n",
       "1          2       1     0.36964    0.000022    0.001932    0.002245   \n",
       "2          3       1     0.23514    0.000013    0.001353    0.001546   \n",
       "3          1       0     0.29320    0.000017    0.001105    0.001444   \n",
       "4          2       0     0.23075    0.000015    0.001073    0.001404   \n",
       "\n",
       "   Shim_loc  Shim_dB  Shim_APQ3  Shim_APQ5  ...    Delta3    Delta4    Delta5  \\\n",
       "0  0.030256  0.26313   0.017463   0.019660  ...  1.407701  1.417218  1.380352   \n",
       "1  0.023146  0.20217   0.013010   0.014097  ...  1.331232  1.227338  1.213377   \n",
       "2  0.019338  0.16710   0.011049   0.012683  ...  1.412304  1.324674  1.276088   \n",
       "3  0.024716  0.20892   0.014525   0.015696  ...  1.501200  1.534170  1.323993   \n",
       "4  0.013119  0.11607   0.006461   0.008385  ...  1.508468  1.334511  1.610694   \n",
       "\n",
       "     Delta6    Delta7    Delta8    Delta9   Delta10   Delta11   Delta12  \n",
       "0  1.420670  1.451240  1.440295  1.403678  1.405495  1.416705  1.354610  \n",
       "1  1.352739  1.354242  1.365692  1.322870  1.314549  1.318999  1.323508  \n",
       "2  1.429634  1.455996  1.368882  1.438053  1.388910  1.305469  1.305402  \n",
       "3  1.496442  1.472926  1.643177  1.551286  1.638346  1.604008  1.621456  \n",
       "4  1.685021  1.417614  1.574895  1.640088  1.533666  1.297536  1.382023  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop([\"Status\"],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Status\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df[[\"Status\"]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recording</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Jitter_rel</th>\n",
       "      <th>Jitter_abs</th>\n",
       "      <th>Jitter_RAP</th>\n",
       "      <th>Jitter_PPQ</th>\n",
       "      <th>Shim_loc</th>\n",
       "      <th>Shim_dB</th>\n",
       "      <th>Shim_APQ3</th>\n",
       "      <th>Shim_APQ5</th>\n",
       "      <th>...</th>\n",
       "      <th>Delta3</th>\n",
       "      <th>Delta4</th>\n",
       "      <th>Delta5</th>\n",
       "      <th>Delta6</th>\n",
       "      <th>Delta7</th>\n",
       "      <th>Delta8</th>\n",
       "      <th>Delta9</th>\n",
       "      <th>Delta10</th>\n",
       "      <th>Delta11</th>\n",
       "      <th>Delta12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.614469</td>\n",
       "      <td>-0.662971</td>\n",
       "      <td>-0.506666</td>\n",
       "      <td>-0.418506</td>\n",
       "      <td>-0.352789</td>\n",
       "      <td>-0.358691</td>\n",
       "      <td>-0.293390</td>\n",
       "      <td>-0.264977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325967</td>\n",
       "      <td>0.322848</td>\n",
       "      <td>0.208432</td>\n",
       "      <td>0.377491</td>\n",
       "      <td>0.517459</td>\n",
       "      <td>0.456646</td>\n",
       "      <td>0.305441</td>\n",
       "      <td>0.351243</td>\n",
       "      <td>0.318174</td>\n",
       "      <td>0.040627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.400910</td>\n",
       "      <td>-0.506000</td>\n",
       "      <td>-0.368597</td>\n",
       "      <td>-0.289864</td>\n",
       "      <td>-0.659723</td>\n",
       "      <td>-0.655370</td>\n",
       "      <td>-0.617055</td>\n",
       "      <td>-0.652047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060705</td>\n",
       "      <td>-0.574647</td>\n",
       "      <td>-0.607871</td>\n",
       "      <td>0.052417</td>\n",
       "      <td>0.062588</td>\n",
       "      <td>0.102947</td>\n",
       "      <td>-0.091342</td>\n",
       "      <td>-0.080073</td>\n",
       "      <td>-0.123891</td>\n",
       "      <td>-0.108627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.652475</td>\n",
       "      <td>-0.695602</td>\n",
       "      <td>-0.540626</td>\n",
       "      <td>-0.447086</td>\n",
       "      <td>-0.824112</td>\n",
       "      <td>-0.826047</td>\n",
       "      <td>-0.759589</td>\n",
       "      <td>-0.750432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349243</td>\n",
       "      <td>-0.114575</td>\n",
       "      <td>-0.301290</td>\n",
       "      <td>0.420389</td>\n",
       "      <td>0.539764</td>\n",
       "      <td>0.118074</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>0.272589</td>\n",
       "      <td>-0.185105</td>\n",
       "      <td>-0.195514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.543881</td>\n",
       "      <td>-0.602009</td>\n",
       "      <td>-0.614281</td>\n",
       "      <td>-0.470103</td>\n",
       "      <td>-0.591947</td>\n",
       "      <td>-0.622519</td>\n",
       "      <td>-0.506938</td>\n",
       "      <td>-0.540790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798755</td>\n",
       "      <td>0.875640</td>\n",
       "      <td>-0.067094</td>\n",
       "      <td>0.740090</td>\n",
       "      <td>0.619154</td>\n",
       "      <td>1.418525</td>\n",
       "      <td>1.030224</td>\n",
       "      <td>1.455556</td>\n",
       "      <td>1.165614</td>\n",
       "      <td>1.321177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.660686</td>\n",
       "      <td>-0.663414</td>\n",
       "      <td>-0.623759</td>\n",
       "      <td>-0.479112</td>\n",
       "      <td>-1.092582</td>\n",
       "      <td>-1.074398</td>\n",
       "      <td>-1.093096</td>\n",
       "      <td>-1.049512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835506</td>\n",
       "      <td>-0.068078</td>\n",
       "      <td>1.334520</td>\n",
       "      <td>1.642508</td>\n",
       "      <td>0.359772</td>\n",
       "      <td>1.094794</td>\n",
       "      <td>1.466256</td>\n",
       "      <td>0.959102</td>\n",
       "      <td>-0.220999</td>\n",
       "      <td>0.172176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recording    Gender  Jitter_rel  Jitter_abs  Jitter_RAP  Jitter_PPQ  \\\n",
       "0  -1.224745  1.224745   -0.614469   -0.662971   -0.506666   -0.418506   \n",
       "1   0.000000  1.224745   -0.400910   -0.506000   -0.368597   -0.289864   \n",
       "2   1.224745  1.224745   -0.652475   -0.695602   -0.540626   -0.447086   \n",
       "3  -1.224745 -0.816497   -0.543881   -0.602009   -0.614281   -0.470103   \n",
       "4   0.000000 -0.816497   -0.660686   -0.663414   -0.623759   -0.479112   \n",
       "\n",
       "   Shim_loc   Shim_dB  Shim_APQ3  Shim_APQ5  ...    Delta3    Delta4  \\\n",
       "0 -0.352789 -0.358691  -0.293390  -0.264977  ...  0.325967  0.322848   \n",
       "1 -0.659723 -0.655370  -0.617055  -0.652047  ... -0.060705 -0.574647   \n",
       "2 -0.824112 -0.826047  -0.759589  -0.750432  ...  0.349243 -0.114575   \n",
       "3 -0.591947 -0.622519  -0.506938  -0.540790  ...  0.798755  0.875640   \n",
       "4 -1.092582 -1.074398  -1.093096  -1.049512  ...  0.835506 -0.068078   \n",
       "\n",
       "     Delta5    Delta6    Delta7    Delta8    Delta9   Delta10   Delta11  \\\n",
       "0  0.208432  0.377491  0.517459  0.456646  0.305441  0.351243  0.318174   \n",
       "1 -0.607871  0.052417  0.062588  0.102947 -0.091342 -0.080073 -0.123891   \n",
       "2 -0.301290  0.420389  0.539764  0.118074  0.474227  0.272589 -0.185105   \n",
       "3 -0.067094  0.740090  0.619154  1.418525  1.030224  1.455556  1.165614   \n",
       "4  1.334520  1.642508  0.359772  1.094794  1.466256  0.959102 -0.220999   \n",
       "\n",
       "    Delta12  \n",
       "0  0.040627  \n",
       "1 -0.108627  \n",
       "2 -0.195514  \n",
       "3  1.321177  \n",
       "4  0.172176  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X=pd.DataFrame(scaler.fit_transform(X),columns=X.columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>116.056158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>114.843733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>114.735126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114.540537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>111.749645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>107.934553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>107.596895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>107.515109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>103.862007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>103.226941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>102.278648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>102.090842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>99.089754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>98.672547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>95.625729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>95.535730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>95.397952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>94.673494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>94.579652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>94.403728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93.478815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>90.953461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>89.837792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>89.455281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>88.901326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>84.951612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>81.243879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>79.508615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>70.282869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29.380522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22.679495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.928361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.916892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.504496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.218122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12.811006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.310022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.841966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.953146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.894969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.149031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.505263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.250259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.524742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.040428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        scores\n",
       "30  116.056158\n",
       "14  114.843733\n",
       "44  114.735126\n",
       "15  114.540537\n",
       "25  111.749645\n",
       "23  107.934553\n",
       "36  107.596895\n",
       "38  107.515109\n",
       "42  103.862007\n",
       "24  103.226941\n",
       "13  102.278648\n",
       "32  102.090842\n",
       "40   99.089754\n",
       "34   98.672547\n",
       "28   95.625729\n",
       "35   95.535730\n",
       "31   95.397952\n",
       "45   94.673494\n",
       "33   94.579652\n",
       "29   94.403728\n",
       "12   93.478815\n",
       "37   90.953461\n",
       "11   89.837792\n",
       "26   89.455281\n",
       "43   88.901326\n",
       "27   84.951612\n",
       "20   81.243879\n",
       "39   79.508615\n",
       "41   70.282869\n",
       "21   29.380522\n",
       "19   22.679495\n",
       "8    15.928361\n",
       "9    14.916892\n",
       "7    14.504496\n",
       "6    14.218122\n",
       "22   12.811006\n",
       "4    10.310022\n",
       "10    9.841966\n",
       "2     8.953146\n",
       "5     6.894969\n",
       "18    4.149031\n",
       "1     2.505263\n",
       "3     2.250259\n",
       "16    1.524742\n",
       "17    0.040428\n",
       "0     0.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# feature extraction. We are going to output the selection scores for all features and select the features with the highest scores.\n",
    "test = SelectKBest(score_func=f_classif, k=\"all\")\n",
    "fit = test.fit(X, np.asarray(y).reshape(y.shape[0],))\n",
    "features = fit.transform(X)\n",
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "scores=fit.scores_\n",
    "scores=pd.DataFrame(scores)\n",
    "scores=scores.rename(columns={0:\"scores\"})\n",
    "scores=scores.sort_values(by=[\"scores\"],ascending=False)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(8, 16, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCC10</th>\n",
       "      <th>HNR35</th>\n",
       "      <th>Delta11</th>\n",
       "      <th>HNR38</th>\n",
       "      <th>MFCC5</th>\n",
       "      <th>MFCC3</th>\n",
       "      <th>Delta3</th>\n",
       "      <th>Delta5</th>\n",
       "      <th>Delta9</th>\n",
       "      <th>MFCC4</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCC2</th>\n",
       "      <th>Jitter_RAP</th>\n",
       "      <th>Shi_APQ11</th>\n",
       "      <th>Jitter_rel</th>\n",
       "      <th>Jitter_PPQ</th>\n",
       "      <th>PPE</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Jitter_abs</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101960</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>0.318174</td>\n",
       "      <td>-0.228541</td>\n",
       "      <td>-0.598428</td>\n",
       "      <td>-0.093842</td>\n",
       "      <td>0.325967</td>\n",
       "      <td>0.208432</td>\n",
       "      <td>0.305441</td>\n",
       "      <td>-0.327441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051423</td>\n",
       "      <td>-0.506666</td>\n",
       "      <td>-0.409597</td>\n",
       "      <td>-0.614469</td>\n",
       "      <td>-0.418506</td>\n",
       "      <td>-1.162138</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.662971</td>\n",
       "      <td>-0.917290</td>\n",
       "      <td>-0.174762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.116714</td>\n",
       "      <td>-0.011545</td>\n",
       "      <td>-0.123891</td>\n",
       "      <td>-0.071178</td>\n",
       "      <td>-0.426257</td>\n",
       "      <td>-0.753608</td>\n",
       "      <td>-0.060705</td>\n",
       "      <td>-0.607871</td>\n",
       "      <td>-0.091342</td>\n",
       "      <td>-0.462302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091389</td>\n",
       "      <td>-0.368597</td>\n",
       "      <td>-0.714508</td>\n",
       "      <td>-0.400910</td>\n",
       "      <td>-0.289864</td>\n",
       "      <td>-0.855996</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.506000</td>\n",
       "      <td>-0.596505</td>\n",
       "      <td>-0.408005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.078448</td>\n",
       "      <td>-0.073271</td>\n",
       "      <td>-0.185105</td>\n",
       "      <td>-0.142394</td>\n",
       "      <td>-0.018092</td>\n",
       "      <td>-0.013827</td>\n",
       "      <td>0.349243</td>\n",
       "      <td>-0.301290</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>-0.068514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212736</td>\n",
       "      <td>-0.540626</td>\n",
       "      <td>-0.943162</td>\n",
       "      <td>-0.652475</td>\n",
       "      <td>-0.447086</td>\n",
       "      <td>-1.162634</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.695602</td>\n",
       "      <td>-1.633324</td>\n",
       "      <td>-0.156557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.701720</td>\n",
       "      <td>0.243730</td>\n",
       "      <td>1.165614</td>\n",
       "      <td>0.158243</td>\n",
       "      <td>1.168629</td>\n",
       "      <td>0.692985</td>\n",
       "      <td>0.798755</td>\n",
       "      <td>-0.067094</td>\n",
       "      <td>1.030224</td>\n",
       "      <td>0.978634</td>\n",
       "      <td>...</td>\n",
       "      <td>1.095069</td>\n",
       "      <td>-0.614281</td>\n",
       "      <td>-0.623892</td>\n",
       "      <td>-0.543881</td>\n",
       "      <td>-0.470103</td>\n",
       "      <td>-1.052616</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.602009</td>\n",
       "      <td>-0.750465</td>\n",
       "      <td>0.158541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.005771</td>\n",
       "      <td>0.632391</td>\n",
       "      <td>-0.220999</td>\n",
       "      <td>0.555302</td>\n",
       "      <td>-0.369798</td>\n",
       "      <td>1.229621</td>\n",
       "      <td>0.835506</td>\n",
       "      <td>1.334520</td>\n",
       "      <td>1.466256</td>\n",
       "      <td>0.696630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979058</td>\n",
       "      <td>-0.623759</td>\n",
       "      <td>-1.063883</td>\n",
       "      <td>-0.660686</td>\n",
       "      <td>-0.479112</td>\n",
       "      <td>-1.030452</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.663414</td>\n",
       "      <td>-1.350304</td>\n",
       "      <td>-0.134223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MFCC10     HNR35   Delta11     HNR38     MFCC5     MFCC3    Delta3  \\\n",
       "0  0.101960 -0.149284  0.318174 -0.228541 -0.598428 -0.093842  0.325967   \n",
       "1  0.116714 -0.011545 -0.123891 -0.071178 -0.426257 -0.753608 -0.060705   \n",
       "2  0.078448 -0.073271 -0.185105 -0.142394 -0.018092 -0.013827  0.349243   \n",
       "3  0.701720  0.243730  1.165614  0.158243  1.168629  0.692985  0.798755   \n",
       "4  1.005771  0.632391 -0.220999  0.555302 -0.369798  1.229621  0.835506   \n",
       "\n",
       "     Delta5    Delta9     MFCC4  ...     MFCC2  Jitter_RAP  Shi_APQ11  \\\n",
       "0  0.208432  0.305441 -0.327441  ...  0.051423   -0.506666  -0.409597   \n",
       "1 -0.607871 -0.091342 -0.462302  ... -0.091389   -0.368597  -0.714508   \n",
       "2 -0.301290  0.474227 -0.068514  ...  0.212736   -0.540626  -0.943162   \n",
       "3 -0.067094  1.030224  0.978634  ...  1.095069   -0.614281  -0.623892   \n",
       "4  1.334520  1.466256  0.696630  ...  0.979058   -0.623759  -1.063883   \n",
       "\n",
       "   Jitter_rel  Jitter_PPQ       PPE    Gender  Jitter_abs      RPDE       DFA  \n",
       "0   -0.614469   -0.418506 -1.162138  1.224745   -0.662971 -0.917290 -0.174762  \n",
       "1   -0.400910   -0.289864 -0.855996  1.224745   -0.506000 -0.596505 -0.408005  \n",
       "2   -0.652475   -0.447086 -1.162634  1.224745   -0.695602 -1.633324 -0.156557  \n",
       "3   -0.543881   -0.470103 -1.052616 -0.816497   -0.602009 -0.750465  0.158541  \n",
       "4   -0.660686   -0.479112 -1.030452 -0.816497   -0.663414 -1.350304 -0.134223  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores=scores[scores[\"scores\"]>0]\n",
    "X=X.iloc[:,scores.index]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest=RandomForestClassifier(n_estimators=250,criterion=\"entropy\",max_depth=4,min_samples_split=3,min_samples_leaf=3,max_features=\"log2\",bootstrap=False,n_jobs=-1,warm_start=True,class_weight=\"balanced_subsample\",ccp_alpha=0.02,random_state=0)\n",
    "scores=cross_val_score(forest,X,np.asarray(y).reshape(240,),cv=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8083333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(forest, X, np.asarray(y).reshape(240,), cv=16)\n",
    "AUC = roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for the Random Forest model:  0.8083333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC for the Random Forest model: \",AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[100  20]\n",
      " [ 26  94]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion matrix: \\n\",confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.7833333333333333\n",
      "Specificity:  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",94/120)\n",
    "print(\"Specificity: \",100/120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8083333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradient=GradientBoostingClassifier(loss=\"deviance\",learning_rate=0.03,n_estimators=220,subsample=0.5,criterion=\"friedman_mse\",min_samples_split=2,min_samples_leaf=3,max_depth=3,max_features=\"sqrt\",ccp_alpha=0.01,random_state=0)\n",
    "scores=cross_val_score(gradient,X,np.asarray(y).reshape(240,),cv=16)\n",
    "print(\"Accuracy: \",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for the Gradient Boosting model:  0.8083333333333331\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(gradient, X, np.asarray(y).reshape(240,), cv=16)\n",
    "AUC = roc_auc_score(y, y_pred)\n",
    "print(\"AUC for the Gradient Boosting model: \",AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[99 21]\n",
      " [25 95]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n\",confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.7916666666666666\n",
      "Specificity:  0.825\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",95/120)\n",
    "print(\"Specificity: \",99/120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "svm=svm.SVC(C=0.015,kernel=\"linear\",degree=2,gamma=\"scale\",cache_size=150,\n",
    "            decision_function_shape=\"ovr\",probability=True,random_state=0)\n",
    "scores=cross_val_score(svm,X,np.asarray(y).reshape(240,),cv=16)\n",
    "print(\"Accuracy: \",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for the SVM model:  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(svm, X, np.asarray(y).reshape(240,), cv=16)\n",
    "AUC = roc_auc_score(y, y_pred)\n",
    "print(\"AUC for the SVM model: \",AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[ 98  22]\n",
      " [ 18 102]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n\",confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.85\n",
      "Specificity:  0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",102/120)\n",
    "print(\"Specificity: \",98/120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.576072</td>\n",
       "      <td>0.423928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.483195</td>\n",
       "      <td>0.516805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523986</td>\n",
       "      <td>0.476014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.830452</td>\n",
       "      <td>0.169548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.784913</td>\n",
       "      <td>0.215087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_0    pred_1\n",
       "0  0.576072  0.423928\n",
       "1  0.483195  0.516805\n",
       "2  0.523986  0.476014\n",
       "3  0.830452  0.169548\n",
       "4  0.784913  0.215087"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =pd.DataFrame((cross_val_predict(svm, X, np.asarray(y).reshape(240,), cv=16,method=\"predict_proba\"))).rename(columns={0:\"pred_0\",1:\"pred_1\"})\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs1=y_pred[[\"pred_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "thresholds=np.arange(0,1,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs,threshold):\n",
    "    return (pos_probs >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "scores=[f1_score(y, to_labels(y_probs1,t)) for t in thresholds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.491, 0.8326530612244897)\n"
     ]
    }
   ],
   "source": [
    "ix=np.argmax(scores)\n",
    "print((thresholds[ix],scores[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_probs1[y_probs1[\"pred_1\"]>=0.491])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 >=0.491),1,y_pred.pred_0)\n",
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 < 0.491),0,y_pred.pred_0)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 >=0.491),1,y_pred.pred_1)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 <0.491),0,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 == y_pred.pred_1),0,y_pred.pred_0)\n",
    "#y_pred[\"pred_1\"]=np.where((y_pred.pred_0 == y_pred.pred_1),1,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_0  pred_1\n",
       "0     1.0     0.0\n",
       "1     0.0     1.0\n",
       "2     1.0     0.0\n",
       "3     1.0     0.0\n",
       "4     1.0     0.0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted negative cases:  115\n"
     ]
    }
   ],
   "source": [
    "len00=len(y_pred[y_pred[\"pred_0\"]==1])\n",
    "print(\"The number of predicted negative cases: \",len00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted positive cases:  125\n"
     ]
    }
   ],
   "source": [
    "len11=len(y_pred[y_pred[\"pred_1\"]==1])\n",
    "print(\"The number of predicted positive cases: \",len11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_0</th>\n",
       "      <th>y_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_0  y_1\n",
       "0  1.0  0.0\n",
       "1  1.0  0.0\n",
       "2  1.0  0.0\n",
       "3  1.0  0.0\n",
       "4  1.0  0.0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc=OneHotEncoder(handle_unknown=\"ignore\")\n",
    "y_true=np.asarray(y).reshape(-1,1)\n",
    "y_true=pd.DataFrame(enc.fit_transform(y_true).toarray()).rename(columns={0:\"y_0\",1:\"y_1\"})\n",
    "y_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 199)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare=pd.concat([y_true,y_pred],axis=1)\n",
    "pd.DataFrame(np.where(compare[\"pred_0\"]==compare[\"y_0\"])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8291666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",199/240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB=GaussianNB()\n",
    "scores=cross_val_score(NB,X,np.asarray(y).reshape(240,),cv=24)\n",
    "print(\"Accuracy: \",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for the Naive Bayes model:  0.8375000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(NB, X, np.asarray(y).reshape(240,), cv=24)\n",
    "AUC = roc_auc_score(y, y_pred)\n",
    "print(\"AUC for the Naive Bayes model: \",AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[103  17]\n",
      " [ 22  98]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion matrix: \\n\",confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.8166666666666667\n",
      "Specificity:  0.8583333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",98/120)\n",
    "print(\"Specificity: \", 103/120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999989</td>\n",
       "      <td>1.110727e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.793542</td>\n",
       "      <td>2.064577e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999446</td>\n",
       "      <td>5.536328e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.266246e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.614880e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_0        pred_1\n",
       "0  0.999989  1.110727e-05\n",
       "1  0.793542  2.064577e-01\n",
       "2  0.999446  5.536328e-04\n",
       "3  1.000000  8.266246e-19\n",
       "4  1.000000  9.614880e-16"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =pd.DataFrame((cross_val_predict(NB, X,np.asarray(y).reshape(240,), cv=24,method=\"predict_proba\"))).rename(columns={0:\"pred_0\",1:\"pred_1\"})\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs1=y_pred[[\"pred_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "thresholds=np.arange(0,1,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs,threshold):\n",
    "    return (pos_probs >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score\n",
    "scores=[f1_score(y, to_labels(y_probs1,t)) for t in thresholds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.427, 0.8340425531914893)\n"
     ]
    }
   ],
   "source": [
    "ix=np.argmax(scores)\n",
    "print((thresholds[ix],scores[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_probs1[y_probs1[\"pred_1\"]>=0.427])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 >=0.427),1,y_pred.pred_0)\n",
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 < 0.427),0,y_pred.pred_0)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 >=0.427),1,y_pred.pred_1)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 <0.427),0,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 == y_pred.pred_1),0,y_pred.pred_0)\n",
    "#y_pred[\"pred_1\"]=np.where((y_pred.pred_0 == y_pred.pred_1),1,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted negative cases:  125\n"
     ]
    }
   ],
   "source": [
    "len00=len(y_pred[y_pred[\"pred_0\"]==1])\n",
    "print(\"The number of predicted negative cases: \",len00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted positive cases:  115\n"
     ]
    }
   ],
   "source": [
    "len11=len(y_pred[y_pred[\"pred_1\"]==1])\n",
    "print(\"The number of predicted positive cases: \",len11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 201)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare=pd.concat([y_true,y_pred],axis=1)\n",
    "pd.DataFrame(np.where(compare[\"pred_0\"]==compare[\"y_0\"])).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of correct predictions is 201."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after adjusting the threshold:  0.8375\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy after adjusting the threshold: \",201/240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New confusion matrix: \n",
      " [[103  17]\n",
      " [ 22  98]]\n"
     ]
    }
   ],
   "source": [
    "print(\"New confusion matrix: \\n\",np.array([[103,17],[22,98]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.8166666666666667\n",
      "Specificity:  0.8583333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",98/120)\n",
    "print(\"Specificity: \",103/120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN=KNeighborsClassifier(n_neighbors=6,weights=\"uniform\",algorithm=\"brute\",leaf_size=35,p=1,n_jobs=-1)\n",
    "scores=cross_val_score(KNN,X,np.asarray(y).reshape(240,),cv=10)\n",
    "print(\"Accuracy: \",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8291666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR=LogisticRegression(penalty=\"l2\",C=0.05,class_weight=\"liblinear\",solver=\"lbfgs\",max_iter=100,multi_class=\"auto\",n_jobs=-1,warm_start=False,random_state=0)\n",
    "scores=cross_val_score(LR,X,np.asarray(y).reshape(240,),cv=12)\n",
    "print(\"Accuracy: \",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for the Naive Bayes model:  0.8291666666666666\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(LR, X, np.asarray(y).reshape(240,), cv=12)\n",
    "AUC = roc_auc_score(y, y_pred)\n",
    "print(\"AUC for the Naive Bayes model: \",AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[ 99  21]\n",
      " [ 20 100]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n\",confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.8333333333333334\n",
      "Specificity:  0.825\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",100/120)\n",
    "print(\"Specificity: \",99/120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.613858</td>\n",
       "      <td>0.386142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.463046</td>\n",
       "      <td>0.536954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.552706</td>\n",
       "      <td>0.447294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.864809</td>\n",
       "      <td>0.135191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.861123</td>\n",
       "      <td>0.138877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_0    pred_1\n",
       "0  0.613858  0.386142\n",
       "1  0.463046  0.536954\n",
       "2  0.552706  0.447294\n",
       "3  0.864809  0.135191\n",
       "4  0.861123  0.138877"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =pd.DataFrame((cross_val_predict(LR, X, y, cv=12,method=\"predict_proba\"))).rename(columns={0:\"pred_0\",1:\"pred_1\"})\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs1=y_pred[[\"pred_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "thresholds=np.arange(0,1,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs,threshold):\n",
    "    return (pos_probs >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "scores=[f1_score(y, to_labels(y_probs1,t)) for t in thresholds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.498, 0.8298755186721992)\n"
     ]
    }
   ],
   "source": [
    "ix=np.argmax(scores)\n",
    "print((thresholds[ix],scores[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 >=0.498),1,y_pred.pred_0)\n",
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 < 0.498),0,y_pred.pred_0)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 >=0.498),1,y_pred.pred_1)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 <0.498),0,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 == y_pred.pred_1),0,y_pred.pred_0)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_0 == y_pred.pred_1),1,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted negative cases:  119\n"
     ]
    }
   ],
   "source": [
    "len00=len(y_pred[y_pred[\"pred_0\"]==1])\n",
    "print(\"The number of predicted negative cases: \",len00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted positive cases:  121\n"
     ]
    }
   ],
   "source": [
    "len11=len(y_pred[y_pred[\"pred_1\"]==1])\n",
    "print(\"The number of predicted positive cases: \",len11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 199)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare=pd.concat([y_true,y_pred],axis=1)\n",
    "pd.DataFrame(np.where(compare[\"pred_0\"]==compare[\"y_0\"])).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maxed out the Logistic Regression model already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  1.0  0.0\n",
       "1  1.0  0.0\n",
       "2  1.0  0.0\n",
       "3  1.0  0.0\n",
       "4  1.0  0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ienc=OneHotEncoder(handle_unknown=\"ignore\")\n",
    "y=ienc.fit_transform(y)\n",
    "y=pd.DataFrame(y.toarray())\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 45)\n",
      "(72, 45)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "length=X_train.shape[1]\n",
    "num_classes=y_test.shape[1]\n",
    "print(length)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(length, activation='relu', input_shape=(length,)))\n",
    "    model.add(Dense(65, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(65,activation=\"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(65,activation=\"relu\"))\n",
    "    model.add(Dropout(0.45))\n",
    "    model.add(Dense(65,activation=\"relu\"))\n",
    "    model.add(Dropout(0.45))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    opt=Adam(lr=0.003)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168 samples, validate on 72 samples\n",
      "Epoch 1/15\n",
      " - 20s - loss: 0.6867 - acc: 0.5417 - val_loss: 0.5884 - val_acc: 0.7639\n",
      "Epoch 2/15\n",
      " - 0s - loss: 0.5921 - acc: 0.6845 - val_loss: 0.4920 - val_acc: 0.8056\n",
      "Epoch 3/15\n",
      " - 0s - loss: 0.5483 - acc: 0.7202 - val_loss: 0.4709 - val_acc: 0.8472\n",
      "Epoch 4/15\n",
      " - 0s - loss: 0.5151 - acc: 0.7857 - val_loss: 0.4973 - val_acc: 0.8333\n",
      "Epoch 5/15\n",
      " - 0s - loss: 0.5374 - acc: 0.7917 - val_loss: 0.4769 - val_acc: 0.7917\n",
      "Epoch 6/15\n",
      " - 0s - loss: 0.4421 - acc: 0.8274 - val_loss: 0.4498 - val_acc: 0.8056\n",
      "Epoch 7/15\n",
      " - 0s - loss: 0.4392 - acc: 0.8036 - val_loss: 0.4336 - val_acc: 0.8194\n",
      "Epoch 8/15\n",
      " - 0s - loss: 0.4854 - acc: 0.8274 - val_loss: 0.4235 - val_acc: 0.8333\n",
      "Epoch 9/15\n",
      " - 0s - loss: 0.4984 - acc: 0.8750 - val_loss: 0.3996 - val_acc: 0.8333\n",
      "Epoch 10/15\n",
      " - 0s - loss: 0.4001 - acc: 0.8571 - val_loss: 0.3870 - val_acc: 0.8889\n",
      "Epoch 11/15\n",
      " - 0s - loss: 0.4287 - acc: 0.8333 - val_loss: 0.3881 - val_acc: 0.8472\n",
      "Epoch 12/15\n",
      " - 0s - loss: 0.3654 - acc: 0.8929 - val_loss: 0.4049 - val_acc: 0.8611\n",
      "Epoch 13/15\n",
      " - 0s - loss: 0.3597 - acc: 0.8571 - val_loss: 0.3849 - val_acc: 0.8750\n",
      "Epoch 14/15\n",
      " - 0s - loss: 0.3400 - acc: 0.8750 - val_loss: 0.3739 - val_acc: 0.8889\n",
      "Epoch 15/15\n",
      " - 0s - loss: 0.3774 - acc: 0.8690 - val_loss: 0.3931 - val_acc: 0.9028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39311499065823025, 0.9027777777777778]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=classification_model()\n",
    "model.fit(X_train,y_train,validation_data=(X_test, y_test),epochs=15, verbose=2)\n",
    "model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.133888</td>\n",
       "      <td>0.866112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.991158</td>\n",
       "      <td>0.008842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.996860</td>\n",
       "      <td>0.003140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.954793</td>\n",
       "      <td>0.045207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.928796</td>\n",
       "      <td>0.071204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_0    pred_1\n",
       "0  0.133888  0.866112\n",
       "1  0.991158  0.008842\n",
       "2  0.996860  0.003140\n",
       "3  0.954793  0.045207\n",
       "4  0.928796  0.071204"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=pd.DataFrame(model.predict(X_test)).rename(columns={0:\"pred_0\",1:\"pred_1\"})\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs1=y_pred[[\"pred_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "thresholds=np.arange(0,1,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs,threshold):\n",
    "    return (pos_probs >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_status=pd.DataFrame(ienc.inverse_transform(y_test)).rename(columns={0:\"status\"})\n",
    "y_status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "scores=[f1_score(y_status, to_labels(y_probs1,t)) for t in thresholds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.41400000000000003, 0.918918918918919)\n"
     ]
    }
   ],
   "source": [
    "ix=np.argmax(scores)\n",
    "print((thresholds[ix],scores[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_probs1[y_probs1[\"pred_1\"]>=0.414])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 >=0.414),1,y_pred.pred_0)\n",
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 < 0.414),0,y_pred.pred_0)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 >=0.414),1,y_pred.pred_1)\n",
    "y_pred[\"pred_1\"]=np.where((y_pred.pred_1 <0.414),0,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"pred_0\"]=np.where((y_pred.pred_0 == y_pred.pred_1),0,y_pred.pred_0)\n",
    "#y_pred[\"pred_1\"]=np.where((y_pred.pred_0 == y_pred.pred_1),1,y_pred.pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted negative cases:  35\n"
     ]
    }
   ],
   "source": [
    "len00=len(y_pred[y_pred[\"pred_0\"]==1])\n",
    "print(\"The number of predicted negative cases: \",len00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted positive cases:  37\n"
     ]
    }
   ],
   "source": [
    "len11=len(y_pred[y_pred[\"pred_1\"]==1])\n",
    "print(\"The number of predicted positive cases: \",len11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true=pd.DataFrame(ienc.inverse_transform(y_test))\n",
    "y_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=pd.DataFrame(ienc.inverse_transform(y_pred))\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data after adjusting the threshold:  0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy on test data after adjusting the threshold: \",accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix after adjusting the threshold: \n",
      " [[32  3]\n",
      " [ 3 34]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion matrix after adjusting the threshold: \\n\",confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.918918918918919\n",
      "Specificity:  0.9142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \",34/37)\n",
    "print(\"Specificity: \",32/35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test data after adjusting the threshold,  0.9166023166023165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"AUC on test data after adjusting the threshold, \",roc_auc_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
