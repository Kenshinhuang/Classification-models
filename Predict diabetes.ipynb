{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size = 5> The diabetes dataset </font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Pre-processing of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden_weight_loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital_thrush</th>\n",
       "      <th>visual_blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed_healing</th>\n",
       "      <th>partial_paresis</th>\n",
       "      <th>muscle_stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Gender Polyuria Polydipsia sudden_weight_loss weakness Polyphagia  \\\n",
       "0   40   Male       No        Yes                 No      Yes         No   \n",
       "1   58   Male       No         No                 No      Yes         No   \n",
       "2   41   Male      Yes         No                 No      Yes        Yes   \n",
       "3   45   Male       No         No                Yes      Yes        Yes   \n",
       "4   60   Male      Yes        Yes                Yes      Yes        Yes   \n",
       "\n",
       "  Genital_thrush visual_blurring Itching Irritability delayed_healing  \\\n",
       "0             No              No     Yes           No             Yes   \n",
       "1             No             Yes      No           No              No   \n",
       "2             No              No     Yes           No             Yes   \n",
       "3            Yes              No     Yes           No             Yes   \n",
       "4             No             Yes     Yes          Yes             Yes   \n",
       "\n",
       "  partial_paresis muscle_stiffness Alopecia Obesity     class  \n",
       "0              No              Yes      Yes     Yes  Positive  \n",
       "1             Yes               No      Yes      No  Positive  \n",
       "2              No              Yes      Yes      No  Positive  \n",
       "3              No               No       No      No  Positive  \n",
       "4             Yes              Yes      Yes     Yes  Positive  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"diabetes_data_upload.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except \"Age\", all attributes are categorical and have values either \"yes\" or \"no\". We are going to apply one-hot encoding to all attributes except \"Age\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   20   21   22   23  \\\n",
       "0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  ...  0.0  1.0  1.0  0.0   \n",
       "1  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  ...  1.0  0.0  0.0  1.0   \n",
       "2  0.0  1.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  ...  0.0  1.0  1.0  0.0   \n",
       "3  0.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  ...  0.0  1.0  1.0  0.0   \n",
       "4  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  ...  0.0  1.0  0.0  1.0   \n",
       "\n",
       "    24   25   26   27   28   29  \n",
       "0  0.0  1.0  0.0  1.0  0.0  1.0  \n",
       "1  1.0  0.0  0.0  1.0  1.0  0.0  \n",
       "2  0.0  1.0  0.0  1.0  1.0  0.0  \n",
       "3  1.0  0.0  1.0  0.0  1.0  0.0  \n",
       "4  0.0  1.0  0.0  1.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc=OneHotEncoder(handle_unknown=\"ignore\")\n",
    "sub_df=df.drop([\"Age\",\"class\"],axis=1)\n",
    "sub_df=pd.DataFrame(enc.fit_transform(sub_df).toarray())\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age    0    1    2    3    4    5    6    7    8  ...   20   21   22   23  \\\n",
       "0   40  0.0  1.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  ...  0.0  1.0  1.0  0.0   \n",
       "1   58  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  1.0  0.0  0.0  1.0   \n",
       "2   41  0.0  1.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  1.0  1.0  0.0   \n",
       "3   45  0.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  1.0  1.0  0.0   \n",
       "4   60  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  0.0  1.0  0.0  1.0   \n",
       "\n",
       "    24   25   26   27   28   29  \n",
       "0  0.0  1.0  0.0  1.0  0.0  1.0  \n",
       "1  1.0  0.0  0.0  1.0  1.0  0.0  \n",
       "2  0.0  1.0  0.0  1.0  1.0  0.0  \n",
       "3  1.0  0.0  1.0  0.0  1.0  0.0  \n",
       "4  0.0  1.0  0.0  1.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age=df[[\"Age\"]]\n",
    "X=pd.concat([age,sub_df],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  0.0  1.0\n",
       "1  0.0  1.0\n",
       "2  0.0  1.0\n",
       "3  0.0  1.0\n",
       "4  0.0  1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=pd.DataFrame(enc.fit_transform(df[[\"class\"]]).toarray())\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model with TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# numFeatures is the number of features in our input data.\n",
    "# In the iris dataset, this number is '4'.\n",
    "numFeatures = trainX.shape[1]\n",
    "\n",
    "# numLabels is the number of classes our data points can be in.\n",
    "# In the iris dataset, this number is '3'.\n",
    "numLabels = trainY.shape[1]\n",
    "\n",
    "\n",
    "# Placeholders\n",
    "# 'None' means TensorFlow shouldn't expect a fixed number in that dimension\n",
    "X = tf.placeholder(tf.float32, [None, numFeatures]) \n",
    "yGold = tf.placeholder(tf.float32, [None, numLabels]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly sample from a normal distribution with standard deviation .01\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([numFeatures,numLabels],\n",
    "                                       mean=0,\n",
    "                                       stddev=0.001,\n",
    "                                       name=\"weights\"))\n",
    "\n",
    "bias = tf.Variable(tf.random_normal([1,numLabels],\n",
    "                                    mean=0,\n",
    "                                    stddev=0.001,\n",
    "                                    name=\"bias\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three-component breakdown of the Logistic Regression equation.\n",
    "# Note that these feed into each other.\n",
    "apply_weights_OP = tf.matmul(X, weights, name=\"apply_weights\")\n",
    "add_bias_OP = tf.add(apply_weights_OP, bias, name=\"add_bias\") \n",
    "activation_OP = tf.nn.sigmoid(add_bias_OP, name=\"activation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Epochs in our training\n",
    "numEpochs = 80000\n",
    "\n",
    "# Defining our learning rate iterations (decay)\n",
    "learningRate = tf.train.exponential_decay(learning_rate=0.0001,\n",
    "                                          global_step= 1,\n",
    "                                          decay_steps=trainX.shape[0],\n",
    "                                          decay_rate= 0.9,\n",
    "                                          staircase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining our cost function - Squared Mean Error\n",
    "cost_OP = tf.nn.l2_loss(activation_OP-yGold, name=\"squared_error_cost\")\n",
    "\n",
    "#Defining our Gradient Descent\n",
    "training_OP = tf.train.GradientDescentOptimizer(learningRate).minimize(cost_OP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorflow session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize our weights and biases variables.\n",
    "init_OP = tf.global_variables_initializer()\n",
    "\n",
    "# Initialize all tensorflow variables\n",
    "sess.run(init_OP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmax(activation_OP, 1) returns the label with the most probability\n",
    "# argmax(yGold, 1) is the correct label\n",
    "correct_predictions_OP = tf.equal(tf.argmax(activation_OP,1),tf.argmax(yGold,1))\n",
    "\n",
    "# If every false prediction is 0 and every true prediction is 1, the average returns us the accuracy\n",
    "accuracy_OP = tf.reduce_mean(tf.cast(correct_predictions_OP, \"float\"))\n",
    "\n",
    "# Summary op for regression output\n",
    "activation_summary_OP = tf.summary.histogram(\"output\", activation_OP)\n",
    "\n",
    "# Summary op for accuracy\n",
    "accuracy_summary_OP = tf.summary.scalar(\"accuracy\", accuracy_OP)\n",
    "\n",
    "# Summary op for cost\n",
    "cost_summary_OP = tf.summary.scalar(\"cost\", cost_OP)\n",
    "\n",
    "# Summary ops to check how variables (W, b) are updating after each iteration\n",
    "weightSummary = tf.summary.histogram(\"weights\", weights.eval(session=sess))\n",
    "biasSummary = tf.summary.histogram(\"biases\", bias.eval(session=sess))\n",
    "\n",
    "# Merge all summaries\n",
    "merged = tf.summary.merge([activation_summary_OP, accuracy_summary_OP, cost_summary_OP, weightSummary, biasSummary])\n",
    "\n",
    "# Summary writer\n",
    "writer = tf.summary.FileWriter(\"summary_logs\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.600575, cost 114.887, change in cost 114.887\n",
      "step 1000, training accuracy 0.804598, cost 56.6106, change in cost 58.2766\n",
      "step 2000, training accuracy 0.882184, cost 32.6268, change in cost 23.9838\n",
      "step 3000, training accuracy 0.908046, cost 24.7462, change in cost 7.8806\n",
      "step 4000, training accuracy 0.925287, cost 22.8926, change in cost 1.85355\n",
      "step 5000, training accuracy 0.925287, cost 22.014, change in cost 0.87863\n",
      "step 6000, training accuracy 0.939655, cost 21.365, change in cost 0.648972\n",
      "step 7000, training accuracy 0.942529, cost 20.863, change in cost 0.502064\n",
      "step 8000, training accuracy 0.942529, cost 20.4613, change in cost 0.401644\n",
      "step 9000, training accuracy 0.942529, cost 20.1317, change in cost 0.32966\n",
      "step 10000, training accuracy 0.939655, cost 19.8556, change in cost 0.276112\n",
      "step 11000, training accuracy 0.939655, cost 19.6205, change in cost 0.235065\n",
      "step 12000, training accuracy 0.939655, cost 19.4177, change in cost 0.202839\n",
      "step 13000, training accuracy 0.939655, cost 19.2406, change in cost 0.177019\n",
      "step 14000, training accuracy 0.939655, cost 19.0847, change in cost 0.155981\n",
      "step 15000, training accuracy 0.939655, cost 18.9461, change in cost 0.138596\n",
      "step 16000, training accuracy 0.939655, cost 18.822, change in cost 0.124035\n",
      "step 17000, training accuracy 0.939655, cost 18.7103, change in cost 0.111721\n",
      "step 18000, training accuracy 0.939655, cost 18.6091, change in cost 0.101204\n",
      "step 19000, training accuracy 0.939655, cost 18.517, change in cost 0.092144\n",
      "step 20000, training accuracy 0.939655, cost 18.4327, change in cost 0.08428\n",
      "step 21000, training accuracy 0.939655, cost 18.3553, change in cost 0.0774097\n",
      "step 22000, training accuracy 0.939655, cost 18.2839, change in cost 0.071373\n",
      "step 23000, training accuracy 0.939655, cost 18.2179, change in cost 0.0660343\n",
      "step 24000, training accuracy 0.939655, cost 18.1566, change in cost 0.0612888\n",
      "step 25000, training accuracy 0.939655, cost 18.0995, change in cost 0.0570507\n",
      "step 26000, training accuracy 0.939655, cost 18.0463, change in cost 0.0532551\n",
      "step 27000, training accuracy 0.939655, cost 17.9964, change in cost 0.049839\n",
      "step 28000, training accuracy 0.939655, cost 17.9497, change in cost 0.0467491\n",
      "step 29000, training accuracy 0.939655, cost 17.9057, change in cost 0.0439453\n",
      "step 30000, training accuracy 0.939655, cost 17.8643, change in cost 0.0414047\n",
      "step 31000, training accuracy 0.939655, cost 17.8252, change in cost 0.0390797\n",
      "step 32000, training accuracy 0.939655, cost 17.7883, change in cost 0.0369511\n",
      "step 33000, training accuracy 0.939655, cost 17.7533, change in cost 0.0350037\n",
      "step 34000, training accuracy 0.939655, cost 17.7201, change in cost 0.033205\n",
      "step 35000, training accuracy 0.939655, cost 17.6885, change in cost 0.0315552\n",
      "step 36000, training accuracy 0.939655, cost 17.6585, change in cost 0.0300255\n",
      "step 37000, training accuracy 0.939655, cost 17.6299, change in cost 0.028614\n",
      "step 38000, training accuracy 0.939655, cost 17.6026, change in cost 0.027298\n",
      "step 39000, training accuracy 0.939655, cost 17.5765, change in cost 0.0260715\n",
      "step 40000, training accuracy 0.936782, cost 17.5516, change in cost 0.0249481\n",
      "step 41000, training accuracy 0.936782, cost 17.5277, change in cost 0.02388\n",
      "step 42000, training accuracy 0.936782, cost 17.5048, change in cost 0.022892\n",
      "step 43000, training accuracy 0.942529, cost 17.4828, change in cost 0.0219631\n",
      "step 44000, training accuracy 0.942529, cost 17.4618, change in cost 0.0210896\n",
      "step 45000, training accuracy 0.942529, cost 17.4415, change in cost 0.0202713\n",
      "step 46000, training accuracy 0.942529, cost 17.422, change in cost 0.0195122\n",
      "step 47000, training accuracy 0.942529, cost 17.4032, change in cost 0.0187874\n",
      "step 48000, training accuracy 0.942529, cost 17.3851, change in cost 0.0181026\n",
      "step 49000, training accuracy 0.942529, cost 17.3676, change in cost 0.0174618\n",
      "step 50000, training accuracy 0.942529, cost 17.3508, change in cost 0.0168629\n",
      "step 51000, training accuracy 0.942529, cost 17.3345, change in cost 0.0162716\n",
      "step 52000, training accuracy 0.942529, cost 17.3187, change in cost 0.0157452\n",
      "step 53000, training accuracy 0.942529, cost 17.3035, change in cost 0.0152187\n",
      "step 54000, training accuracy 0.942529, cost 17.2888, change in cost 0.0147285\n",
      "step 55000, training accuracy 0.942529, cost 17.2745, change in cost 0.0142746\n",
      "step 56000, training accuracy 0.942529, cost 17.2607, change in cost 0.013813\n",
      "step 57000, training accuracy 0.942529, cost 17.2473, change in cost 0.0134182\n",
      "step 58000, training accuracy 0.942529, cost 17.2343, change in cost 0.0129948\n",
      "step 59000, training accuracy 0.942529, cost 17.2217, change in cost 0.0126266\n",
      "step 60000, training accuracy 0.942529, cost 17.2094, change in cost 0.0122585\n",
      "step 61000, training accuracy 0.942529, cost 17.1975, change in cost 0.0119152\n",
      "step 62000, training accuracy 0.942529, cost 17.1859, change in cost 0.0115814\n",
      "step 63000, training accuracy 0.942529, cost 17.1746, change in cost 0.0112629\n",
      "step 64000, training accuracy 0.942529, cost 17.1637, change in cost 0.0109615\n",
      "step 65000, training accuracy 0.942529, cost 17.153, change in cost 0.0106697\n",
      "step 66000, training accuracy 0.942529, cost 17.1426, change in cost 0.0103874\n",
      "step 67000, training accuracy 0.942529, cost 17.1325, change in cost 0.0101357\n",
      "step 68000, training accuracy 0.942529, cost 17.1226, change in cost 0.00985336\n",
      "step 69000, training accuracy 0.942529, cost 17.113, change in cost 0.00963211\n",
      "step 70000, training accuracy 0.942529, cost 17.1036, change in cost 0.00937462\n",
      "step 71000, training accuracy 0.942529, cost 17.0945, change in cost 0.00915909\n",
      "step 72000, training accuracy 0.942529, cost 17.0855, change in cost 0.008955\n",
      "step 73000, training accuracy 0.942529, cost 17.0768, change in cost 0.00871086\n",
      "step 74000, training accuracy 0.942529, cost 17.0683, change in cost 0.00853729\n",
      "step 75000, training accuracy 0.942529, cost 17.0599, change in cost 0.00833893\n",
      "step 76000, training accuracy 0.942529, cost 17.0518, change in cost 0.00812531\n",
      "step 77000, training accuracy 0.942529, cost 17.0438, change in cost 0.00797653\n",
      "step 78000, training accuracy 0.942529, cost 17.036, change in cost 0.00779915\n",
      "step 79000, training accuracy 0.942529, cost 17.0284, change in cost 0.00759506\n",
      "final accuracy on test set: 0.95348835\n"
     ]
    }
   ],
   "source": [
    "# Initialize reporting variables\n",
    "cost = 0\n",
    "diff = 1\n",
    "epoch_values = []\n",
    "accuracy_values = []\n",
    "cost_values = []\n",
    "\n",
    "# Training epochs\n",
    "for i in range(numEpochs):\n",
    "    if i > 1 and diff < .0001:\n",
    "        print(\"change in cost %g; convergence.\"%diff)\n",
    "        break\n",
    "    else:\n",
    "        # Run training step\n",
    "        step = sess.run(training_OP, feed_dict={X: trainX, yGold: trainY})\n",
    "        # Report occasional stats\n",
    "        if i % 1000 == 0:\n",
    "            # Add epoch to epoch_values\n",
    "            epoch_values.append(i)\n",
    "            # Generate accuracy stats on test data\n",
    "            train_accuracy, newCost = sess.run([accuracy_OP, cost_OP], feed_dict={X: trainX, yGold: trainY})\n",
    "            # Add accuracy to live graphing variable\n",
    "            accuracy_values.append(train_accuracy)\n",
    "            # Add cost to live graphing variable\n",
    "            cost_values.append(newCost)\n",
    "            # Re-assign values for variables\n",
    "            diff = abs(newCost - cost)\n",
    "            cost = newCost\n",
    "\n",
    "            #generate print statements\n",
    "            print(\"step %d, training accuracy %g, cost %g, change in cost %g\"%(i, train_accuracy, newCost, diff))\n",
    "\n",
    "\n",
    "# How well do we perform on held-out test data?\n",
    "print(\"final accuracy on test set: %s\" %str(sess.run(accuracy_OP, \n",
    "                                                     feed_dict={X: testX, \n",
    "                                                                yGold: testY})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the accuracy and cost values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(accuracy_values,cost_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"sess.run\" compares the predicted label with the actual label and outputs True for correct predictions and False for incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=sess.run(correct_predictions_OP,feed_dict={X:testX,yGold:testY})\n",
    "pred=pd.DataFrame(data=array, columns=[\"Correct=True\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the rows that the model missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct=True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Correct=True\n",
       "39          False\n",
       "41          False\n",
       "58          False\n",
       "72          False\n",
       "100         False\n",
       "121         False\n",
       "135         False\n",
       "171         False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect=pred[pred[\"Correct=True\"] != True]\n",
    "incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden_weight_loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital_thrush</th>\n",
       "      <th>visual_blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed_healing</th>\n",
       "      <th>partial_paresis</th>\n",
       "      <th>muscle_stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>50</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>48</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>35</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>48</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender Polyuria Polydipsia sudden_weight_loss weakness Polyphagia  \\\n",
       "39    30  Female      Yes         No                Yes      Yes        Yes   \n",
       "41    50  Female      Yes        Yes                Yes       No        Yes   \n",
       "58    59  Female       No         No                 No       No         No   \n",
       "72    65  Female       No         No                 No       No         No   \n",
       "100   48  Female      Yes        Yes                Yes       No        Yes   \n",
       "121   35    Male      Yes        Yes                 No      Yes        Yes   \n",
       "135   66    Male       No         No                 No      Yes         No   \n",
       "171   48    Male      Yes        Yes                 No      Yes         No   \n",
       "\n",
       "    Genital_thrush visual_blurring Itching Irritability delayed_healing  \\\n",
       "39              No              No      No           No             Yes   \n",
       "41              No              No      No           No             Yes   \n",
       "58              No              No      No           No              No   \n",
       "72             Yes              No      No           No              No   \n",
       "100            Yes              No      No          Yes             Yes   \n",
       "121            Yes              No     Yes           No             Yes   \n",
       "135            Yes             Yes      No          Yes             Yes   \n",
       "171            Yes             Yes     Yes           No              No   \n",
       "\n",
       "    partial_paresis muscle_stiffness Alopecia Obesity     class  \n",
       "39               No               No       No      No  Positive  \n",
       "41              Yes               No       No      No  Positive  \n",
       "58               No               No       No      No  Positive  \n",
       "72               No               No       No      No  Positive  \n",
       "100              No              Yes      Yes     Yes  Positive  \n",
       "121             Yes              Yes       No      No  Positive  \n",
       "135             Yes              Yes      Yes      No  Positive  \n",
       "171              No               No       No      No  Positive  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect=df.iloc[[39,41,58,72,100,121,135,171],:]\n",
    "incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, all the missed \"class\" are positive. The model correctly classified all negative instances.That tells us the model has a 100% specificity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the sensitivity of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col_1</th>\n",
       "      <th>Col_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Col_1  Col_2\n",
       "275    1.0    0.0\n",
       "93     0.0    1.0\n",
       "6      0.0    1.0\n",
       "167    0.0    1.0\n",
       "90     0.0    1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY=testY.rename(columns={0:\"Col_1\",1:\"Col_2\"})\n",
    "testY.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute sensitivity. Sensitivity = # of true positive divided by total # of positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sensitivity of the model is:  0.9279279279279279\n"
     ]
    }
   ],
   "source": [
    "testY_yes=testY[testY[\"Col_2\"] == 1] # Select all the positive instances in the test data. \n",
    "print(\"The sensitivity of the model is: \", (len(testY_yes)-len(incorrect))/len(testY_yes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a sensitivity of 92.8% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with TensorFlow has a sensitivity of 92.8%, specificity of 100%  and an overall accuracy of 95.35% on test data. Not bad at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try neural network with Keras and see if we can get beyond 95.35%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Neural network with Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "length=trainX.shape[1]\n",
    "num_classes=testY.shape[1]\n",
    "\n",
    "# Load the libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# define classification model\n",
    "\n",
    "def classification_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(length, activation='relu', input_shape=(length,)))\n",
    "    model.add(Dense(550, activation='tanh'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 348 samples, validate on 172 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.7165 - acc: 0.5172 - val_loss: 0.5931 - val_acc: 0.6802\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6182 - acc: 0.6782 - val_loss: 0.5509 - val_acc: 0.6628\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.5556 - acc: 0.7241 - val_loss: 0.4876 - val_acc: 0.7093\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.4807 - acc: 0.7816 - val_loss: 0.4154 - val_acc: 0.8779\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.4020 - acc: 0.8563 - val_loss: 0.3632 - val_acc: 0.8895\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.3596 - acc: 0.8534 - val_loss: 0.3432 - val_acc: 0.8256\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.3071 - acc: 0.8966 - val_loss: 0.2788 - val_acc: 0.9070\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.2684 - acc: 0.8966 - val_loss: 0.2617 - val_acc: 0.9070\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.3171 - acc: 0.8563 - val_loss: 0.3067 - val_acc: 0.8256\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.4461 - acc: 0.8161 - val_loss: 0.4163 - val_acc: 0.7791\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.2645 - acc: 0.8966 - val_loss: 0.2240 - val_acc: 0.9302\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.2249 - acc: 0.9138 - val_loss: 0.2161 - val_acc: 0.9302\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.2169 - acc: 0.9080 - val_loss: 0.2265 - val_acc: 0.9012\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.2118 - acc: 0.9253 - val_loss: 0.2149 - val_acc: 0.9302\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.2109 - acc: 0.9080 - val_loss: 0.2217 - val_acc: 0.9128\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.2145 - acc: 0.9052 - val_loss: 0.2105 - val_acc: 0.9128\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.2339 - acc: 0.9023 - val_loss: 0.1927 - val_acc: 0.9302\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.2382 - acc: 0.8908 - val_loss: 0.2332 - val_acc: 0.8895\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.2518 - acc: 0.9052 - val_loss: 0.3250 - val_acc: 0.8140\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.2082 - acc: 0.9052 - val_loss: 0.1816 - val_acc: 0.9477\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.1870 - acc: 0.9195 - val_loss: 0.1802 - val_acc: 0.9419\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.1999 - acc: 0.9109 - val_loss: 0.1850 - val_acc: 0.9360\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.1835 - acc: 0.9397 - val_loss: 0.1797 - val_acc: 0.9360\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.1923 - acc: 0.9224 - val_loss: 0.2034 - val_acc: 0.9012\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.2135 - acc: 0.9195 - val_loss: 0.2274 - val_acc: 0.8837\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.2224 - acc: 0.9023 - val_loss: 0.1749 - val_acc: 0.9360\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.1855 - acc: 0.9195 - val_loss: 0.1920 - val_acc: 0.9360\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.1850 - acc: 0.9138 - val_loss: 0.1648 - val_acc: 0.9419\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.1707 - acc: 0.9224 - val_loss: 0.1650 - val_acc: 0.9477\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.1702 - acc: 0.9282 - val_loss: 0.1583 - val_acc: 0.9419\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.1752 - acc: 0.9138 - val_loss: 0.1608 - val_acc: 0.9477\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.1777 - acc: 0.9282 - val_loss: 0.1570 - val_acc: 0.9360\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.1726 - acc: 0.9339 - val_loss: 0.1613 - val_acc: 0.9419\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.1636 - acc: 0.9339 - val_loss: 0.2120 - val_acc: 0.8953\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.2234 - acc: 0.9138 - val_loss: 0.1561 - val_acc: 0.9360\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.1686 - acc: 0.9282 - val_loss: 0.1537 - val_acc: 0.9419\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.1674 - acc: 0.9397 - val_loss: 0.1676 - val_acc: 0.9419\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.1899 - acc: 0.9224 - val_loss: 0.1636 - val_acc: 0.9360\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1644 - acc: 0.9310 - val_loss: 0.1476 - val_acc: 0.9360\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.1623 - acc: 0.9282 - val_loss: 0.1764 - val_acc: 0.9419\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.1602 - acc: 0.9339 - val_loss: 0.1459 - val_acc: 0.9477\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.1550 - acc: 0.9368 - val_loss: 0.1678 - val_acc: 0.9419\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.1663 - acc: 0.9310 - val_loss: 0.1465 - val_acc: 0.9477\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.1664 - acc: 0.9397 - val_loss: 0.1851 - val_acc: 0.9070\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.2256 - acc: 0.8937 - val_loss: 0.2763 - val_acc: 0.8779\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.2133 - acc: 0.9138 - val_loss: 0.1517 - val_acc: 0.9419\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.1782 - acc: 0.9310 - val_loss: 0.1461 - val_acc: 0.9419\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.1705 - acc: 0.9195 - val_loss: 0.1477 - val_acc: 0.9360\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.1749 - acc: 0.9138 - val_loss: 0.2124 - val_acc: 0.9128\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.1705 - acc: 0.9425 - val_loss: 0.1608 - val_acc: 0.9477\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.1670 - acc: 0.9195 - val_loss: 0.1382 - val_acc: 0.9419\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.1544 - acc: 0.9253 - val_loss: 0.1438 - val_acc: 0.9419\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.1679 - acc: 0.9368 - val_loss: 0.1422 - val_acc: 0.9419\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.1778 - acc: 0.9253 - val_loss: 0.1359 - val_acc: 0.9360\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.1691 - acc: 0.9310 - val_loss: 0.1375 - val_acc: 0.9477\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.1584 - acc: 0.9425 - val_loss: 0.1463 - val_acc: 0.9419\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.1664 - acc: 0.9368 - val_loss: 0.1817 - val_acc: 0.9419\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.1574 - acc: 0.9282 - val_loss: 0.1687 - val_acc: 0.9535\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.1655 - acc: 0.9310 - val_loss: 0.2005 - val_acc: 0.9186\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.1617 - acc: 0.9310 - val_loss: 0.1375 - val_acc: 0.9535\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.1468 - acc: 0.9368 - val_loss: 0.1676 - val_acc: 0.9477\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.1462 - acc: 0.9339 - val_loss: 0.1386 - val_acc: 0.9593\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.1524 - acc: 0.9397 - val_loss: 0.1488 - val_acc: 0.9535\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.1541 - acc: 0.9425 - val_loss: 0.1390 - val_acc: 0.9419\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.1417 - acc: 0.9454 - val_loss: 0.1365 - val_acc: 0.9535\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.1451 - acc: 0.9339 - val_loss: 0.1331 - val_acc: 0.9419\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.1434 - acc: 0.9310 - val_loss: 0.1630 - val_acc: 0.9302\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.1670 - acc: 0.9368 - val_loss: 0.1297 - val_acc: 0.9477\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.1543 - acc: 0.9339 - val_loss: 0.1791 - val_acc: 0.9419\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.2279 - acc: 0.9080 - val_loss: 0.1291 - val_acc: 0.9477\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.2088 - acc: 0.9023 - val_loss: 0.1403 - val_acc: 0.9535\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.2113 - acc: 0.9109 - val_loss: 0.1346 - val_acc: 0.9419\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.1612 - acc: 0.9310 - val_loss: 0.1498 - val_acc: 0.9419\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.1594 - acc: 0.9282 - val_loss: 0.1442 - val_acc: 0.9535\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.1705 - acc: 0.9224 - val_loss: 0.1290 - val_acc: 0.9419\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.1640 - acc: 0.9282 - val_loss: 0.1254 - val_acc: 0.9535\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.1692 - acc: 0.9282 - val_loss: 0.1411 - val_acc: 0.9477\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.1372 - acc: 0.9368 - val_loss: 0.1770 - val_acc: 0.9419\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.1388 - acc: 0.9425 - val_loss: 0.1241 - val_acc: 0.9535\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.1419 - acc: 0.9425 - val_loss: 0.1225 - val_acc: 0.9477\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.1327 - acc: 0.9425 - val_loss: 0.1272 - val_acc: 0.9593\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.1381 - acc: 0.9310 - val_loss: 0.1247 - val_acc: 0.9593\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.1267 - acc: 0.9511 - val_loss: 0.1441 - val_acc: 0.9419\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.1444 - acc: 0.9368 - val_loss: 0.1459 - val_acc: 0.9419\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.1386 - acc: 0.9454 - val_loss: 0.1247 - val_acc: 0.9593\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.1261 - acc: 0.9425 - val_loss: 0.1180 - val_acc: 0.9535\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.1332 - acc: 0.9454 - val_loss: 0.1192 - val_acc: 0.9535\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.1260 - acc: 0.9368 - val_loss: 0.1234 - val_acc: 0.9593\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.1348 - acc: 0.9368 - val_loss: 0.1184 - val_acc: 0.9535\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.1282 - acc: 0.9454 - val_loss: 0.1452 - val_acc: 0.9477\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.1332 - acc: 0.9425 - val_loss: 0.2134 - val_acc: 0.9244\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.2056 - acc: 0.9195 - val_loss: 0.3155 - val_acc: 0.8430\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.1840 - acc: 0.9368 - val_loss: 0.1863 - val_acc: 0.9419\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.1415 - acc: 0.9425 - val_loss: 0.1143 - val_acc: 0.9535\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.1575 - acc: 0.9511 - val_loss: 0.1163 - val_acc: 0.9593\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.1174 - acc: 0.9483 - val_loss: 0.1357 - val_acc: 0.9651\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.1303 - acc: 0.9483 - val_loss: 0.1239 - val_acc: 0.9593\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.1212 - acc: 0.9454 - val_loss: 0.1167 - val_acc: 0.9593\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.1184 - acc: 0.9483 - val_loss: 0.1214 - val_acc: 0.9593\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.1138 - acc: 0.9483 - val_loss: 0.1223 - val_acc: 0.9593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12225702197052711, 0.9593023269675499]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=classification_model()\n",
    "model.fit(trainX,trainY,validation_data=(testX, testY),epochs=100, verbose=2)\n",
    "model.evaluate(testX,testY,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network model delivered a slightly better performance than the model with TensorFlow, yielding a 96% accuracy on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
