{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install imbalanced-learn","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting imbalanced-learn\n  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n\u001b[K     |████████████████████████████████| 167 kB 4.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: joblib>=0.11 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from imbalanced-learn) (0.17.0)\nRequirement already satisfied: numpy>=1.13.3 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from imbalanced-learn) (1.19.4)\nRequirement already satisfied: scipy>=0.19.1 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from imbalanced-learn) (1.5.3)\nRequirement already satisfied: scikit-learn>=0.23 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from imbalanced-learn) (0.23.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\nInstalling collected packages: imbalanced-learn\nSuccessfully installed imbalanced-learn-0.7.0\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nurl=\"https://bd29ee0e-54ab-4daa-9671-d153865d1620.usrfiles.com/ugd/bd29ee_7196538281784381bd575ee5aa302a45.csv\"\ndf=pd.read_csv(url)\ndf.head()","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"         name   mcg   gvh   alm   mit  erl  pox   vac   nuc class\n0  ADT1_YEAST  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22   MIT\n1  ADT2_YEAST  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22   MIT\n2  ADT3_YEAST  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22   MIT\n3  AAR2_YEAST  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22   NUC\n4  AATM_YEAST  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22   MIT","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>mcg</th>\n      <th>gvh</th>\n      <th>alm</th>\n      <th>mit</th>\n      <th>erl</th>\n      <th>pox</th>\n      <th>vac</th>\n      <th>nuc</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ADT1_YEAST</td>\n      <td>0.58</td>\n      <td>0.61</td>\n      <td>0.47</td>\n      <td>0.13</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.48</td>\n      <td>0.22</td>\n      <td>MIT</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ADT2_YEAST</td>\n      <td>0.43</td>\n      <td>0.67</td>\n      <td>0.48</td>\n      <td>0.27</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.53</td>\n      <td>0.22</td>\n      <td>MIT</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ADT3_YEAST</td>\n      <td>0.64</td>\n      <td>0.62</td>\n      <td>0.49</td>\n      <td>0.15</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.53</td>\n      <td>0.22</td>\n      <td>MIT</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAR2_YEAST</td>\n      <td>0.58</td>\n      <td>0.44</td>\n      <td>0.57</td>\n      <td>0.13</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.54</td>\n      <td>0.22</td>\n      <td>NUC</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AATM_YEAST</td>\n      <td>0.42</td>\n      <td>0.44</td>\n      <td>0.48</td>\n      <td>0.54</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.48</td>\n      <td>0.22</td>\n      <td>MIT</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop([\"name\"],axis=1)\ndf.shape","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"(1484, 9)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\ny=df[[\"class\"]]\ny.groupby(\"class\")[\"class\"].count()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"class\nCYT    463\nERL      5\nEXC     35\nME1     44\nME2     51\nME3    163\nMIT    244\nNUC    429\nPOX     20\nVAC     30\nName: class, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ny=pd.DataFrame(le.fit_transform(y),columns=y.columns)\ny.head()","execution_count":4,"outputs":[{"output_type":"stream","text":"/srv/conda/envs/notebook/lib/python3.6/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(**kwargs)\n","name":"stderr"},{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   class\n0      6\n1      6\n2      6\n3      7\n4      6","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.groupby(\"class\")[\"class\"].count()/len(y)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"class\n0    0.311995\n1    0.003369\n2    0.023585\n3    0.029650\n4    0.034367\n5    0.109838\n6    0.164420\n7    0.289084\n8    0.013477\n9    0.020216\nName: class, dtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop([\"class\"],axis=1)\nX.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"    mcg   gvh   alm   mit  erl  pox   vac   nuc\n0  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22\n1  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22\n2  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22\n3  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22\n4  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mcg</th>\n      <th>gvh</th>\n      <th>alm</th>\n      <th>mit</th>\n      <th>erl</th>\n      <th>pox</th>\n      <th>vac</th>\n      <th>nuc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.58</td>\n      <td>0.61</td>\n      <td>0.47</td>\n      <td>0.13</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.48</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.43</td>\n      <td>0.67</td>\n      <td>0.48</td>\n      <td>0.27</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.53</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.64</td>\n      <td>0.62</td>\n      <td>0.49</td>\n      <td>0.15</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.53</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.58</td>\n      <td>0.44</td>\n      <td>0.57</td>\n      <td>0.13</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.54</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.42</td>\n      <td>0.44</td>\n      <td>0.48</td>\n      <td>0.54</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.48</td>\n      <td>0.22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom numpy import set_printoptions\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n\n# feature extraction. We are going to output the selection scores for all features and select the features with the highest scores.\ntest = SelectKBest(score_func=f_classif, k=\"all\")\nfit = test.fit(X, np.asarray(y).reshape(y.shape[0],))\nfeatures = fit.transform(X)\n# summarize scores\nset_printoptions(precision=3)\n\nscores=fit.scores_\nscores=pd.DataFrame(scores)\nscores=scores.rename(columns={0:\"scores\"})\nscores=scores.sort_values(by=[\"scores\"],ascending=False)\nscores","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"       scores\n2  138.798404\n5  116.074130\n0  100.729393\n4   90.884060\n1   72.984406\n3   51.692897\n7   22.013807\n6    4.878718","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>138.798404</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>116.074130</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>100.729393</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>90.884060</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>72.984406</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>51.692897</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>22.013807</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4.878718</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_scores=scores[scores[\"scores\"]>0]\nlen(X_scores)","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"8"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_prime=X.iloc[:,X_scores.index]\nX_prime.head()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"    alm  pox   mcg  erl   gvh   mit   nuc   vac\n0  0.47  0.0  0.58  0.5  0.61  0.13  0.22  0.48\n1  0.48  0.0  0.43  0.5  0.67  0.27  0.22  0.53\n2  0.49  0.0  0.64  0.5  0.62  0.15  0.22  0.53\n3  0.57  0.0  0.58  0.5  0.44  0.13  0.22  0.54\n4  0.48  0.0  0.42  0.5  0.44  0.54  0.22  0.48","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alm</th>\n      <th>pox</th>\n      <th>mcg</th>\n      <th>erl</th>\n      <th>gvh</th>\n      <th>mit</th>\n      <th>nuc</th>\n      <th>vac</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.47</td>\n      <td>0.0</td>\n      <td>0.58</td>\n      <td>0.5</td>\n      <td>0.61</td>\n      <td>0.13</td>\n      <td>0.22</td>\n      <td>0.48</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.48</td>\n      <td>0.0</td>\n      <td>0.43</td>\n      <td>0.5</td>\n      <td>0.67</td>\n      <td>0.27</td>\n      <td>0.22</td>\n      <td>0.53</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.49</td>\n      <td>0.0</td>\n      <td>0.64</td>\n      <td>0.5</td>\n      <td>0.62</td>\n      <td>0.15</td>\n      <td>0.22</td>\n      <td>0.53</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.57</td>\n      <td>0.0</td>\n      <td>0.58</td>\n      <td>0.5</td>\n      <td>0.44</td>\n      <td>0.13</td>\n      <td>0.22</td>\n      <td>0.54</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.48</td>\n      <td>0.0</td>\n      <td>0.42</td>\n      <td>0.5</td>\n      <td>0.44</td>\n      <td>0.54</td>\n      <td>0.22</td>\n      <td>0.48</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nX_prime=pd.DataFrame(scaler.fit_transform(X_prime),columns=X_prime.columns)\nX_prime.head()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"        alm       pox       mcg      erl       gvh       mit       nuc  \\\n0 -0.346645 -0.099131  0.581981 -0.09759  0.888481 -0.957203 -0.527919   \n1 -0.231226 -0.099131 -0.510891 -0.09759  1.372811  0.064312 -0.527919   \n2 -0.115808 -0.099131  1.019130 -0.09759  0.969203 -0.811272 -0.527919   \n3  0.807542 -0.099131  0.581981 -0.09759 -0.483786 -0.957203 -0.527919   \n4 -0.231226 -0.099131 -0.583749 -0.09759 -0.483786  2.034375 -0.527919   \n\n        vac  \n0 -0.344175  \n1  0.521219  \n2  0.521219  \n3  0.694298  \n4 -0.344175  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alm</th>\n      <th>pox</th>\n      <th>mcg</th>\n      <th>erl</th>\n      <th>gvh</th>\n      <th>mit</th>\n      <th>nuc</th>\n      <th>vac</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.346645</td>\n      <td>-0.099131</td>\n      <td>0.581981</td>\n      <td>-0.09759</td>\n      <td>0.888481</td>\n      <td>-0.957203</td>\n      <td>-0.527919</td>\n      <td>-0.344175</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.231226</td>\n      <td>-0.099131</td>\n      <td>-0.510891</td>\n      <td>-0.09759</td>\n      <td>1.372811</td>\n      <td>0.064312</td>\n      <td>-0.527919</td>\n      <td>0.521219</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.115808</td>\n      <td>-0.099131</td>\n      <td>1.019130</td>\n      <td>-0.09759</td>\n      <td>0.969203</td>\n      <td>-0.811272</td>\n      <td>-0.527919</td>\n      <td>0.521219</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.807542</td>\n      <td>-0.099131</td>\n      <td>0.581981</td>\n      <td>-0.09759</td>\n      <td>-0.483786</td>\n      <td>-0.957203</td>\n      <td>-0.527919</td>\n      <td>0.694298</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.231226</td>\n      <td>-0.099131</td>\n      <td>-0.583749</td>\n      <td>-0.09759</td>\n      <td>-0.483786</td>\n      <td>2.034375</td>\n      <td>-0.527919</td>\n      <td>-0.344175</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X_prime,y,test_size=0.202,random_state=42)\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":11,"outputs":[{"output_type":"stream","text":"(1184, 8)\n(300, 8)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.concat([X_train,y_train],axis=1)\n\ntrain0=train[train[\"class\"]==0]\ntrain1=train[train[\"class\"]==1]\ntrain2=train[train[\"class\"]==2]\ntrain3=train[train[\"class\"]==3]\ntrain4=train[train[\"class\"]==4]\ntrain5=train[train[\"class\"]==5]\ntrain6=train[train[\"class\"]==6]\ntrain7=train[train[\"class\"]==7]\ntrain8=train[train[\"class\"]==8]\ntrain9=train[train[\"class\"]==9]\n\n#train1=pd.concat([train1]*3,axis=0)\nminority=pd.concat([train1,train2,train3,train4,train8,train9],axis=0)\nminority=pd.concat([minority]*2,axis=0)\n\ntrain=pd.concat([train0,minority,train5,train6,train7],axis=0)\n\nX_train=train.drop([\"class\"],axis=1)\ny_train=train[[\"class\"]]\n\nprint(X_train.shape)","execution_count":12,"outputs":[{"output_type":"stream","text":"(1339, 8)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nForest=RandomForestClassifier(random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nForest","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"RandomForestClassifier(random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ntrain_pred=Forest.predict(X_train)\ntest_pred=Forest.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":14,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  1.0\nAccuracy on test data:  0.61\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Forest=RandomForestClassifier(n_estimators=99,n_jobs=-1,ccp_alpha=0.002,random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nForest","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"RandomForestClassifier(ccp_alpha=0.002, n_estimators=99, n_jobs=-1,\n                       random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=Forest.predict(X_train)\ntest_pred=Forest.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":16,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.8200149365197908\nAccuracy on test data:  0.62\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nprint(\"F1 score on train data: \",f1_score(y_train,train_pred,average=\"micro\"))\nprint(\"F1 score on test data: \",f1_score(y_test,test_pred,average=\"micro\"))","execution_count":17,"outputs":[{"output_type":"stream","text":"F1 score on train data:  0.8200149365197908\nF1 score on test data:  0.62\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score\nprint(\"Precision score on train data: \",precision_score(y_train,train_pred,average=\"micro\"))\nprint(\"Precision score on test data: \",precision_score(y_test,test_pred,average=\"micro\"))","execution_count":18,"outputs":[{"output_type":"stream","text":"Precision score on train data:  0.8200149365197908\nPrecision score on test data:  0.62\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import recall_score\nprint(\"Recall score on train data: \",recall_score(y_train,train_pred,average=\"micro\"))\nprint(\"Recall score on test data: \",recall_score(y_test,test_pred,average=\"micro\"))","execution_count":19,"outputs":[{"output_type":"stream","text":"Recall score on train data:  0.8200149365197908\nRecall score on test data:  0.62\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import confusion_matrix\nprint(\"Confusion matrix on train data: \\n\",confusion_matrix(y_train,train_pred))\nprint(\"Confusion matrix on test data: \\n\",confusion_matrix(y_test,test_pred))","execution_count":20,"outputs":[{"output_type":"stream","text":"Confusion matrix on train data: \n [[305   0   0   0   1   4  11  42   1   0]\n [  0  10   0   0   0   0   0   0   0   0]\n [  2   0  50   0   2   0   0   0   0   0]\n [  0   0   2  70   0   0   0   0   0   0]\n [  0   0   0   2  80   6   0   2   0   0]\n [  5   0   0   0   1 116   1   6   0   0]\n [ 36   0   0   1   3   4 140   8   0   0]\n [ 47   0   0   0   1   9  14 273   0   0]\n [  6   0   0   0   0   0   2   0  28   0]\n [ 12   0   0   0   2   6   0   2   0  26]]\nConfusion matrix on test data: \n [[63  1  0  0  3  3 29  0  0]\n [ 2  4  0  0  0  2  0  0  0]\n [ 0  3  5  0  0  0  0  0  0]\n [ 1  0  1  3  0  1  0  0  0]\n [ 0  0  0  0 31  1  2  0  0]\n [14  0  0  2  3 27  6  0  0]\n [23  0  0  1  7  3 51  0  0]\n [ 0  0  0  0  0  0  0  2  0]\n [ 2  2  0  0  0  1  1  0  0]]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The above results used standardized data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.202,random_state=42)\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":21,"outputs":[{"output_type":"stream","text":"(1184, 8)\n(300, 8)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.concat([X_train,y_train],axis=1)\n\ntrain0=train[train[\"class\"]==0]\ntrain1=train[train[\"class\"]==1]\ntrain2=train[train[\"class\"]==2]\ntrain3=train[train[\"class\"]==3]\ntrain4=train[train[\"class\"]==4]\ntrain5=train[train[\"class\"]==5]\ntrain6=train[train[\"class\"]==6]\ntrain7=train[train[\"class\"]==7]\ntrain8=train[train[\"class\"]==8]\ntrain9=train[train[\"class\"]==9]\n\n#train1=pd.concat([train1]*3,axis=0)\nminority=pd.concat([train1,train2,train3,train4,train8,train9],axis=0)\nminority=pd.concat([minority]*2,axis=0)\n\ntrain=pd.concat([train0,minority,train5,train6,train7],axis=0)\n\nX_train=train.drop([\"class\"],axis=1)\ny_train=train[[\"class\"]]\n\nprint(X_train.shape)","execution_count":22,"outputs":[{"output_type":"stream","text":"(1339, 8)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nForest=RandomForestClassifier(random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nForest","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"RandomForestClassifier(random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ntrain_pred=Forest.predict(X_train)\ntest_pred=Forest.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":24,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  1.0\nAccuracy on test data:  0.62\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Forest=RandomForestClassifier(n_estimators=99,n_jobs=-1,ccp_alpha=0.002,random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nForest","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"RandomForestClassifier(ccp_alpha=0.002, n_estimators=99, n_jobs=-1,\n                       random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=Forest.predict(X_train)\ntest_pred=Forest.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":26,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.8267363704256908\nAccuracy on test data:  0.63\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"With the same hyper-parameter values, using raw data increased the model's accuracy by 1%. From this point on, I will use raw data."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nGradient=GradientBoostingClassifier(random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nGradient","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"GradientBoostingClassifier(random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=Gradient.predict(X_train)\ntest_pred=Gradient.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":28,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.8678117998506348\nAccuracy on test data:  0.5566666666666666\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Gradient=GradientBoostingClassifier(learning_rate=0.015,subsample=0.5,criterion=\"mse\",\n                                    random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nGradient","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"GradientBoostingClassifier(criterion='mse', learning_rate=0.015, random_state=0,\n                           subsample=0.5)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=Gradient.predict(X_train)\ntest_pred=Gradient.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":30,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.6885735623599701\nAccuracy on test data:  0.62\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"F1 score on train data: \",f1_score(y_train,train_pred,average=\"micro\"))\nprint(\"F1 score on test data: \",f1_score(y_test,test_pred,average=\"micro\"))","execution_count":31,"outputs":[{"output_type":"stream","text":"F1 score on train data:  0.6885735623599701\nF1 score on test data:  0.62\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nSVM=svm.SVC(random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nSVM","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"SVC(random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=SVM.predict(X_train)\ntest_pred=SVM.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":33,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.619865571321882\nAccuracy on test data:  0.6166666666666667\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"SVM=svm.SVC(C=0.5,random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nSVM","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"SVC(C=0.5, random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=SVM.predict(X_train)\ntest_pred=SVM.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":35,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.6094100074682599\nAccuracy on test data:  0.62\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"F1 score on train data: \",f1_score(y_train,train_pred,average=\"micro\"))\nprint(\"F1 score on test data: \",f1_score(y_test,test_pred,average=\"micro\"))","execution_count":36,"outputs":[{"output_type":"stream","text":"F1 score on train data:  0.6094100074682599\nF1 score on test data:  0.62\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.ensemble import BalancedRandomForestClassifier\nBForest=BalancedRandomForestClassifier(\n                                       random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nBForest","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"BalancedRandomForestClassifier(random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=BForest.predict(X_train)\ntest_pred=BForest.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":38,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.6415235250186706\nAccuracy on test data:  0.5266666666666666\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"BForest=BalancedRandomForestClassifier(n_estimators=110,min_samples_split=3,min_samples_leaf=4,\n                                       random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nBForest","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"BalancedRandomForestClassifier(min_samples_leaf=4, min_samples_split=3,\n                               n_estimators=110, random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=BForest.predict(X_train)\ntest_pred=BForest.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":40,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.5608663181478716\nAccuracy on test data:  0.5766666666666667\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"F1 score on train data: \",f1_score(y_train,train_pred,average=\"micro\"))\nprint(\"F1 score on test data: \",f1_score(y_test,test_pred,average=\"micro\"))","execution_count":41,"outputs":[{"output_type":"stream","text":"F1 score on train data:  0.5608663181478716\nF1 score on test data:  0.5766666666666667\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"How would the model have performed if minority classes were not duplicated in traind ata?"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.202,random_state=42)\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":42,"outputs":[{"output_type":"stream","text":"(1184, 8)\n(300, 8)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Forest=RandomForestClassifier(random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nForest","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"RandomForestClassifier(random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=Forest.predict(X_train)\ntest_pred=Forest.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":44,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  1.0\nAccuracy on test data:  0.59\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Forest=RandomForestClassifier(n_estimators=99,n_jobs=-1,ccp_alpha=0.002,random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nForest","execution_count":45,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"RandomForestClassifier(ccp_alpha=0.002, n_estimators=99, n_jobs=-1,\n                       random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=Forest.predict(X_train)\ntest_pred=Forest.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":46,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.8175675675675675\nAccuracy on test data:  0.6266666666666667\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"F1 score on train data: \",f1_score(y_train,train_pred,average=\"micro\"))\nprint(\"F1 score on test data: \",f1_score(y_test,test_pred,average=\"micro\"))","execution_count":47,"outputs":[{"output_type":"stream","text":"F1 score on train data:  0.8175675675675675\nF1 score on test data:  0.6266666666666667\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Gradient=GradientBoostingClassifier(random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nGradient","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"GradientBoostingClassifier(random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=Gradient.predict(X_train)\ntest_pred=Gradient.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":49,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.8547297297297297\nAccuracy on test data:  0.5833333333333334\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Gradient=GradientBoostingClassifier(learning_rate=0.015,subsample=0.5,criterion=\"mse\",\n                                    random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nGradient","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"GradientBoostingClassifier(criterion='mse', learning_rate=0.015, random_state=0,\n                           subsample=0.5)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=Gradient.predict(X_train)\ntest_pred=Gradient.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":51,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.6883445945945946\nAccuracy on test data:  0.62\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"F1 score on train data: \",f1_score(y_train,train_pred,average=\"micro\"))\nprint(\"F1 score on test data: \",f1_score(y_test,test_pred,average=\"micro\"))","execution_count":52,"outputs":[{"output_type":"stream","text":"F1 score on train data:  0.6883445945945946\nF1 score on test data:  0.62\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"SVM=svm.SVC(random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nSVM","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"SVC(random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=SVM.predict(X_train)\ntest_pred=SVM.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":54,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.6275337837837838\nAccuracy on test data:  0.6133333333333333\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"SVM=svm.SVC(C=0.5,random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nSVM","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"SVC(C=0.5, random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=SVM.predict(X_train)\ntest_pred=SVM.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":56,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.6114864864864865\nAccuracy on test data:  0.6266666666666667\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"F1 score on train data: \",f1_score(y_train,train_pred,average=\"micro\"))\nprint(\"F1 score on test data: \",f1_score(y_test,test_pred,average=\"micro\"))","execution_count":57,"outputs":[{"output_type":"stream","text":"F1 score on train data:  0.6114864864864865\nF1 score on test data:  0.6266666666666667\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"BForest=BalancedRandomForestClassifier(\n                                       random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nBForest","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"BalancedRandomForestClassifier(random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=BForest.predict(X_train)\ntest_pred=BForest.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":59,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.5244932432432432\nAccuracy on test data:  0.4666666666666667\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"BForest=BalancedRandomForestClassifier(n_estimators=90,min_samples_split=3,min_samples_leaf=4,\n                                       random_state=0).fit(X_train,np.asarray(y_train).reshape(y_train.shape[0],))\nBForest","execution_count":78,"outputs":[{"output_type":"execute_result","execution_count":78,"data":{"text/plain":"BalancedRandomForestClassifier(min_samples_leaf=4, min_samples_split=3,\n                               n_estimators=90, random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=BForest.predict(X_train)\ntest_pred=BForest.predict(X_test)\nprint(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\nprint(\"Accuracy on test data: \",accuracy_score(y_test,test_pred))","execution_count":79,"outputs":[{"output_type":"stream","text":"Accuracy on train data:  0.5008445945945946\nAccuracy on test data:  0.48333333333333334\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"F1 score on train data: \",f1_score(y_train,train_pred,average=\"micro\"))\nprint(\"F1 score on test data: \",f1_score(y_test,test_pred,average=\"micro\"))","execution_count":73,"outputs":[{"output_type":"stream","text":"F1 score on train data:  0.5008445945945946\nF1 score on test data:  0.48333333333333334\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Summary"},{"metadata":{},"cell_type":"markdown","source":"#### Except the first experimental model, all models were built using raw data, since the experimental model showed that using raw data resulted in slightly higher accuracy."},{"metadata":{},"cell_type":"markdown","source":"#### With no data resampling and default values for hyper-parameters"},{"metadata":{},"cell_type":"markdown","source":"|Model|Train data accuracy|Test data accuracy|\n|-----|-------------------|------------------|\n|RandomForestClassifier|100%|59%|\n|GradientBoostingClassifier|85.47%|58.33%|\n|Support Vector Machine|62.15%|61.33%|\n|BalancedRandomForestClassifier|52.45%|46.67%|"},{"metadata":{},"cell_type":"markdown","source":"#### With no data resampling but tuned values for the impactful hyer-parameters."},{"metadata":{},"cell_type":"markdown","source":"|Model|Train data accuracy|Train data F1 score|Test data accuracy|Test data F1 score|\n|-----|-------------------|------------------|-------------------|------------------|\n|RandomForestClassifier|81.76%|81.76%|62.76%|62.76%|\n|GradientBoostingClassifier|68.83%|68.83%|62%|62%|\n|Support Vector Machine (SVM)|61.15%|61.15%|62.67%|62.67%|\n|BalancedRandomForestClassifier|50.08%|50.08%|48.33%|48.33%|"},{"metadata":{},"cell_type":"markdown","source":"#### Fine-tuning the impactful hyper-parameters reduced the models' accuracies on train data but improved their accuracies on test data. Hyper-parameter fine-tuning, in this case, reduced overfitting. A model's robustness is often measured on test data, not train data."},{"metadata":{},"cell_type":"markdown","source":"#### With the minority classes in train data duplicated by 2 times and default values for hyper-paramters"},{"metadata":{},"cell_type":"markdown","source":"|Model|Train data accuracy|Test data accuracy|\n|-----|-------------------|------------------|\n|RandomForestClassifier|100%| 62%|\n|GradientBoostingClassifier|86.78%|55.67%|\n|Support Vector Machine (SVM)|61.99%|61.67%|\n|BalancedRandomForestClassifier|64.15%|52.67%|"},{"metadata":{},"cell_type":"markdown","source":"#### With minority classes in train data duplicated by 2 times and the impactful hyper-parameters tuned."},{"metadata":{},"cell_type":"markdown","source":"|Model|Train data accuracy|Train data F1 score|Test data accuracy|Test data F1 score|\n|-----|-------------------|-------------------|------------------|------------------|\n|RandomForestClassifier|82.67%|82.67%|63%|63%|\n|GradientBoostingClassifier|68.86%|68.86%|62%|62%|\n|Support Vector Machine (SVM)|60.94%|60.94%|62%|62%|\n|BalancedRandomForestClassifier|56.09%|56.09%|57.67%|57.67%|"},{"metadata":{},"cell_type":"markdown","source":"1. When exposure to minority classes is increased by duplicating the minority classes by 2 times in train data, except the GradientBoostingClassifier model, all models delivered higher accuracies on test data.\n2. The best model is the RandomForestClassifier model when exposure to minority classes is increased by duplicating those classes by 2 times in train data and with the impactful hyper-parameters tuned.The model had an accuracy and F1 score of 63% on test data.\n3. Increasing the model's exposure to minority classes by duplicating those classes in train data does not guarantee better performance in test data. **The impact depends on the dataset in hand and is therefore case-specific.** Nonetheless, it is a quick and effortless way to tackle imbalanced class distribution. For this dataset, the strategy did improve the best model's performance on test data by 1%. Note that even BalancedRandomForestClassifier model, which has built-in functions to handle class imbalance, benefited from the increased exposure to minority classes in train data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}