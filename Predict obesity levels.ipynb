{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size = 6> Predict overweight levels and obesity levels based on lifestyles and eating habits </font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "\n",
    "- [Preprocessing of data](#preprocessing)\n",
    "- [Multilabel neural network](#neural_network)\n",
    "- [Multilabel logistic regression with TensorFlow](#logistic_w_tf)\n",
    "- [Multilabel Random Forest Decision Tree](#random_forest)\n",
    "- [Comparison the lifestyles and eating habits between normal weight individuals and obese individuals](#comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocessing'></a>\n",
    "### I. Preprocessing of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.780000</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>Female</td>\n",
       "      <td>20.976842</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.408528</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.728139</td>\n",
       "      <td>no</td>\n",
       "      <td>1.676269</td>\n",
       "      <td>0.906247</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.982942</td>\n",
       "      <td>1.748584</td>\n",
       "      <td>133.742943</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.005130</td>\n",
       "      <td>no</td>\n",
       "      <td>1.341390</td>\n",
       "      <td>0.599270</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>Female</td>\n",
       "      <td>22.524036</td>\n",
       "      <td>1.752206</td>\n",
       "      <td>133.689352</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.054193</td>\n",
       "      <td>no</td>\n",
       "      <td>1.414209</td>\n",
       "      <td>0.646288</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.361936</td>\n",
       "      <td>1.739450</td>\n",
       "      <td>133.346641</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.852339</td>\n",
       "      <td>no</td>\n",
       "      <td>1.139107</td>\n",
       "      <td>0.586035</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>Female</td>\n",
       "      <td>23.664709</td>\n",
       "      <td>1.738836</td>\n",
       "      <td>133.472641</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.863513</td>\n",
       "      <td>no</td>\n",
       "      <td>1.026452</td>\n",
       "      <td>0.714137</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2111 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender        Age    Height      Weight family_history_with_overweight  \\\n",
       "0     Female  21.000000  1.620000   64.000000                            yes   \n",
       "1     Female  21.000000  1.520000   56.000000                            yes   \n",
       "2       Male  23.000000  1.800000   77.000000                            yes   \n",
       "3       Male  27.000000  1.800000   87.000000                             no   \n",
       "4       Male  22.000000  1.780000   89.800000                             no   \n",
       "...      ...        ...       ...         ...                            ...   \n",
       "2106  Female  20.976842  1.710730  131.408528                            yes   \n",
       "2107  Female  21.982942  1.748584  133.742943                            yes   \n",
       "2108  Female  22.524036  1.752206  133.689352                            yes   \n",
       "2109  Female  24.361936  1.739450  133.346641                            yes   \n",
       "2110  Female  23.664709  1.738836  133.472641                            yes   \n",
       "\n",
       "     FAVC  FCVC  NCP       CAEC SMOKE      CH2O  SCC       FAF       TUE  \\\n",
       "0      no   2.0  3.0  Sometimes    no  2.000000   no  0.000000  1.000000   \n",
       "1      no   3.0  3.0  Sometimes   yes  3.000000  yes  3.000000  0.000000   \n",
       "2      no   2.0  3.0  Sometimes    no  2.000000   no  2.000000  1.000000   \n",
       "3      no   3.0  3.0  Sometimes    no  2.000000   no  2.000000  0.000000   \n",
       "4      no   2.0  1.0  Sometimes    no  2.000000   no  0.000000  0.000000   \n",
       "...   ...   ...  ...        ...   ...       ...  ...       ...       ...   \n",
       "2106  yes   3.0  3.0  Sometimes    no  1.728139   no  1.676269  0.906247   \n",
       "2107  yes   3.0  3.0  Sometimes    no  2.005130   no  1.341390  0.599270   \n",
       "2108  yes   3.0  3.0  Sometimes    no  2.054193   no  1.414209  0.646288   \n",
       "2109  yes   3.0  3.0  Sometimes    no  2.852339   no  1.139107  0.586035   \n",
       "2110  yes   3.0  3.0  Sometimes    no  2.863513   no  1.026452  0.714137   \n",
       "\n",
       "            CALC                 MTRANS           NObeyesdad  \n",
       "0             no  Public_Transportation        Normal_Weight  \n",
       "1      Sometimes  Public_Transportation        Normal_Weight  \n",
       "2     Frequently  Public_Transportation        Normal_Weight  \n",
       "3     Frequently                Walking   Overweight_Level_I  \n",
       "4      Sometimes  Public_Transportation  Overweight_Level_II  \n",
       "...          ...                    ...                  ...  \n",
       "2106   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2107   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2108   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2109   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2110   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "\n",
       "[2111 rows x 17 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"Obesity_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several non-numeric attributes that needs to be either one-hot encoded or label-encoded. Let's see how many unique classes are in each of those non-numeric attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender:  ['Female' 'Male']\n",
      "family_history_with_overweight:  ['no' 'yes']\n",
      "FAVC:  ['no' 'yes']\n",
      "SMOKE:  ['no' 'yes']\n",
      "SCC:  ['no' 'yes']\n",
      "CAEC:  ['Always' 'Frequently' 'Sometimes' 'no']\n",
      "CALC:  ['Always' 'Frequently' 'Sometimes' 'no']\n",
      "MTRANS:  ['Automobile' 'Bike' 'Motorbike' 'Public_Transportation' 'Walking']\n",
      "NObeyesdad ['Insufficient_Weight' 'Normal_Weight' 'Obesity_Type_I' 'Obesity_Type_II'\n",
      " 'Obesity_Type_III' 'Overweight_Level_I' 'Overweight_Level_II']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Gender: \", np.unique(df[[\"Gender\"]]))\n",
    "print(\"family_history_with_overweight: \",np.unique(df[[\"family_history_with_overweight\"]]))\n",
    "print(\"FAVC: \", np.unique(df[[\"FAVC\"]]))\n",
    "print(\"SMOKE: \", np.unique(df[[\"SMOKE\"]]))\n",
    "print(\"SCC: \", np.unique(df[[\"SCC\"]]))\n",
    "print(\"CAEC: \", np.unique(df[[\"CAEC\"]]))\n",
    "print(\"CALC: \", np.unique(df[[\"CALC\"]]))\n",
    "print(\"MTRANS: \", np.unique(df[[\"MTRANS\"]]))\n",
    "print(\"NObeyesdad\", np.unique(df[[\"NObeyesdad\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All non-numeric variables are categorical variables or non-cardinal variables. We are going to apply one-hot encoding to these categorical variables and standardize the numeric variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 17-1 = 16 predictor variables. Some of the predictors might not be relevant. We are going to run a feature selection algorithm and output the feature importance scores. Before that, we need to one-hot encode the categorical variables. If we don't we are going to get an error saying that \"cannot covert strings to floats\". The \"strings\" are the categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the numeric predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.522124</td>\n",
       "      <td>-0.875589</td>\n",
       "      <td>-0.862558</td>\n",
       "      <td>-0.785019</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>-1.188039</td>\n",
       "      <td>0.561997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.522124</td>\n",
       "      <td>-1.947599</td>\n",
       "      <td>-1.168077</td>\n",
       "      <td>1.088342</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>1.618759</td>\n",
       "      <td>2.339750</td>\n",
       "      <td>-1.080625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.206889</td>\n",
       "      <td>1.054029</td>\n",
       "      <td>-0.366090</td>\n",
       "      <td>-0.785019</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>1.163820</td>\n",
       "      <td>0.561997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.423582</td>\n",
       "      <td>1.054029</td>\n",
       "      <td>0.015808</td>\n",
       "      <td>1.088342</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>1.163820</td>\n",
       "      <td>-1.080625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.364507</td>\n",
       "      <td>0.839627</td>\n",
       "      <td>0.122740</td>\n",
       "      <td>-0.785019</td>\n",
       "      <td>-2.167023</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>-1.188039</td>\n",
       "      <td>-1.080625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age    Height    Weight      FCVC       NCP      CH2O       FAF  \\\n",
       "0 -0.522124 -0.875589 -0.862558 -0.785019  0.404153 -0.013073 -1.188039   \n",
       "1 -0.522124 -1.947599 -1.168077  1.088342  0.404153  1.618759  2.339750   \n",
       "2 -0.206889  1.054029 -0.366090 -0.785019  0.404153 -0.013073  1.163820   \n",
       "3  0.423582  1.054029  0.015808  1.088342  0.404153 -0.013073  1.163820   \n",
       "4 -0.364507  0.839627  0.122740 -0.785019 -2.167023 -0.013073 -1.188039   \n",
       "\n",
       "        TUE  \n",
       "0  0.561997  \n",
       "1 -1.080625  \n",
       "2  0.561997  \n",
       "3 -1.080625  \n",
       "4 -1.080625  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "numeric_predictors=df[[\"Age\",\"Height\",\"Weight\",\"FCVC\",\"NCP\",\"CH2O\",\"FAF\",\"TUE\"]]\n",
    "names=numeric_predictors.columns\n",
    "scaler=preprocessing.StandardScaler()\n",
    "numeric_predictors=scaler.fit_transform(numeric_predictors)\n",
    "numeric_predictors=pd.DataFrame(numeric_predictors,columns=names)\n",
    "numeric_predictors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the categorical predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   11   12   13   14  \\\n",
       "0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  1.0  0.0  0.0  1.0   \n",
       "2  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "3  0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "4  0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0  1.0   \n",
       "\n",
       "    15   16   17   18   19   20  \n",
       "0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_predictors=df[[\"Gender\",\"family_history_with_overweight\",\"FAVC\",\"CAEC\",\"SMOKE\",\"CALC\",\"MTRANS\"]]\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ienc=OneHotEncoder(handle_unknown=\"ignore\")\n",
    "categorical_predictors=ienc.fit_transform(categorical_predictors)\n",
    "categorical_predictors=pd.DataFrame(categorical_predictors.toarray())\n",
    "categorical_predictors.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.522124</td>\n",
       "      <td>-0.875589</td>\n",
       "      <td>-0.862558</td>\n",
       "      <td>-0.785019</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>-1.188039</td>\n",
       "      <td>0.561997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.522124</td>\n",
       "      <td>-1.947599</td>\n",
       "      <td>-1.168077</td>\n",
       "      <td>1.088342</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>1.618759</td>\n",
       "      <td>2.339750</td>\n",
       "      <td>-1.080625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.206889</td>\n",
       "      <td>1.054029</td>\n",
       "      <td>-0.366090</td>\n",
       "      <td>-0.785019</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>1.163820</td>\n",
       "      <td>0.561997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.423582</td>\n",
       "      <td>1.054029</td>\n",
       "      <td>0.015808</td>\n",
       "      <td>1.088342</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>1.163820</td>\n",
       "      <td>-1.080625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.364507</td>\n",
       "      <td>0.839627</td>\n",
       "      <td>0.122740</td>\n",
       "      <td>-0.785019</td>\n",
       "      <td>-2.167023</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>-1.188039</td>\n",
       "      <td>-1.080625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age    Height    Weight      FCVC       NCP      CH2O       FAF  \\\n",
       "0 -0.522124 -0.875589 -0.862558 -0.785019  0.404153 -0.013073 -1.188039   \n",
       "1 -0.522124 -1.947599 -1.168077  1.088342  0.404153  1.618759  2.339750   \n",
       "2 -0.206889  1.054029 -0.366090 -0.785019  0.404153 -0.013073  1.163820   \n",
       "3  0.423582  1.054029  0.015808  1.088342  0.404153 -0.013073  1.163820   \n",
       "4 -0.364507  0.839627  0.122740 -0.785019 -2.167023 -0.013073 -1.188039   \n",
       "\n",
       "        TUE    0    1  ...   11   12   13   14   15   16   17   18   19   20  \n",
       "0  0.561997  1.0  0.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1 -1.080625  1.0  0.0  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2  0.561997  0.0  1.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3 -1.080625  0.0  1.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "4 -1.080625  0.0  1.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=pd.concat([numeric_predictors,categorical_predictors],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After one-hot encoding, the predictor set has 29 columns (or attributes). We are going to select the first 15. To do that, we output the 15 largest feature importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.263783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.589299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.420364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.380155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.301670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.287182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.284436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.267063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.218379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.199268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.153091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.146002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.112193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.111077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.102009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scores\n",
       "2   1.263783\n",
       "0   0.589299\n",
       "1   0.420364\n",
       "3   0.380155\n",
       "6   0.301670\n",
       "5   0.287182\n",
       "7   0.284436\n",
       "4   0.267063\n",
       "9   0.218379\n",
       "8   0.199268\n",
       "11  0.153091\n",
       "10  0.146002\n",
       "16  0.112193\n",
       "15  0.111077\n",
       "22  0.102009"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "y=df[[\"NObeyesdad\"]]\n",
    "\n",
    "test=SelectKBest(score_func=mutual_info_classif,k=\"all\")\n",
    "fit=test.fit(X,y)\n",
    "features=fit.transform(X)\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "scores=fit.scores_\n",
    "scores=pd.DataFrame(scores)\n",
    "scores=scores.rename(columns={0:\"scores\"})\n",
    "scores.sort_values(by=[\"scores\"],ascending=False).nlargest(15,\"scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the columns from the original predictor set to form the new predictor set that would be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>NCP</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>8</th>\n",
       "      <th>14</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862558</td>\n",
       "      <td>-0.522124</td>\n",
       "      <td>-0.875589</td>\n",
       "      <td>-0.785019</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>-1.188039</td>\n",
       "      <td>0.561997</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.168077</td>\n",
       "      <td>-0.522124</td>\n",
       "      <td>-1.947599</td>\n",
       "      <td>1.088342</td>\n",
       "      <td>1.618759</td>\n",
       "      <td>2.339750</td>\n",
       "      <td>-1.080625</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.366090</td>\n",
       "      <td>-0.206889</td>\n",
       "      <td>1.054029</td>\n",
       "      <td>-0.785019</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>1.163820</td>\n",
       "      <td>0.561997</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015808</td>\n",
       "      <td>0.423582</td>\n",
       "      <td>1.054029</td>\n",
       "      <td>1.088342</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>1.163820</td>\n",
       "      <td>-1.080625</td>\n",
       "      <td>0.404153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122740</td>\n",
       "      <td>-0.364507</td>\n",
       "      <td>0.839627</td>\n",
       "      <td>-0.785019</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>-1.188039</td>\n",
       "      <td>-1.080625</td>\n",
       "      <td>-2.167023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Weight       Age    Height      FCVC      CH2O       FAF       TUE  \\\n",
       "0 -0.862558 -0.522124 -0.875589 -0.785019 -0.013073 -1.188039  0.561997   \n",
       "1 -1.168077 -0.522124 -1.947599  1.088342  1.618759  2.339750 -1.080625   \n",
       "2 -0.366090 -0.206889  1.054029 -0.785019 -0.013073  1.163820  0.561997   \n",
       "3  0.015808  0.423582  1.054029  1.088342 -0.013073  1.163820 -1.080625   \n",
       "4  0.122740 -0.364507  0.839627 -0.785019 -0.013073 -1.188039 -1.080625   \n",
       "\n",
       "        NCP    0    1    3    2    8   14    7  \n",
       "0  0.404153  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "1  0.404153  1.0  0.0  1.0  0.0  1.0  1.0  0.0  \n",
       "2  0.404153  0.0  1.0  1.0  0.0  1.0  0.0  0.0  \n",
       "3  0.404153  0.0  1.0  0.0  1.0  1.0  0.0  0.0  \n",
       "4 -2.167023  0.0  1.0  0.0  1.0  1.0  1.0  0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=X.iloc[:,[2,0,1,3,5,6,7,4,8,9,11,10,16,22,15]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6\n",
       "0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "1  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "2  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "3  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df[[\"NObeyesdad\"]]\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ienc=OneHotEncoder(handle_unknown=\"ignore\")\n",
    "y=ienc.fit_transform(y)\n",
    "y=pd.DataFrame(y.toarray())\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1794, 15)\n",
      "(317, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train, y_test=train_test_split(X,y,test_size=0.15,random_state=12)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='neural_network'></a>\n",
    "### II. Multilabel neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build, train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=X_train.shape[1]\n",
    "num_classes=y_test.shape[1]\n",
    "\n",
    "import keras\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# define classification model\n",
    "\n",
    "def classification_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(length, activation='relu', input_shape=(length,)))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50,activation=\"relu\"))\n",
    "    model.add(Dense(50,activation=\"relu\"))\n",
    "    model.add(Dense(50,activation=\"tanh\"))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "      \n",
    "    # compile model\n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1794 samples, validate on 317 samples\n",
      "Epoch 1/22\n",
      " - 4s - loss: 1.7682 - acc: 0.3166 - val_loss: 1.4290 - val_acc: 0.4511\n",
      "Epoch 2/22\n",
      " - 1s - loss: 1.0505 - acc: 0.5819 - val_loss: 0.8742 - val_acc: 0.5994\n",
      "Epoch 3/22\n",
      " - 1s - loss: 0.6665 - acc: 0.7542 - val_loss: 0.5953 - val_acc: 0.7413\n",
      "Epoch 4/22\n",
      " - 1s - loss: 0.4799 - acc: 0.8356 - val_loss: 0.4504 - val_acc: 0.7918\n",
      "Epoch 5/22\n",
      " - 1s - loss: 0.3665 - acc: 0.8813 - val_loss: 0.3264 - val_acc: 0.9054\n",
      "Epoch 6/22\n",
      " - 2s - loss: 0.3230 - acc: 0.9019 - val_loss: 0.2840 - val_acc: 0.9211\n",
      "Epoch 7/22\n",
      " - 1s - loss: 0.2546 - acc: 0.9275 - val_loss: 0.3004 - val_acc: 0.9022\n",
      "Epoch 8/22\n",
      " - 1s - loss: 0.2299 - acc: 0.9309 - val_loss: 0.2311 - val_acc: 0.9117\n",
      "Epoch 9/22\n",
      " - 1s - loss: 0.1885 - acc: 0.9415 - val_loss: 0.1824 - val_acc: 0.9527\n",
      "Epoch 10/22\n",
      " - 1s - loss: 0.1761 - acc: 0.9459 - val_loss: 0.1744 - val_acc: 0.9432\n",
      "Epoch 11/22\n",
      " - 1s - loss: 0.1517 - acc: 0.9521 - val_loss: 0.1416 - val_acc: 0.9590\n",
      "Epoch 12/22\n",
      " - 1s - loss: 0.1423 - acc: 0.9571 - val_loss: 0.1343 - val_acc: 0.9621\n",
      "Epoch 13/22\n",
      " - 1s - loss: 0.1290 - acc: 0.9582 - val_loss: 0.1272 - val_acc: 0.9527\n",
      "Epoch 14/22\n",
      " - 1s - loss: 0.1060 - acc: 0.9671 - val_loss: 0.1330 - val_acc: 0.9401\n",
      "Epoch 15/22\n",
      " - 1s - loss: 0.0932 - acc: 0.9716 - val_loss: 0.1257 - val_acc: 0.9495\n",
      "Epoch 16/22\n",
      " - 1s - loss: 0.0875 - acc: 0.9693 - val_loss: 0.1478 - val_acc: 0.9369\n",
      "Epoch 17/22\n",
      " - 1s - loss: 0.0868 - acc: 0.9744 - val_loss: 0.1109 - val_acc: 0.9653\n",
      "Epoch 18/22\n",
      " - 1s - loss: 0.0758 - acc: 0.9749 - val_loss: 0.2054 - val_acc: 0.9180\n",
      "Epoch 19/22\n",
      " - 1s - loss: 0.1394 - acc: 0.9448 - val_loss: 0.1397 - val_acc: 0.9527\n",
      "Epoch 20/22\n",
      " - 1s - loss: 0.0661 - acc: 0.9783 - val_loss: 0.0934 - val_acc: 0.9653\n",
      "Epoch 21/22\n",
      " - 1s - loss: 0.0516 - acc: 0.9894 - val_loss: 0.1280 - val_acc: 0.9527\n",
      "Epoch 22/22\n",
      " - 1s - loss: 0.0525 - acc: 0.9849 - val_loss: 0.1079 - val_acc: 0.9621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10792465103137944, 0.9621451104100947]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=classification_model()\n",
    "model.fit(X_train,y_train,validation_data=(X_test, y_test),epochs=22, verbose=2)\n",
    "model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  neural network model has a 96.2% accuracy on test data. Not bad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='logistic_w_tf'></a>\n",
    "### III. Multilabel logistic regression with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try TensorFlow as well. **Restart the kernel and re-run the code blocks up to the code block the separates the data for training and test purpose. Reset the train-test split.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# numFeatures is the number of features in our input data.\n",
    "numFeatures = X_train.shape[1]\n",
    "\n",
    "# numLabels is the number of classes our data points can be in.\n",
    "numLabels = y_train.shape[1]\n",
    "\n",
    "\n",
    "# Placeholders\n",
    "# 'None' means TensorFlow shouldn't expect a fixed number in that dimension\n",
    "X = tf.placeholder(tf.float32, [None, numFeatures]) \n",
    "yGold = tf.placeholder(tf.float32, [None, numLabels]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.random_normal([numFeatures,numLabels],\n",
    "                                       mean=0,\n",
    "                                       stddev=0.001,\n",
    "                                       name=\"weights\"))\n",
    "\n",
    "bias = tf.Variable(tf.random_normal([1,numLabels],\n",
    "                                    mean=0,\n",
    "                                    stddev=0.001,\n",
    "                                    name=\"bias\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three-component breakdown of the Logistic Regression equation.\n",
    "# Note that these feed into each other.\n",
    "apply_weights_OP = tf.matmul(X, weights, name=\"apply_weights\")\n",
    "add_bias_OP = tf.add(apply_weights_OP, bias, name=\"add_bias\") \n",
    "activation_OP = tf.nn.sigmoid(add_bias_OP, name=\"activation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Epochs in our training\n",
    "numEpochs = 50000\n",
    "\n",
    "# Defining our learning rate iterations (decay)\n",
    "learningRate = tf.train.exponential_decay(learning_rate=0.0001,\n",
    "                                          global_step= 1,\n",
    "                                          decay_steps=X_train.shape[0],\n",
    "                                          decay_rate= 0.9,\n",
    "                                          staircase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining our cost function - Squared Mean Error\n",
    "cost_OP = tf.nn.l2_loss(activation_OP-yGold, name=\"squared_error_cost\")\n",
    "\n",
    "#Defining our Gradient Descent\n",
    "training_OP = tf.train.GradientDescentOptimizer(learningRate).minimize(cost_OP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorflow session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize our weights and biases variables.\n",
    "init_OP = tf.global_variables_initializer()\n",
    "\n",
    "# Initialize all tensorflow variables\n",
    "sess.run(init_OP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmax(activation_OP, 1) returns the label with the most probability\n",
    "# argmax(yGold, 1) is the correct label\n",
    "correct_predictions_OP = tf.equal(tf.argmax(activation_OP,1),tf.argmax(yGold,1))\n",
    "\n",
    "# If every false prediction is 0 and every true prediction is 1, the average returns us the accuracy\n",
    "accuracy_OP = tf.reduce_mean(tf.cast(correct_predictions_OP, \"float\"))\n",
    "\n",
    "# Summary op for regression output\n",
    "activation_summary_OP = tf.summary.histogram(\"output\", activation_OP)\n",
    "\n",
    "# Summary op for accuracy\n",
    "accuracy_summary_OP = tf.summary.scalar(\"accuracy\", accuracy_OP)\n",
    "\n",
    "# Summary op for cost\n",
    "cost_summary_OP = tf.summary.scalar(\"cost\", cost_OP)\n",
    "\n",
    "# Summary ops to check how variables (W, b) are updating after each iteration\n",
    "weightSummary = tf.summary.histogram(\"weights\", weights.eval(session=sess))\n",
    "biasSummary = tf.summary.histogram(\"biases\", bias.eval(session=sess))\n",
    "\n",
    "# Merge all summaries\n",
    "merged = tf.summary.merge([activation_summary_OP, accuracy_summary_OP, cost_summary_OP, weightSummary, biasSummary])\n",
    "\n",
    "# Summary writer\n",
    "writer = tf.summary.FileWriter(\"summary_logs\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.483278, cost 1504.89, change in cost 1504.89\n",
      "step 1000, training accuracy 0.63155, cost 476.217, change in cost 1028.68\n",
      "step 2000, training accuracy 0.670011, cost 445.928, change in cost 30.2888\n",
      "step 3000, training accuracy 0.687848, cost 430.748, change in cost 15.1806\n",
      "step 4000, training accuracy 0.694537, cost 421.33, change in cost 9.4176\n",
      "step 5000, training accuracy 0.701784, cost 414.843, change in cost 6.48734\n",
      "step 6000, training accuracy 0.705686, cost 410.064, change in cost 4.7785\n",
      "step 7000, training accuracy 0.708473, cost 406.375, change in cost 3.68954\n",
      "step 8000, training accuracy 0.70903, cost 403.423, change in cost 2.95151\n",
      "step 9000, training accuracy 0.711817, cost 400.998, change in cost 2.42578\n",
      "step 10000, training accuracy 0.715162, cost 398.96, change in cost 2.03754\n",
      "step 11000, training accuracy 0.718506, cost 397.218, change in cost 1.74194\n",
      "step 12000, training accuracy 0.719064, cost 395.707, change in cost 1.51083\n",
      "step 13000, training accuracy 0.721293, cost 394.381, change in cost 1.32642\n",
      "step 14000, training accuracy 0.722408, cost 393.204, change in cost 1.17712\n",
      "step 15000, training accuracy 0.723523, cost 392.15, change in cost 1.05374\n",
      "step 16000, training accuracy 0.724638, cost 391.199, change in cost 0.950897\n",
      "step 17000, training accuracy 0.725195, cost 390.335, change in cost 0.864014\n",
      "step 18000, training accuracy 0.725753, cost 389.545, change in cost 0.789703\n",
      "step 19000, training accuracy 0.726867, cost 388.82, change in cost 0.725677\n",
      "step 20000, training accuracy 0.72631, cost 388.149, change in cost 0.670227\n",
      "step 21000, training accuracy 0.727982, cost 387.528, change in cost 0.621735\n",
      "step 22000, training accuracy 0.730212, cost 386.949, change in cost 0.578949\n",
      "step 23000, training accuracy 0.731327, cost 386.408, change in cost 0.540955\n",
      "step 24000, training accuracy 0.731327, cost 385.901, change in cost 0.507019\n",
      "step 25000, training accuracy 0.731884, cost 385.424, change in cost 0.476562\n",
      "step 26000, training accuracy 0.731327, cost 384.975, change in cost 0.449432\n",
      "step 27000, training accuracy 0.731327, cost 384.55, change in cost 0.424805\n",
      "step 28000, training accuracy 0.731884, cost 384.148, change in cost 0.402222\n",
      "step 29000, training accuracy 0.734114, cost 383.766, change in cost 0.381805\n",
      "step 30000, training accuracy 0.734114, cost 383.403, change in cost 0.362915\n",
      "step 31000, training accuracy 0.734671, cost 383.057, change in cost 0.345856\n",
      "step 32000, training accuracy 0.734671, cost 382.727, change in cost 0.329803\n",
      "step 33000, training accuracy 0.735229, cost 382.412, change in cost 0.315491\n",
      "step 34000, training accuracy 0.735786, cost 382.11, change in cost 0.301788\n",
      "step 35000, training accuracy 0.735786, cost 381.821, change in cost 0.289307\n",
      "step 36000, training accuracy 0.735786, cost 381.543, change in cost 0.277527\n",
      "step 37000, training accuracy 0.735786, cost 381.277, change in cost 0.266449\n",
      "step 38000, training accuracy 0.735786, cost 381.02, change in cost 0.256378\n",
      "step 39000, training accuracy 0.735786, cost 380.773, change in cost 0.247009\n",
      "step 40000, training accuracy 0.735786, cost 380.536, change in cost 0.237701\n",
      "step 41000, training accuracy 0.735786, cost 380.306, change in cost 0.229767\n",
      "step 42000, training accuracy 0.735786, cost 380.085, change in cost 0.221497\n",
      "step 43000, training accuracy 0.735786, cost 379.871, change in cost 0.213989\n",
      "step 44000, training accuracy 0.735786, cost 379.664, change in cost 0.20694\n",
      "step 45000, training accuracy 0.736343, cost 379.463, change in cost 0.200378\n",
      "step 46000, training accuracy 0.736343, cost 379.269, change in cost 0.194061\n",
      "step 47000, training accuracy 0.736343, cost 379.081, change in cost 0.187988\n",
      "step 48000, training accuracy 0.736343, cost 378.899, change in cost 0.182343\n",
      "step 49000, training accuracy 0.736343, cost 378.722, change in cost 0.176849\n",
      "final accuracy on test set: 0.7097792\n"
     ]
    }
   ],
   "source": [
    "# Initialize reporting variables\n",
    "cost = 0\n",
    "diff = 1\n",
    "epoch_values = []\n",
    "accuracy_values = []\n",
    "cost_values = []\n",
    "\n",
    "# Training epochs\n",
    "for i in range(numEpochs):\n",
    "    if i > 1 and diff < .0001:\n",
    "        print(\"change in cost %g; convergence.\"%diff)\n",
    "        break\n",
    "    else:\n",
    "        # Run training step\n",
    "        step = sess.run(training_OP, feed_dict={X: X_train, yGold: y_train})\n",
    "        # Report occasional stats\n",
    "        if i % 1000 == 0:\n",
    "            # Add epoch to epoch_values\n",
    "            epoch_values.append(i)\n",
    "            # Generate accuracy stats on test data\n",
    "            train_accuracy, newCost = sess.run([accuracy_OP, cost_OP], feed_dict={X: X_train, yGold: y_train})\n",
    "            # Add accuracy to live graphing variable\n",
    "            accuracy_values.append(train_accuracy)\n",
    "            # Add cost to live graphing variable\n",
    "            cost_values.append(newCost)\n",
    "            # Re-assign values for variables\n",
    "            diff = abs(newCost - cost)\n",
    "            cost = newCost\n",
    "\n",
    "            #generate print statements\n",
    "            print(\"step %d, training accuracy %g, cost %g, change in cost %g\"%(i, train_accuracy, newCost, diff))\n",
    "\n",
    "\n",
    "# How well do we perform on held-out test data?\n",
    "print(\"final accuracy on test set: %s\" %str(sess.run(accuracy_OP, \n",
    "                                                     feed_dict={X: X_test, \n",
    "                                                                yGold: y_test})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model with TensorFlow performed miserably, with an accuracy of only 71% on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='random_forest'></a>\n",
    "### IV. Random Forest Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also try Random Forest decision tree. **Re-start the kernel and re-run the code blocks up to where it splits the data for training and test purposes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=15,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForest = RandomForestClassifier(criterion=\"entropy\", max_depth = 25,random_state=42,min_samples_split=15)\n",
    "RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=15,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTrees's Accuracy:  0.7767253044654939\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "y_pred=RandomForest.predict(X_test)\n",
    "print(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network model delivered commendable result on test data. However, the logistic regression model with TensorFlow and the Random Forest Decision Tree model performed miserably. We could have stopped after the neural network model. Most of the time, a neural network model outperforms other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='comparison'></a>\n",
    "### V. Comparsion of the lifestyles and eating habits of normal weight individuals and obese individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the lifestyles and eating habits of the obesed individuals and the individuals with normal weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Male</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Female</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Female</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Female</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>Female</td>\n",
       "      <td>20.976842</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.408528</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.728139</td>\n",
       "      <td>no</td>\n",
       "      <td>1.676269</td>\n",
       "      <td>0.906247</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.982942</td>\n",
       "      <td>1.748584</td>\n",
       "      <td>133.742943</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.005130</td>\n",
       "      <td>no</td>\n",
       "      <td>1.341390</td>\n",
       "      <td>0.599270</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>Female</td>\n",
       "      <td>22.524036</td>\n",
       "      <td>1.752206</td>\n",
       "      <td>133.689352</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.054193</td>\n",
       "      <td>no</td>\n",
       "      <td>1.414209</td>\n",
       "      <td>0.646288</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.361936</td>\n",
       "      <td>1.739450</td>\n",
       "      <td>133.346641</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.852339</td>\n",
       "      <td>no</td>\n",
       "      <td>1.139107</td>\n",
       "      <td>0.586035</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>Female</td>\n",
       "      <td>23.664709</td>\n",
       "      <td>1.738836</td>\n",
       "      <td>133.472641</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.863513</td>\n",
       "      <td>no</td>\n",
       "      <td>1.026452</td>\n",
       "      <td>0.714137</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>972 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender        Age    Height      Weight family_history_with_overweight  \\\n",
       "10      Male  26.000000  1.850000  105.000000                            yes   \n",
       "13      Male  41.000000  1.800000   99.000000                             no   \n",
       "17    Female  29.000000  1.530000   78.000000                             no   \n",
       "21    Female  52.000000  1.690000   87.000000                            yes   \n",
       "23    Female  22.000000  1.600000   82.000000                            yes   \n",
       "...      ...        ...       ...         ...                            ...   \n",
       "2106  Female  20.976842  1.710730  131.408528                            yes   \n",
       "2107  Female  21.982942  1.748584  133.742943                            yes   \n",
       "2108  Female  22.524036  1.752206  133.689352                            yes   \n",
       "2109  Female  24.361936  1.739450  133.346641                            yes   \n",
       "2110  Female  23.664709  1.738836  133.472641                            yes   \n",
       "\n",
       "     FAVC  FCVC  NCP        CAEC SMOKE      CH2O SCC       FAF       TUE  \\\n",
       "10    yes   3.0  3.0  Frequently    no  3.000000  no  2.000000  2.000000   \n",
       "13    yes   2.0  3.0   Sometimes    no  2.000000  no  2.000000  1.000000   \n",
       "17    yes   2.0  1.0   Sometimes    no  2.000000  no  0.000000  0.000000   \n",
       "21    yes   3.0  1.0   Sometimes   yes  2.000000  no  0.000000  0.000000   \n",
       "23    yes   1.0  1.0   Sometimes    no  2.000000  no  0.000000  2.000000   \n",
       "...   ...   ...  ...         ...   ...       ...  ..       ...       ...   \n",
       "2106  yes   3.0  3.0   Sometimes    no  1.728139  no  1.676269  0.906247   \n",
       "2107  yes   3.0  3.0   Sometimes    no  2.005130  no  1.341390  0.599270   \n",
       "2108  yes   3.0  3.0   Sometimes    no  2.054193  no  1.414209  0.646288   \n",
       "2109  yes   3.0  3.0   Sometimes    no  2.852339  no  1.139107  0.586035   \n",
       "2110  yes   3.0  3.0   Sometimes    no  2.863513  no  1.026452  0.714137   \n",
       "\n",
       "            CALC                 MTRANS        NObeyesdad  \n",
       "10     Sometimes  Public_Transportation    Obesity_Type_I  \n",
       "13    Frequently             Automobile    Obesity_Type_I  \n",
       "17            no             Automobile    Obesity_Type_I  \n",
       "21            no             Automobile    Obesity_Type_I  \n",
       "23     Sometimes  Public_Transportation    Obesity_Type_I  \n",
       "...          ...                    ...               ...  \n",
       "2106   Sometimes  Public_Transportation  Obesity_Type_III  \n",
       "2107   Sometimes  Public_Transportation  Obesity_Type_III  \n",
       "2108   Sometimes  Public_Transportation  Obesity_Type_III  \n",
       "2109   Sometimes  Public_Transportation  Obesity_Type_III  \n",
       "2110   Sometimes  Public_Transportation  Obesity_Type_III  \n",
       "\n",
       "[972 rows x 17 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_I=df[df[\"NObeyesdad\"]==\"Obesity_Type_I\"]\n",
    "obesity_II=df[df[\"NObeyesdad\"]==\"Obesity_Type_II\"]\n",
    "obesity_III=df[df[\"NObeyesdad\"]==\"Obesity_Type_III\"]\n",
    "obesity=pd.concat([obesity_I, obesity_II, obesity_III],axis=0)\n",
    "obesity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to plot how the categorical variables that describe the lifestyles and eating habits the obesed individuals. Simply plotting the counts can be misleading. For example, there dataset may include many more non-smokers than smokers. If we simply plot the counts, it might lead to the mis-conclusion that smokers are less likely to be obesed. Hence, we are going to plot the percentage relative to the toal number of obesed individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of obesed individuals who monitored their calorie consumption is:  0.0030864197530864196\n",
      "Proportion of obesed individual with family history of overweight is:  0.9917695473251029\n",
      "Proportion of obesed individuals who took public transportation or drove is:  0.992798353909465\n",
      "Average frequency of consumption of vegetables for obesed individuals (FCVC):  FCVC    2.520077\n",
      "dtype: float64\n",
      "Numer of main meals for obesed individuals (NCP):  NCP    2.716786\n",
      "dtype: float64\n",
      "Consumption of water daily (CH20):  CH2O    2.072639\n",
      "dtype: float64\n",
      "Physical activity frequency (FAF):  FAF    0.874888\n",
      "dtype: float64\n",
      "Time using technology devices (TUE):  TUE    0.603338\n",
      "dtype: float64\n",
      "Frequent consumption of high caloric food (FAVC):  0.9804526748971193\n",
      "Consumption of food between meals (CAEC):  0.9979423868312757\n",
      "Consumption of alcohol:  0.7561728395061729\n"
     ]
    }
   ],
   "source": [
    "SCC = obesity[obesity[\"SCC\"]==\"yes\"]\n",
    "print(\"Proportion of obesed individuals who monitored their calorie consumption is: \", len(SCC)/len(obesity))\n",
    "\n",
    "family_history=obesity[obesity[\"family_history_with_overweight\"]==\"yes\"]\n",
    "print(\"Proportion of obesed individual with family history of overweight is: \", len(family_history)/len(obesity))\n",
    "\n",
    "MTRANS_public=obesity[obesity[\"MTRANS\"]==\"Public_Transportation\"]\n",
    "MTRANS_auto=obesity[obesity[\"MTRANS\"]==\"Automobile\"]\n",
    "print(\"Proportion of obesed individuals who took public transportation or drove is: \", (len(MTRANS_public)+len(MTRANS_auto))/len(obesity))\n",
    "\n",
    "print(\"Average frequency of consumption of vegetables for obesed individuals (FCVC): \",obesity[[\"FCVC\"]].mean())\n",
    "print(\"Numer of main meals for obesed individuals (NCP): \",obesity[[\"NCP\"]].mean())\n",
    "print(\"Consumption of water daily (CH20): \", obesity[[\"CH2O\"]].mean())\n",
    "print(\"Physical activity frequency (FAF): \", obesity[[\"FAF\"]].mean())\n",
    "print(\"Time using technology devices (TUE): \",obesity[[\"TUE\"]].mean())\n",
    "\n",
    "FAVC=obesity[obesity[\"FAVC\"]==\"yes\"]\n",
    "print(\"Frequent consumption of high caloric food (FAVC): \",len(FAVC)/len(obesity))\n",
    "\n",
    "CAEC=obesity[obesity[\"CAEC\"]==\"no\"]\n",
    "print(\"Consumption of food between meals (CAEC): \", (len(obesity)-len(CAEC))/len(obesity) )\n",
    "\n",
    "CALC=obesity[obesity[\"CALC\"]==\"no\"]\n",
    "print(\"Consumption of alcohol: \",(len(obesity)-len(CALC))/len(obesity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>53.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>55.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>Male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>68.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>65.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>66.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>60.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Always</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>45.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
       "0    Female  21.0    1.62    64.0                            yes   no   2.0   \n",
       "1    Female  21.0    1.52    56.0                            yes   no   3.0   \n",
       "2      Male  23.0    1.80    77.0                            yes   no   2.0   \n",
       "5      Male  29.0    1.62    53.0                             no  yes   2.0   \n",
       "6    Female  23.0    1.50    55.0                            yes  yes   3.0   \n",
       "..      ...   ...     ...     ...                            ...  ...   ...   \n",
       "491    Male  25.0    1.66    68.0                             no  yes   2.0   \n",
       "493    Male  20.0    1.80    65.0                             no  yes   2.0   \n",
       "494  Female  18.0    1.67    66.0                             no  yes   3.0   \n",
       "495    Male  19.0    1.80    60.0                            yes  yes   3.0   \n",
       "497    Male  20.0    1.56    45.0                             no   no   2.0   \n",
       "\n",
       "     NCP        CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
       "0    3.0   Sometimes    no   2.0   no  0.0  1.0          no   \n",
       "1    3.0   Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
       "2    3.0   Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
       "5    3.0   Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
       "6    3.0   Sometimes    no   2.0   no  1.0  0.0   Sometimes   \n",
       "..   ...         ...   ...   ...  ...  ...  ...         ...   \n",
       "491  3.0   Sometimes   yes   1.0   no  1.0  1.0   Sometimes   \n",
       "493  3.0  Frequently    no   1.0   no  2.0  0.0   Sometimes   \n",
       "494  3.0   Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
       "495  1.0      Always    no   1.0  yes  0.0  0.0          no   \n",
       "497  3.0   Sometimes    no   2.0   no  1.0  1.0   Sometimes   \n",
       "\n",
       "                    MTRANS     NObeyesdad  \n",
       "0    Public_Transportation  Normal_Weight  \n",
       "1    Public_Transportation  Normal_Weight  \n",
       "2    Public_Transportation  Normal_Weight  \n",
       "5               Automobile  Normal_Weight  \n",
       "6                Motorbike  Normal_Weight  \n",
       "..                     ...            ...  \n",
       "491  Public_Transportation  Normal_Weight  \n",
       "493              Motorbike  Normal_Weight  \n",
       "494  Public_Transportation  Normal_Weight  \n",
       "495              Motorbike  Normal_Weight  \n",
       "497  Public_Transportation  Normal_Weight  \n",
       "\n",
       "[287 rows x 17 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal=df[df[\"NObeyesdad\"]==\"Normal_Weight\"]\n",
    "normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of normal weight individuals who monitored their calorie consumption is:  0.10452961672473868\n",
      "Proportion of normal weight individual with family history of overweight is:  0.5400696864111498\n",
      "Proportion of normal weight individuals who took public transportation or drove is:  0.8536585365853658\n",
      "Average frequency of consumption of vegetables for obesed individuals (FCVC):  FCVC    2.334495\n",
      "dtype: float64\n",
      "Numer of main meals for obesed individuals (NCP):  NCP    2.738676\n",
      "dtype: float64\n",
      "Consumption of water daily (CH2O):  CH2O    1.850174\n",
      "dtype: float64\n",
      "Physical activity frequency (FAF):  FAF    1.247387\n",
      "dtype: float64\n",
      "Time using technology devices (TUE):  TUE    0.675958\n",
      "dtype: float64\n",
      "Frequent consumption of high caloric food (FAVC):  0.7247386759581882\n",
      "Consumption of food between meals (CAEC):  3.35191637630662\n",
      "Consumption of alcohol:  3.013937282229965\n"
     ]
    }
   ],
   "source": [
    "SCC = normal[normal[\"SCC\"]==\"yes\"]\n",
    "print(\"Proportion of normal weight individuals who monitored their calorie consumption is: \", len(SCC)/len(normal))\n",
    "\n",
    "family_history=normal[normal[\"family_history_with_overweight\"]==\"yes\"]\n",
    "print(\"Proportion of normal weight individual with family history of overweight is: \", len(family_history)/len(normal))\n",
    "\n",
    "MTRANS_public=normal[normal[\"MTRANS\"]==\"Public_Transportation\"]\n",
    "MTRANS_auto=normal[normal[\"MTRANS\"]==\"Automobile\"]\n",
    "print(\"Proportion of normal weight individuals who took public transportation or drove is: \", (len(MTRANS_public)+len(MTRANS_auto))/len(normal))\n",
    "\n",
    "print(\"Average frequency of consumption of vegetables for obesed individuals (FCVC): \",normal[[\"FCVC\"]].mean())\n",
    "print(\"Numer of main meals for obesed individuals (NCP): \",normal[[\"NCP\"]].mean())\n",
    "print(\"Consumption of water daily (CH2O): \", normal[[\"CH2O\"]].mean())\n",
    "print(\"Physical activity frequency (FAF): \", normal[[\"FAF\"]].mean())\n",
    "print(\"Time using technology devices (TUE): \",normal[[\"TUE\"]].mean())\n",
    "\n",
    "FAVC=normal[normal[\"FAVC\"]==\"yes\"]\n",
    "print(\"Frequent consumption of high caloric food (FAVC): \",len(FAVC)/len(normal))\n",
    "\n",
    "CAEC=normal[normal[\"CAEC\"]==\"no\"]\n",
    "print(\"Consumption of food between meals (CAEC): \", (len(obesity)-len(CAEC))/len(normal) )\n",
    "\n",
    "CALC=normal[normal[\"CALC\"]==\"no\"]\n",
    "print(\"Consumption of alcohol: \",(len(obesity)-len(CALC))/len(normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize the outputs above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Monitor calorie consumption</th>\n",
       "      <th>Family history</th>\n",
       "      <th>Public transportation or drove</th>\n",
       "      <th>Number of main meals (NCP)</th>\n",
       "      <th>Daily consumption of water (CH2O)</th>\n",
       "      <th>Physical activity frequency (FAF)</th>\n",
       "      <th>Time using technology devices (TUE)</th>\n",
       "      <th>Frequent consumption of high caloric food (FAVC)</th>\n",
       "      <th>Consumption of food between meals (CAEC)</th>\n",
       "      <th>Consumption of alcohol (CALC)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Obese</th>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.9918</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>2.7168</td>\n",
       "      <td>2.0726</td>\n",
       "      <td>0.8749</td>\n",
       "      <td>0.6033</td>\n",
       "      <td>0.98045</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.75617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal weight</th>\n",
       "      <td>0.1045</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.8537</td>\n",
       "      <td>2.7387</td>\n",
       "      <td>1.8502</td>\n",
       "      <td>1.2474</td>\n",
       "      <td>0.6760</td>\n",
       "      <td>0.72470</td>\n",
       "      <td>3.3519</td>\n",
       "      <td>3.01390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Monitor calorie consumption  Family history  \\\n",
       "Obese                               0.0031          0.9918   \n",
       "Normal weight                       0.1045          0.5401   \n",
       "\n",
       "               Public transportation or drove  Number of main meals (NCP)  \\\n",
       "Obese                                  0.9928                      2.7168   \n",
       "Normal weight                          0.8537                      2.7387   \n",
       "\n",
       "               Daily consumption of water (CH2O)  \\\n",
       "Obese                                     2.0726   \n",
       "Normal weight                             1.8502   \n",
       "\n",
       "               Physical activity frequency (FAF)  \\\n",
       "Obese                                     0.8749   \n",
       "Normal weight                             1.2474   \n",
       "\n",
       "               Time using technology devices (TUE)  \\\n",
       "Obese                                       0.6033   \n",
       "Normal weight                               0.6760   \n",
       "\n",
       "               Frequent consumption of high caloric food (FAVC)  \\\n",
       "Obese                                                   0.98045   \n",
       "Normal weight                                           0.72470   \n",
       "\n",
       "               Consumption of food between meals (CAEC)  \\\n",
       "Obese                                            0.9979   \n",
       "Normal weight                                    3.3519   \n",
       "\n",
       "               Consumption of alcohol (CALC)  \n",
       "Obese                                0.75617  \n",
       "Normal weight                        3.01390  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Obese': [0.0031,0.9918,0.9928,2.7168,2.0726,0.8749,0.6033,0.98045,0.9979, 0.75617], 'Normal weight': [0.1045, 0.5401,0.8537,2.7387,1.8502,1.2474,0.6760,0.7247,3.3519,3.0139]}\n",
    "d = pd.DataFrame(data=d).T.rename(columns={0:\"Monitor calorie consumption\",1:\"Family history\",2:\"Public transportation or drove\",3:\"Number of main meals (NCP)\",4:\"Daily consumption of water (CH2O)\",5:\"Physical activity frequency (FAF)\",6:\"Time using technology devices (TUE)\",7:\"Frequent consumption of high caloric food (FAVC)\",8:\"Consumption of food between meals (CAEC)\",9:\"Consumption of alcohol (CALC)\"})\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "d.T.plot(kind=\"barh\",figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics and the graph show a stark contrast between the lifestyles of the individuals who were normal weight and the ones who were obese. \n",
    "\n",
    "- Normal weight individuals are more likely to monitor their calorie consumption. More than 10% of the normal weight individuals monitor their calorie consumption, while less than 1% of obese individuals did the same thing.\n",
    "- More than 99% of the obese individuals had family history of overweight, while only 54% of normal weight individuals had such family history.\n",
    "- Normal weight individuals were more active. More than 99% of the obese individuals took public transportation or drove, while only slightly more than 85% of the normal individuals did the same. Normal weight individuals were more active. They were 15% more likely to ride a bike or walk.\n",
    "- Normal weight individuals were much more likely to do physical activities.\n",
    "- Normal weight individuals had more main meals. Normal weight individuals were also more likely to snack between meals. In other words, normal weight individuals even out their consumption of food, versus obese individuals who ate less ofen and had big meals.\n",
    "- Normal weight individuals were less likely to consume high calorie food.\n",
    "\n",
    "Several puzzling differences were also found, although it is not clear how these differences contributed to body weight.\n",
    "- Normal weight individuals consumed more alcohol.\n",
    "- Normal weight individual consumed less amount of water.\n",
    "- Normal weight individual spent more time using technology devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a neural network model that can predict whether an individual will be underweight,normal weight, overweight level I, overweight level II, obesity type I, obesity type II, or obesity type III. The model has a 96.2% accuracy on test data. We also analyzed the lifestyles and eating habits of individuals with normal weight and individuals with obesity.\n",
    "\n",
    "For exercise purpose, we also included two extra predictive model: logistic regression with TensorFlow and Random Forest Decision Tree. However, the performances of these two models are inferior to that of the neural network model. The logistic regression model with TensorFlow and the Random Forest Decision Tree model can be igored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
